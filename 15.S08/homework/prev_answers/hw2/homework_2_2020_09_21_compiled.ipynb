{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Homework #2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "%pylab inline"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\r\n",
    "import json\r\n",
    "import re\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Problem 1: Word phrases\n",
    "\n",
    "### In this problem we will look at methods to identify valid n-grams such as 'New York' or 'Barack Obama' while eliminating statistical flukes such as `in the` or `i write`.\n",
    "\n",
    "### Preprocessing such as this can drastically improved embeddings since words can ngrams will often have a different meaning than the sum of its parts\n",
    "### `V('united')` + `V('states')` != `V('united states')`\n",
    "### `V('real')` + `V('estate')` != `V('real estate')`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "wiki_df = pd.read_csv('./data/kdwd_r1k_articles.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### get consecutive unigrams for the 'intro_text' column of our dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# list of lists of unigrams\r\n",
    "unigram_pattern = r'[a-z0-9]+'\r\n",
    "corpus = [re.findall(unigram_pattern, doc.lower()) for doc in wiki_df['intro_text'].tolist()]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The package `gensim` has a convenient wrapper to obtain statistically significant ngrams/Phrase automatically\n",
    "\n",
    "### we need to first `pip install gensim`\n",
    "### `gensim` is a useful library for anything related to word representations and embeddings. It will come up a few more times. https://radimrehurek.com/gensim/index.html"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import sys\r\n",
    "!{sys.executable} -m pip install gensim\r\n",
    "from gensim.models.phrases import Phrases"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: gensim in d:\\anaconda\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in d:\\anaconda\\lib\\site-packages (from gensim) (1.19.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in d:\\anaconda\\lib\\site-packages (from gensim) (1.5.2)\n",
      "Requirement already satisfied: six>=1.5.0 in d:\\anaconda\\lib\\site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: smart-open>=1.7.0 in d:\\anaconda\\lib\\site-packages (from gensim) (2.2.0)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from smart-open>=1.7.0->gensim) (2.24.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in d:\\anaconda\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (3.0.4)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Write some code to parse our corpus and use valid ngrams using `Phrases`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "phrases = Phrases(corpus, min_count=1, threshold=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "vocab_count_dict = {k.decode('utf8'): v for k, v in phrases.vocab.items()}\r\n",
    "\r\n",
    "n_grams = pd.Series(data=vocab_count_dict).sort_values(ascending=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "print(n_grams.shape[0], 'n-grams found')\r\n",
    "n_grams.head(10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "60689 n-grams found\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "the            4873\n",
       "and            4173\n",
       "in             3706\n",
       "of             2422\n",
       "company        1884\n",
       "is             1686\n",
       "a              1336\n",
       "to             1072\n",
       "the_company     999\n",
       "s               961\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### How do the results look? Can you improve the results by excluding common terms using the `common_terms` kwarg of `Phrases`?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "from sklearn.feature_extraction import stop_words\r\n",
    "\r\n",
    "phrases = Phrases(corpus, min_count=1, threshold=1, common_terms=stop_words.ENGLISH_STOP_WORDS)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "vocab_count_dict = {k.decode('utf8'): v for k, v in phrases.vocab.items()}\r\n",
    "n_grams = pd.Series(data=vocab_count_dict).sort_values(ascending=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "print(n_grams.shape[0], 'n-grams found')\r\n",
    "n_grams.head(10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "55985 n-grams found\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "company          1884\n",
       "s                 961\n",
       "american          498\n",
       "largest           453\n",
       "states            451\n",
       "united            443\n",
       "services          418\n",
       "united_states     393\n",
       "corporation       391\n",
       "products          360\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## This was convenient, but it's also a black box where many of the knobs for tuning are actually broken in the newest version. Let's try to create our own solution for finding n-grams.\r\n",
    "\r\n",
    "### To do this, let's start by counting unigrams and bigrams within our corpus"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tip: use Counter for easy counting. It behaves similar to a dictionary with some added functionality around counting. such as `my_counter[unknown_key]` returning `0` for all unknown keys"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "from collections import Counter\r\n",
    "\r\n",
    "unigram_count = Counter()\r\n",
    "bigram_count = Counter()\r\n",
    "for doc in corpus:\r\n",
    "    # your code here\r\n",
    "    n = len(doc)\r\n",
    "    for i in range(n-1):\r\n",
    "        unigram_count[doc[i]] += 1\r\n",
    "        bigram_count[doc[i]+' '+doc[i+1]] += 1\r\n",
    "    unigram_count[doc[n-1]] += 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now we need to come up with a score for each bigram that helps us decide on its importance and the fact of whether it is truly a bigram or two independent unigrams."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# your code here\r\n",
    "tf_idf = dict()\r\n",
    "n = wiki_df.shape[0]\r\n",
    "for token in bigram_count.keys():\r\n",
    "    max_tf = 0\r\n",
    "    df = 0\r\n",
    "    \r\n",
    "    for document in wiki_df['intro_text'].tolist():\r\n",
    "        \r\n",
    "        document = document.lower()\r\n",
    "        tf = document.count(token)/(len(document.split())-1)\r\n",
    "        if tf > 0: df += 1\r\n",
    "        max_tf = max(tf, max_tf)\r\n",
    "    \r\n",
    "    tf_idf[token] = max_tf*(np.log((1+n)/(1+df))+1)\r\n",
    "\r\n",
    "bigram_df = pd.DataFrame(tf_idf.items(), columns=['bigram','tf-idf'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "bigram_df.head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>tf-idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple inc</td>\n",
       "      <td>0.034528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inc is</td>\n",
       "      <td>0.121065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is an</td>\n",
       "      <td>0.147476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>an american</td>\n",
       "      <td>0.158072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>american multinational</td>\n",
       "      <td>0.282122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>multinational technology</td>\n",
       "      <td>0.077946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>technology company</td>\n",
       "      <td>0.122653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>company headquartered</td>\n",
       "      <td>0.192896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>headquartered in</td>\n",
       "      <td>0.145858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>in cupertino</td>\n",
       "      <td>0.010270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     bigram    tf-idf\n",
       "0                 apple inc  0.034528\n",
       "1                    inc is  0.121065\n",
       "2                     is an  0.147476\n",
       "3               an american  0.158072\n",
       "4    american multinational  0.282122\n",
       "5  multinational technology  0.077946\n",
       "6        technology company  0.122653\n",
       "7     company headquartered  0.192896\n",
       "8          headquartered in  0.145858\n",
       "9              in cupertino  0.010270"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Find ways to sort and filter your output to bigrams that make sense, such as `wells fargo`, `apple inc` or `puerto rico`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# your code here\r\n",
    "filtered_bigram_df = bigram_df[bigram_df['tf-idf']>0.01].sort_values(by=['tf-idf'], ascending=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "filtered_bigram_df.head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>tf-idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19817</th>\n",
       "      <td>marathon oil</td>\n",
       "      <td>0.747124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50072</th>\n",
       "      <td>reinsurance company</td>\n",
       "      <td>0.694280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50069</th>\n",
       "      <td>everest re</td>\n",
       "      <td>0.694280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50071</th>\n",
       "      <td>a reinsurance</td>\n",
       "      <td>0.694280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29985</th>\n",
       "      <td>in hamilton</td>\n",
       "      <td>0.653733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49739</th>\n",
       "      <td>b2b it</td>\n",
       "      <td>0.631164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49738</th>\n",
       "      <td>provides b2b</td>\n",
       "      <td>0.631164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49911</th>\n",
       "      <td>alexandria real</td>\n",
       "      <td>0.631164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49912</th>\n",
       "      <td>estate equities</td>\n",
       "      <td>0.631164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49913</th>\n",
       "      <td>equities is</td>\n",
       "      <td>0.631164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    bigram    tf-idf\n",
       "19817         marathon oil  0.747124\n",
       "50072  reinsurance company  0.694280\n",
       "50069           everest re  0.694280\n",
       "50071        a reinsurance  0.694280\n",
       "29985          in hamilton  0.653733\n",
       "49739               b2b it  0.631164\n",
       "49738         provides b2b  0.631164\n",
       "49911      alexandria real  0.631164\n",
       "49912      estate equities  0.631164\n",
       "49913          equities is  0.631164"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Problem 2: Word vectors via Pointwise Mutual Information (PMI)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### In this problem we will investigate another way of creating word representation from word co-occurrences. For this we will create a word-word matrix that counts the number of times that two words appear close to each other.\n",
    "\n",
    "## More formally:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The pointwise mutual information (PMI) for a (word, context) pair in a corpus is defined as the probability of their co-occurrence divided by the probabilities of them appearing individually, \r\n",
    "## $$\r\n",
    "{\\rm pmi}(w, c) = \\log \\frac{p(w, c)}{p(w) p(c)}\r\n",
    "$$\r\n",
    "\r\n",
    "## $$\r\n",
    "p(w, c) = \\frac{\r\n",
    "f_{i,j}\r\n",
    "}{\r\n",
    "\\sum_{i=1}^N \\sum_{j=1}^N f_{i,j}\r\n",
    "}, \\quad \r\n",
    "p(w) = \\frac{\r\n",
    "\\sum_{j=1}^N f_{i,j}\r\n",
    "}{\r\n",
    "\\sum_{i=1}^N \\sum_{j=1}^N f_{i,j}\r\n",
    "}, \\quad\r\n",
    "p(c) = \\frac{\r\n",
    "\\sum_{i=1}^N f_{i,j}\r\n",
    "}{\r\n",
    "\\sum_{i=1}^N \\sum_{j=1}^N f_{i,j}\r\n",
    "}\r\n",
    "$$\r\n",
    "### where $f_{i,j}$ is the word-word count matrix. <br />\r\n",
    "### In addition we can define the positive pointwise mutual information as, \r\n",
    "## $$\r\n",
    "{\\rm ppmi}(w, c) = {\\rm max}\\left[{\\rm pmi(w,c)}, 0 \\right]\r\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## We will implement this on our wiki featured articles dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "wiki_feat_df = pd.read_csv('./data/kdwd_featured_articles.csv')\r\n",
    "wiki_feat_df.sample(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_id</th>\n",
       "      <th>page_title</th>\n",
       "      <th>page_views</th>\n",
       "      <th>intro_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4645</th>\n",
       "      <td>23325915</td>\n",
       "      <td>Byzantine civil war of 1341–1347</td>\n",
       "      <td>932</td>\n",
       "      <td>The Byzantine civil war of 1341–1347, sometime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>2072335</td>\n",
       "      <td>Lambeosaurus</td>\n",
       "      <td>1232</td>\n",
       "      <td>'Lambeosaurus' ( ; meaning \"Lambe's lizard\") i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>339877</td>\n",
       "      <td>Simeon I of Bulgaria</td>\n",
       "      <td>2458</td>\n",
       "      <td>Tsar Simeon (also Symeon) I the Great (, trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>161190</td>\n",
       "      <td>Star Trek VI: The Undiscovered Country</td>\n",
       "      <td>8021</td>\n",
       "      <td>'Star Trek VI: The Undiscovered Country' is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5383</th>\n",
       "      <td>41908173</td>\n",
       "      <td>Streatham portrait</td>\n",
       "      <td>443</td>\n",
       "      <td>The \"Streatham\" portrait is an oil painting on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_id                              page_title  page_views  \\\n",
       "4645  23325915        Byzantine civil war of 1341–1347         932   \n",
       "2632   2072335                            Lambeosaurus        1232   \n",
       "1385    339877                    Simeon I of Bulgaria        2458   \n",
       "895     161190  Star Trek VI: The Undiscovered Country        8021   \n",
       "5383  41908173                      Streatham portrait         443   \n",
       "\n",
       "                                             intro_text  \n",
       "4645  The Byzantine civil war of 1341–1347, sometime...  \n",
       "2632  'Lambeosaurus' ( ; meaning \"Lambe's lizard\") i...  \n",
       "1385  Tsar Simeon (also Symeon) I the Great (, trans...  \n",
       "895   'Star Trek VI: The Undiscovered Country' is a ...  \n",
       "5383  The \"Streatham\" portrait is an oil painting on...  "
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "corpus = wiki_feat_df['intro_text'].tolist()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "def get_tokens(text):\r\n",
    "    token_pattern = r\"\\b\\w\\w+\\\\?'?s?(?:-\\w+)?\\b\"\r\n",
    "    return re.findall(token_pattern, text.lower())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "from collections import Counter"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "unigram_counts = Counter()\r\n",
    "for doc in corpus:\r\n",
    "    # your code here\r\n",
    "    tokens = get_tokens(doc)\r\n",
    "    for word in tokens:\r\n",
    "        unigram_counts[word] += 1\r\n",
    "vocab = {token: n for n, token in enumerate(pd.Series(unigram_counts).sort_values().index)}\r\n",
    "inv_vocab = {v: k for k, v in vocab.items()}\r\n",
    "print('vocabulary size: {}'.format(len(unigram_counts)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "vocabulary size: 72750\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Skip-grams are a generalization of n-grams: https://en.wikipedia.org/wiki/N-gram#Skip-gram\n",
    "### We will use this term here to find pairs of word within a context window, meaning that all words separated by max N words will be considered a bigram"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# use skip-2-grams and context length 2 in each direction\r\n",
    "word_window_len = 2\r\n",
    "skipgram_counts = Counter()\r\n",
    "for doc in corpus:\r\n",
    "    tokens = get_tokens(doc)\r\n",
    "    for token_idx, token in enumerate(tokens):\r\n",
    "        for context_token in tokens[token_idx - word_window_len:token_idx + word_window_len]:\r\n",
    "            if token != context_token:\r\n",
    "                skipgram_counts[(vocab[token], vocab[context_token])] += 1\r\n",
    "print('number of skipgrams:', len(skipgram_counts))\r\n",
    "print('most common:')\r\n",
    "\r\n",
    "[((inv_vocab[t1], inv_vocab[t2]), v) for (t1, t2), v in skipgram_counts.most_common(5)]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of skipgrams: 1981470\n",
      "most common:\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(('of', 'the'), 42125),\n",
       " (('the', 'of'), 23088),\n",
       " (('in', 'the'), 18020),\n",
       " (('the', 'in'), 17652),\n",
       " (('and', 'the'), 11390)]"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now let's create a sparse matrix that contains word-word co-occurrence counts"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "from scipy import sparse as ssp\r\n",
    "\r\n",
    "row_indxs = []\r\n",
    "col_indxs = []\r\n",
    "dat_values = []\r\n",
    "\r\n",
    "\r\n",
    "# your code here\r\n",
    "row_indxs = [t1 for (t1, t2), v in skipgram_counts.items()]\r\n",
    "col_indxs = [t2 for (t1, t2), v in skipgram_counts.items()]\r\n",
    "dat_values = [v for (t1, t2), v in skipgram_counts.items()]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "wwcnt_mat = ssp.csr_matrix((dat_values, (row_indxs, col_indxs)))\n",
    "wwcnt_mat"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<72750x72750 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 1981470 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Next, create the PPMI matrix"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# reusable quantities\n",
    "num_skipgrams = wwcnt_mat.sum()\n",
    "sum_over_words = np.array(wwcnt_mat.sum(axis=0)).flatten()\n",
    "sum_over_contexts = np.array(wwcnt_mat.sum(axis=1)).flatten()\n",
    "\n",
    "ppmi_dat_values = []   # positive pointwise mutial information\n",
    "row_indxs = []  # for creating sparce matrices\n",
    "col_indxs = []  # for creating sparce matrices\n",
    "for (tok_word, tok_context), sg_count in skipgram_counts.items():\n",
    "\n",
    "    nwc = sg_count\n",
    "    Pwc = nwc / num_skipgrams\n",
    "    nw = sum_over_words[tok_word]\n",
    "    Pw = nw / num_skipgrams\n",
    "    nc = sum_over_words[tok_context]\n",
    "    Pc = nc / num_skipgrams\n",
    "    \n",
    "    pmi = np.log2(Pwc / (Pw * Pc))   \n",
    "    ppmi = max(pmi, 0)\n",
    "    \n",
    "    row_indxs.append(tok_word)\n",
    "    col_indxs.append(tok_context)\n",
    "    ppmi_dat_values.append(ppmi)\n",
    "\n",
    "ppmi_mat = ssp.csr_matrix((ppmi_dat_values, (row_indxs, col_indxs)))\n",
    "ppmi_mat"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<72750x72750 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1981470 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use `ppmi_mat` to investigate the most similar values to a few test terms."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# to speed up calculation we do dimentionality reduction here\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=64, random_state=6006)\n",
    "trafo_ppmi_mat = svd.fit_transform(ppmi_mat)\n",
    "sim_mat = cosine_similarity(trafo_ppmi_mat)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "MemoryError",
     "evalue": "Unable to allocate 39.4 GiB for an array with shape (72750, 72750) and data type float64",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-8d67db13980c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msvd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTruncatedSVD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6006\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrafo_ppmi_mat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mppmi_mat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0msim_mat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrafo_ppmi_mat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m     K = safe_sparse_dot(X_normalized, Y_normalized.T,\n\u001b[1;32m-> 1188\u001b[1;33m                         dense_output=dense_output)\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 39.4 GiB for an array with shape (72750, 72750) and data type float64"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "token = 'eminem'\n",
    "# print most similar terms\n",
    "word_idx = vocab[token]\n",
    "for idx, row in pd.Series(sim_mat[word_idx]).sort_values(ascending=False).head(10).iteritems():\n",
    "    print('%.3f' % row, inv_vocab[idx])"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'sim_mat' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-7dfe6e1e17c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# print most similar terms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mword_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim_mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%.3f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minv_vocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sim_mat' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "token = 'quantum'\n",
    "# print most similar terms\n",
    "word_idx = vocab[token]\n",
    "for idx, row in pd.Series(sim_mat[word_idx]).sort_values(ascending=False).head(10).iteritems():\n",
    "    print('%.3f' % row, inv_vocab[idx])"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'sim_mat' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-244d8cb2110b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# print most similar terms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mword_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim_mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%.3f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minv_vocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sim_mat' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## In what way do these embeddings differ the TfIdf based ones we covered in class? Can you think of advantages/disadvantages for each approach?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Your answer here!\n",
    "print('The difference between these embeddings and TfIdf is that these embeddings find similar terms by cosine similarity, while TfIdf based ones do that by word counting. The advantage of cosine similarity is that it can find out the relationship among different words, which is the disadvantage of TfIdf based ones since they focus on word counting. The disadvantage of these embeddings is that it requires huge amount and types of data/words to calculate the relationship, while TfIdf based ones do not need.')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Problem 3: Word vectors for different domains\n",
    "\n",
    "\n",
    "### In this problem we will creat embeddings for the `intro_text` column of the datasets `kdwd_featured_articles.csv` and `kdwd_r1k_articles.csv`\n",
    "### We can think of these as examples of 'generic' and 'finance specific' word representations\n",
    "\n",
    "## The goal of this exercise is to compare these two representations and find out which words change meaning the most across these two domains"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "import scipy.sparse as ssp\r\n",
    "from scipy.sparse import csr_matrix\r\n",
    "import pandas as pd\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "generic_df = pd.read_csv('./data/kdwd_featured_articles.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "finance_df = pd.read_csv('./data/kdwd_r1k_articles.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create word representation for our 2 corpora using your favorite method"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "vectorizer = TfidfVectorizer(min_df=3, max_df=1.0)\r\n",
    "generic_mat = vectorizer.fit_transform(generic_df['intro_text'].tolist())\r\n",
    "generic_vocab = {token: n for n, token in enumerate(pd.Series(vectorizer.vocabulary_).sort_values().index)}\r\n",
    "\r\n",
    "vectorizer = TfidfVectorizer(min_df=3, max_df=1.0)\r\n",
    "finance_mat = vectorizer.fit_transform(finance_df['intro_text'].tolist())\r\n",
    "finance_vocab = {token: n for n, token in enumerate(pd.Series(vectorizer.vocabulary_).sort_values().index)}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Since our two corpora use different vocabulary we want to sub-select each representation matrix to be only of vacabulary tokens that occur in both corpora"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "common_terms = list(set(generic_vocab) & set(finance_vocab))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "filtered_generic_mat = []\r\n",
    "filtered_finance_mat = []\r\n",
    "\r\n",
    "# your code here\r\n",
    "for word in common_terms:\r\n",
    "    filtered_generic_mat.append(generic_mat[:,generic_vocab[word]])\r\n",
    "    filtered_finance_mat.append(finance_mat[:,finance_vocab[word]])\r\n",
    "\r\n",
    "filtered_generic_mat = ssp.hstack(filtered_generic_mat)\r\n",
    "filtered_finance_mat = ssp.hstack(filtered_finance_mat)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Our documents for each corpus are different so there is no direct way of comparing our two representations, even though they now have the same dimension. To get them on equal footing, let's look at the word-word similarlity matrix for each domain.\r\n",
    "### Comparing these two, find terms that seem to have a drastically different meaning within the two domains."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# get the term-term similarity matrix\r\n",
    "generic_term_sim_mat = cosine_similarity(filtered_generic_mat.T)\r\n",
    "finance_term_sim_mat = cosine_similarity(filtered_finance_mat.T)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "term_drift_scores = {}\r\n",
    "for n, term in enumerate(common_terms):\r\n",
    "    term_sim = cosine_similarity([generic_term_sim_mat[n]],[finance_term_sim_mat[n]])\r\n",
    "    term_drift_scores[term] = term_sim"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "term_drifts = pd.Series(term_drift_scores).sort_values()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "term_drifts.head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "highway            [[0.24520438464636277]]\n",
       "staffing            [[0.2871955698477838]]\n",
       "written             [[0.2912808573896264]]\n",
       "pharmaceuticals    [[0.29643837015355917]]\n",
       "formula            [[0.29802407875828485]]\n",
       "fruit              [[0.29827656395060986]]\n",
       "king               [[0.29960946318389897]]\n",
       "preferred          [[0.30167333531360996]]\n",
       "proved              [[0.3026852090127874]]\n",
       "won                [[0.30302971798690137]]\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "term_drifts.tail(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "for     [[0.8114789418584171]]\n",
       "its     [[0.8152663255658184]]\n",
       "with    [[0.8206452301148983]]\n",
       "and     [[0.8304891735052484]]\n",
       "in      [[0.8319360747475575]]\n",
       "as       [[0.833800459880701]]\n",
       "by      [[0.8361606478193372]]\n",
       "of      [[0.8423985374468572]]\n",
       "the     [[0.8526193824575488]]\n",
       "to      [[0.8538485132645217]]\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Problem 4: Corporate Similarity and Returns\n",
    "### In this example we'll explore how to use NLP to measure corporate similarity\n",
    "\n",
    "### In particular we will\n",
    " - ### Make word vectors for firms in order to get an NLP measure of similarity\n",
    " - ### Measure the quality of this similarity metric by predicting future co-movement of returns. \n",
    " \n",
    "## Step X: This problem uses a few concepts of basic modeling such as `sklearn.model_selection.train_test_split` and `sklearn.linear_model.LinearRegression`\n",
    "## Feel free to read some of the sklearn documentation, but otherwise we will cover these concepts next class\n",
    " \n",
    "\n",
    "# $ \\\\ $\n",
    "## Step 0: Load the MD&A section from Form-10-K from 2016"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open('parsed_mda.json') as f:\r\n",
    "    data = json.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Next, take only the first filing for each company"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clean = []\r\n",
    "seen = set()\r\n",
    "for item in data:\r\n",
    "    if item['ticker'] in seen:\r\n",
    "        continue\r\n",
    "    else:\r\n",
    "        seen.add(item['ticker'])\r\n",
    "        clean.append(item)\r\n",
    "data = clean\r\n",
    "del clean"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now load the price data for 2015-2018"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prices = pd.read_csv(\r\n",
    "    'sp500_prices.csv', \r\n",
    "    index_col=0, \r\n",
    "    parse_dates=True\r\n",
    ").loc['2015-01-01':'2018-01-01']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prices.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_tickers = [item['ticker'] for item in data]\n",
    "assert len(data_tickers) == len(set(data_tickers)), 'non-unique tickers, this will not work'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: clean the text\n",
    "### Much of NLP boils down to doing reasonable processing on text.\n",
    "### First, we'll try out very minimial processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def clean_mda_simple(mda):\n",
    "    return mda.lower()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# add import here\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vectorizer = CountVectorizer()\n",
    "word_lower = []\n",
    "for item in data:\n",
    "    word_lower.append(clean_mda_simple(item['mda']))\n",
    "word_vecs = vectorizer.fit_transform(word_lower)\n",
    "vocab = {token: n for n, token in enumerate(pd.Series(vectorizer.vocabulary_).sort_values().index)}\n",
    "inv_vocab = {v: k for k, v in vocab.items()}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Pairwise Word similarity\n",
    "### Calculate the pariwise cosine similarity between word vectors\n",
    "### Make the cosine similarities into a dataframe indexed/columned on ticker symbols"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "word_sims = cosine_similarity(word_vecs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.DataFrame(word_sims, index = data_tickers, columns = data_tickers)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2a: Why `cosine_similarity` and not another measure?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ANSWER GOES HERE\n",
    "print(\"cosine_similarity produces results with absolute value equal or smaller than 1, which are easy to understand and compare.\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Wrangle the price and word data\n",
    "### Our goal here is to have a dataframe which is indexed on PAIRS of tickers and has columns\n",
    " - ### `returns_correlation`: the correlation of returns for those two tickers from Jan 1 2016 to Jan 1 2017\n",
    " - ### `word_similarity`: the cosine similarity of the word vectors for the two companies' MD&A sections\n",
    " \n",
    "## Tips\n",
    " - ### NB: use pct_change to calculate returns in pandas\n",
    " - ### NB: use the pandas builtin corr function to calculate correlations (we don't need anything fancy)\n",
    " - ### NB: the index of the dataframe should have two columns (the tickers)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# one way you might do this is\n",
    "rets = prices.pct_change()\n",
    "rets = rets.loc['2016-01-01':'2017-01-01']\n",
    "rets_cor = rets.corr().stack().to_frame(name = 'returns_correlation') # calculate returns correlations\n",
    "word_cor = df.stack()#  calcuate the word similarities in the right shape\n",
    "word_cor.name = 'word_similarity'\n",
    "all_data = rets_cor.join(word_cor)\n",
    "all_data = all_data.dropna()\n",
    "all_data.head()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'prices' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-961acf5ff038>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# one way you might do this is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpct_change\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mrets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'2016-01-01'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'2017-01-01'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrets_cor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'returns_correlation'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# calculate returns correlations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mword_cor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#  calcuate the word similarities in the right shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prices' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3a: \n",
    " - ### What is the contemperaneous correlation of these data?\n",
    " - ### Make a scatter plot of the returns correlation and word similarities"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "all_data.corr()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## This should be about 12%. That's not bad, but we can do better"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "all_data.plot.scatter(x='returns_correlation', y='word_similarity')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 4: Try to predict the future returns correlations\n",
    "### Use OLS (`LinearRegression`) to predict `returns_correlation` from `word_similarity`. \n",
    "### What is the (contemperaneous) out of sample performance?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "data_df = np.array(all_data)\n",
    "feature_cols = data_df[:,1:]\n",
    "target_col = data_df[:,0]"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'all_data' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-51bfd9f6a2b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfeature_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtarget_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_data' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# add code here\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg = linear_model.LinearRegression()# add code here\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_cols,target_col,test_size=0.4, random_state=0)\n",
    "\n",
    "reg.fit(X_train, y_train)\n",
    "reg.score(X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#pd.Series(reg.coef_, index=feature_cols)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### This is not amazing. We can do better!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## $ \\\\ $ "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 5: Repeat, but be careful\n",
    "### Here we will see if we can clean the data better\n",
    "\n",
    "### Things to try\n",
    " - ### Look at the histograms of word similarities to see if we can \"ignore\" some ill-behaved data\n",
    " - ### Try limiting how greedy the `TFIDFVectorizer` is: `min_df`, `max_df`, `max_features`, etc.\n",
    " \n",
    "### We will examine our data and look for things that look out of place\n",
    " - ### We will ultimately want our data to look normally distributed\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def clean_mda(mda):\n",
    "    paras = [p.lower() for p in mda.split('\\n') if len(p) > 40]\n",
    "    cleaned =  ' '.join(paras)\n",
    "    words = cleaned.split()\n",
    "    words = [word for word in words if len(word) > 2]\n",
    "    if len(words) > 10:\n",
    "        return ' '.join(words)\n",
    "    else:\n",
    "        return ''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec = TfidfVectorizer(\n",
    "    min_df = 3,\n",
    "    max_df = 1.0,\n",
    "    max_features= None\n",
    ")\n",
    "word_vecs = vec.fit_transform((clean_mda(item['mda']) for item in data))\n",
    "\n",
    "vocab = {token: n for n, token in enumerate(pd.Series(vec.vocabulary_).sort_values().index)}\n",
    "inv_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "word_sims =  cosine_similarity(word_vecs)\n",
    "# Lots of word similarities are all zeros- so we'll ignore\n",
    "# add code here to remove rows of word_sims where all the elements are zero\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# calculate the returns correlation and the cosine similarities as above\n",
    "word_cor_wo_zero = df_wo_zero.stack()#  calcuate the word similarities in the right shape\n",
    "word_cor_wo_zero.name = 'word_similarity'\n",
    "all_data = rets_cor.join(word_cor_wo_zero)\n",
    "all_data = all_data.dropna()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_wo_zero' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-8fc35df5d9ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# calculate the returns correlation and the cosine similarities as above\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mword_cor_wo_zero\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_wo_zero\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#  calcuate the word similarities in the right shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mword_cor_wo_zero\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'word_similarity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mall_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrets_cor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_cor_wo_zero\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mall_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_wo_zero' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# inspect your data- make some histograms\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,7))\n",
    "all_data.returns_correlation.hist(bins=40)\n",
    "plt.title('Returns Correlation')\n",
    "plt.figure(figsize=(12,7))\n",
    "all_data.word_similarity.hist(bins=40)\n",
    "plt.title('Word Similarity')"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'all_data' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4fac2001cf5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mall_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturns_correlation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Returns Correlation'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_data' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cleaning our data\n",
    "### It seems lots of things are identically 0 (no word overlap) or identically 1 (the MD&A section for one company perfectly overlaps itself). We will exclude those"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# your code here\n",
    "all_data = all_data[(all_data['word_similarity'] < 1) & (all_data['word_similarity'] > 0)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# examine histograms again\n",
    "plt.figure(figsize=(12,7))\n",
    "all_data.returns_correlation.hist(bins=40)\n",
    "plt.title('Returns Correlation')\n",
    "plt.figure(figsize=(12,7))\n",
    "all_data.word_similarity.hist(bins=40)\n",
    "plt.title('Word Similarity')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "all_data.corr()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Lastly, there is a bit of a \"hump\" at low `word_similarity`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# add code here\n",
    "all_data = all_data[(all_data['word_similarity'] > 0.6)]\n",
    "all_data.corr()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The contemperaneous correlation is twice as large!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 6: Now, repeat the exercise of predicting future returns correlation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_df = np.array(all_data)# Add code here\n",
    "# add code here\n",
    "feature_cols = data_df[:,1:]\n",
    "target_col = data_df[:,0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_cols,target_col,test_size=0.4, random_state=0)\n",
    "\n",
    "reg.fit(X_train, y_train)\n",
    "reg.score(X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#pd.Series(reg.coef_, index=feature_cols)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### This is about 5 times better than before!\n",
    "## $ \\\\ $ \n",
    "## Part 7: What will happen if we include last year's returns correlation as a feature"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rets = prices.pct_change()\n",
    "last_year_corr =  rets.loc['2015-01-01':'2016-01-01'].corr().stack().to_frame(name = 'last_year_returns_correlation')\n",
    "data_df = last_year_corr.join(all_data)\n",
    "data_df = data_df.dropna()\n",
    "data_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_df = np.array(data_df)\n",
    "feature_cols = data_df[:, [0,2]]\n",
    "target_col = data_df[:, 1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_cols, target_col, test_size=0.33, random_state=42)\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "reg.score(X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "reg.coef_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#pd.Series(reg.coef_, index=feature_cols)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Indeed, we do much better, but the word features still help!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}