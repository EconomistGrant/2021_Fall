{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Word phrases\n",
    "\n",
    "### In this problem we will look at methods to identify valid n-grams such as 'New York' or 'Barack Obama' while eliminating statistical flukes such as `in the` or `i write`.\n",
    "\n",
    "### Preprocessing such as this can drastically improved embeddings since words can ngrams will often have a different meaning than the sum of its parts\n",
    "### `V('united')` + `V('states')` != `V('united states')`\n",
    "### `V('real')` + `V('estate')` != `V('real estate')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df = pd.read_csv('/Users/mac/Desktop/MFin Materials/15.S08/data/kdwd_r1k_articles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get consecutive unigrams for the 'intro_text' column of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of lists of unigrams\n",
    "unigram_pattern = r'[a-z0-9]+'\n",
    "corpus = [re.findall(unigram_pattern, doc.lower()) for doc in wiki_df['intro_text'].tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The package `gensim` has a convenient wrapper to obtain statistically significant ngrams/Phrase automatically\n",
    "\n",
    "### we need to first `pip install gensim`\n",
    "### `gensim` is a useful library for anything related to word representations and embeddings. It will come up a few more times. https://radimrehurek.com/gensim/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write some code to parse our corpus and use valid ngrams using `Phrases`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = Phrases(corpus, min_count=1, threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the                    4873\n",
       "and                    4173\n",
       "in                     3706\n",
       "of                     2422\n",
       "company                1884\n",
       "                       ... \n",
       "nxp_semiconductors        1\n",
       "17_3                      1\n",
       "of_17                     1\n",
       "total_value               1\n",
       "prismacolor_rotring       1\n",
       "Length: 60689, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_count_dict = {k.decode('utf8'): v for k, v in phrases.vocab.items()}\n",
    "\n",
    "n_grams = pd.Series(data=vocab_count_dict).sort_values(ascending=False)\n",
    "n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60689 n-grams found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "the            4873\n",
       "and            4173\n",
       "in             3706\n",
       "of             2422\n",
       "company        1884\n",
       "is             1686\n",
       "a              1336\n",
       "to             1072\n",
       "the_company     999\n",
       "s               961\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(n_grams.shape[0], 'n-grams found')\n",
    "n_grams.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do the results look? Can you improve the results by excluding common terms using the `common_terms` kwarg of `Phrases`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import stop_words\n",
    "\n",
    "phrases = Phrases(corpus, min_count=1, threshold=1, common_terms=stop_words.ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_count_dict = {k.decode('utf8'): v for k, v in phrases.vocab.items()}\n",
    "\n",
    "n_grams = pd.Series(data=vocab_count_dict).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55985 n-grams found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "company          1884\n",
       "s                 961\n",
       "american          498\n",
       "largest           453\n",
       "states            451\n",
       "united            443\n",
       "services          418\n",
       "united_states     393\n",
       "corporation       391\n",
       "products          360\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(n_grams.shape[0], 'n-grams found')\n",
    "n_grams.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This was convenient, but it's also a black box where many of the knobs for tuning are actually broken in the newest version. Let's try to create our own solution for finding n-grams.\n",
    "\n",
    "### To do this, let's start by counting unigrams and bigrams within our corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tip: use Counter for easy counting. It behaves similar to a dictionary with some added functionality around counting. such as `my_counter[unknown_key]` returning `0` for all unknown keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "unigram_counter = Counter()\n",
    "bigram_counter = Counter()\n",
    "for tokens in corpus:\n",
    "    # your code here\n",
    "    n = len(tokens)\n",
    "    for i in range(n-1):\n",
    "        unigram_counter[tokens[i]] += 1\n",
    "        bigram_counter[tokens[i]+' '+tokens[i+1]] += 1\n",
    "    unigram_counter[tokens[n-1]] += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we need to come up with a score for each bigram that helps us decide on its importance and the fact of whether it is truly a bigram or two independent unigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0055248618784530384 3 761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'apple inc': 0.03452846516335224,\n",
       " 'inc is': 0.12106460439641134,\n",
       " 'is an': 0.14747558178580406,\n",
       " 'an american': 0.15807206254999143,\n",
       " 'american multinational': 0.28212246023030824,\n",
       " 'multinational technology': 0.07794570420042922,\n",
       " 'technology company': 0.12265325449667411,\n",
       " 'company headquartered': 0.19289633699982672,\n",
       " 'headquartered in': 0.14585797257749325,\n",
       " 'in cupertino': 0.010270413276814647,\n",
       " 'cupertino california': 0.0,\n",
       " 'california that': 0.10214421429241603,\n",
       " 'that designs': 0.08881103286032148,\n",
       " 'designs develops': 0.0,\n",
       " 'develops and': 0.08140726810759044,\n",
       " 'and sells': 0.1412209683117795,\n",
       " 'sells consumer': 0.13074668534037073,\n",
       " 'consumer electronics': 0.20152369263650313,\n",
       " 'electronics computer': 0.0,\n",
       " 'computer software': 0.08255491292126775,\n",
       " 'software and': 0.15638358588400686,\n",
       " 'and online': 0.08680072492453828,\n",
       " 'online services': 0.020540826553629293,\n",
       " 'services it': 0.0,\n",
       " 'it is': 0.10570894149594955,\n",
       " 'is considered': 0.07486890008725437,\n",
       " 'considered one': 0.010270413276814647,\n",
       " 'one of': 0.0907876141204401,\n",
       " 'of the': 0.06938707993858191,\n",
       " 'the big': 0.059032192792511026,\n",
       " 'big four': 0.09207513052138784,\n",
       " 'four tech': 0.010270413276814647,\n",
       " 'tech companies': 0.010270413276814647,\n",
       " 'companies along': 0.024302357869957384,\n",
       " 'along with': 0.06858296500521079,\n",
       " 'with amazon': 0.010270413276814647,\n",
       " 'amazon google': 0.0,\n",
       " 'google and': 0.05934016559937352,\n",
       " 'and facebook': 0.010270413276814647,\n",
       " 'facebook the': 0.0,\n",
       " 'the company': 0.08653287475195577,\n",
       " 'company s': 0.12841115690546553,\n",
       " 's hardware': 0.0489960052296955,\n",
       " 'hardware products': 0.014150074171035793,\n",
       " 'products include': 0.08125023131823396,\n",
       " 'include the': 0.06584396867521729,\n",
       " 'the iphone': 0.03611786887855545,\n",
       " 'iphone smartphone': 0.010270413276814647,\n",
       " 'smartphone the': 0.0,\n",
       " 'the ipad': 0.010270413276814647,\n",
       " 'ipad tablet': 0.010270413276814647,\n",
       " 'tablet computer': 0.014150074171035793,\n",
       " 'computer the': 0.0,\n",
       " 'the mac': 0.031130163176278747,\n",
       " 'mac personal': 0.010270413276814647,\n",
       " 'personal computer': 0.08537635203146926,\n",
       " 'the ipod': 0.010270413276814647,\n",
       " 'ipod portable': 0.010270413276814647,\n",
       " 'portable media': 0.010270413276814647,\n",
       " 'media player': 0.03081123983044394,\n",
       " 'player the': 0.0,\n",
       " 'the apple': 0.03081123983044394,\n",
       " 'apple watch': 0.010270413276814647,\n",
       " 'watch smartwatch': 0.010270413276814647,\n",
       " 'smartwatch the': 0.0,\n",
       " 'apple tv': 0.020540826553629293,\n",
       " 'tv digital': 0.010270413276814647,\n",
       " 'digital media': 0.010270413276814647,\n",
       " 'the airpods': 0.010270413276814647,\n",
       " 'airpods wireless': 0.010270413276814647,\n",
       " 'wireless earbuds': 0.010270413276814647,\n",
       " 'earbuds and': 0.010270413276814647,\n",
       " 'and the': 0.12376161682252462,\n",
       " 'the homepod': 0.010270413276814647,\n",
       " 'homepod smart': 0.010270413276814647,\n",
       " 'smart speaker': 0.010270413276814647,\n",
       " 'speaker apple': 0.0,\n",
       " 'apple s': 0.04108165310725859,\n",
       " 's software': 0.12638771609553764,\n",
       " 'software includes': 0.010270413276814647,\n",
       " 'includes the': 0.09057466948647472,\n",
       " 'the macos': 0.010270413276814647,\n",
       " 'macos ios': 0.0,\n",
       " 'ios ipados': 0.0,\n",
       " 'ipados watchos': 0.0,\n",
       " 'watchos and': 0.0,\n",
       " 'and tvos': 0.010270413276814647,\n",
       " 'tvos operating': 0.010270413276814647,\n",
       " 'operating systems': 0.019112086221916683,\n",
       " 'systems the': 0.0,\n",
       " 'the itunes': 0.03081123983044394,\n",
       " 'itunes media': 0.010270413276814647,\n",
       " 'the safari': 0.010270413276814647,\n",
       " 'safari web': 0.010270413276814647,\n",
       " 'web browser': 0.014150074171035793,\n",
       " 'browser the': 0.0,\n",
       " 'the shazam': 0.010270413276814647,\n",
       " 'shazam acoustic': 0.010270413276814647,\n",
       " 'acoustic fingerprint': 0.010270413276814647,\n",
       " 'fingerprint utility': 0.010270413276814647,\n",
       " 'utility and': 0.055101582342275406,\n",
       " 'the ilife': 0.010270413276814647,\n",
       " 'ilife and': 0.010270413276814647,\n",
       " 'and iwork': 0.010270413276814647,\n",
       " 'iwork creativity': 0.010270413276814647,\n",
       " 'creativity and': 0.010270413276814647,\n",
       " 'and productivity': 0.02583926587754362,\n",
       " 'productivity suites': 0.010270413276814647,\n",
       " 'suites as': 0.0,\n",
       " 'as well': 0.07634728265160434,\n",
       " 'well as': 0.0783248139468232,\n",
       " 'as professional': 0.010270413276814647,\n",
       " 'professional applications': 0.010270413276814647,\n",
       " 'applications like': 0.010270413276814647,\n",
       " 'like final': 0.010270413276814647,\n",
       " 'final cut': 0.010270413276814647,\n",
       " 'cut pro': 0.010270413276814647,\n",
       " 'pro logic': 0.0,\n",
       " 'logic pro': 0.010270413276814647,\n",
       " 'pro and': 0.0,\n",
       " 'and xcode': 0.010270413276814647,\n",
       " 'xcode its': 0.0,\n",
       " 'its online': 0.04734584995883906,\n",
       " 'services include': 0.09177478075211827,\n",
       " 'itunes store': 0.020540826553629293,\n",
       " 'store the': 0.0,\n",
       " 'the ios': 0.010270413276814647,\n",
       " 'ios app': 0.010270413276814647,\n",
       " 'app store': 0.020540826553629293,\n",
       " 'store mac': 0.0,\n",
       " 'mac app': 0.010270413276814647,\n",
       " 'store apple': 0.0,\n",
       " 'apple music': 0.010270413276814647,\n",
       " 'music apple': 0.0,\n",
       " 'tv imessage': 0.0,\n",
       " 'imessage and': 0.0,\n",
       " 'and icloud': 0.010270413276814647,\n",
       " 'icloud other': 0.0,\n",
       " 'other services': 0.03495900677550019,\n",
       " 'include apple': 0.010270413276814647,\n",
       " 'apple store': 0.020540826553629293,\n",
       " 'store genius': 0.0,\n",
       " 'genius bar': 0.010270413276814647,\n",
       " 'bar applecare': 0.0,\n",
       " 'applecare apple': 0.0,\n",
       " 'apple pay': 0.020540826553629293,\n",
       " 'pay apple': 0.0,\n",
       " 'pay cash': 0.010270413276814647,\n",
       " 'cash and': 0.041277456460633875,\n",
       " 'and apple': 0.07440062136388995,\n",
       " 'apple card': 0.010270413276814647,\n",
       " 'card apple': 0.0,\n",
       " 'apple was': 0.010270413276814647,\n",
       " 'was founded': 0.08905642685437079,\n",
       " 'founded by': 0.06491981682326486,\n",
       " 'by steve': 0.0484469162369516,\n",
       " 'steve jobs': 0.03611786887855545,\n",
       " 'jobs steve': 0.0,\n",
       " 'steve wozniak': 0.010270413276814647,\n",
       " 'wozniak and': 0.0,\n",
       " 'and ronald': 0.010270413276814647,\n",
       " 'ronald wayne': 0.010270413276814647,\n",
       " 'wayne in': 0.010270413276814647,\n",
       " 'in april': 0.06592642881818575,\n",
       " 'april 1976': 0.010270413276814647,\n",
       " '1976 to': 0.010270413276814647,\n",
       " 'to develop': 0.032288326444522605,\n",
       " 'develop and': 0.11816683614220679,\n",
       " 'and sell': 0.13883038856488522,\n",
       " 'sell wozniak': 0.010270413276814647,\n",
       " 'wozniak s': 0.0,\n",
       " 's apple': 0.02090184680457109,\n",
       " 'apple i': 0.055470285750592506,\n",
       " 'i personal': 0.010270413276814647,\n",
       " 'computer though': 0.0,\n",
       " 'though wayne': 0.010270413276814647,\n",
       " 'wayne sold': 0.010270413276814647,\n",
       " 'sold his': 0.0688140449159846,\n",
       " 'his share': 0.010270413276814647,\n",
       " 'share back': 0.010270413276814647,\n",
       " 'back within': 0.010270413276814647,\n",
       " 'within 12': 0.010270413276814647,\n",
       " '12 days': 0.010270413276814647,\n",
       " 'days it': 0.0,\n",
       " 'it was': 0.20871318534036792,\n",
       " 'was incorporated': 0.04741697005526111,\n",
       " 'incorporated as': 0.010270413276814647,\n",
       " 'as apple': 0.02090184680457109,\n",
       " 'apple computer': 0.010270413276814647,\n",
       " 'computer inc': 0.0,\n",
       " 'inc in': 0.0,\n",
       " 'in january': 0.06992160157428201,\n",
       " 'january 1977': 0.010270413276814647,\n",
       " '1977 and': 0.0,\n",
       " 'and sales': 0.07998120556397686,\n",
       " 'sales of': 0.13647689065096044,\n",
       " 'of its': 0.06778985945217952,\n",
       " 'its computers': 0.010270413276814647,\n",
       " 'computers including': 0.0,\n",
       " 'including the': 0.12409254372873577,\n",
       " 'apple ii': 0.010270413276814647,\n",
       " 'ii grew': 0.0,\n",
       " 'grew quickly': 0.031130163176278747,\n",
       " 'quickly within': 0.0,\n",
       " 'within a': 0.12754392233809705,\n",
       " 'a few': 0.017959709524776202,\n",
       " 'few years': 0.020540826553629293,\n",
       " 'years jobs': 0.0,\n",
       " 'jobs and': 0.020540826553629293,\n",
       " 'and wozniak': 0.010270413276814647,\n",
       " 'wozniak had': 0.010270413276814647,\n",
       " 'had hired': 0.010270413276814647,\n",
       " 'hired a': 0.009670612821033337,\n",
       " 'a staff': 0.034773054611800726,\n",
       " 'staff of': 0.034773054611800726,\n",
       " 'of computer': 0.10044181072087577,\n",
       " 'computer designers': 0.010270413276814647,\n",
       " 'designers and': 0.024702182587220376,\n",
       " 'and had': 0.09943131761225704,\n",
       " 'had a': 0.08058011825628401,\n",
       " 'a production': 0.09905051919725055,\n",
       " 'production line': 0.010270413276814647,\n",
       " 'line apple': 0.0,\n",
       " 'apple went': 0.010270413276814647,\n",
       " 'went public': 0.07690996027082304,\n",
       " 'public in': 0.22597975227573722,\n",
       " 'in 1980': 0.0740867335200908,\n",
       " '1980 to': 0.010270413276814647,\n",
       " 'to instant': 0.010270413276814647,\n",
       " 'instant financial': 0.010270413276814647,\n",
       " 'financial success': 0.07345319401144423,\n",
       " 'success over': 0.0,\n",
       " 'over the': 0.08184455129512931,\n",
       " 'the next': 0.0449739450988996,\n",
       " 'next few': 0.010270413276814647,\n",
       " 'years apple': 0.0,\n",
       " 'apple shipped': 0.010270413276814647,\n",
       " 'shipped new': 0.010270413276814647,\n",
       " 'new computers': 0.010270413276814647,\n",
       " 'computers featuring': 0.010270413276814647,\n",
       " 'featuring innovative': 0.010270413276814647,\n",
       " 'innovative graphical': 0.010270413276814647,\n",
       " 'graphical user': 0.010270413276814647,\n",
       " 'user interfaces': 0.010270413276814647,\n",
       " 'interfaces such': 0.0,\n",
       " 'such as': 0.12959333465907769,\n",
       " 'as the': 0.05724781044204746,\n",
       " 'the original': 0.08963632710407732,\n",
       " 'original macintosh': 0.010270413276814647,\n",
       " 'macintosh in': 0.010270413276814647,\n",
       " 'in 1984': 0.05556505014006811,\n",
       " '1984 and': 0.0,\n",
       " 's marketing': 0.08802327034601065,\n",
       " 'marketing advertisements': 0.010270413276814647,\n",
       " 'advertisements for': 0.010270413276814647,\n",
       " 'for its': 0.10273965077676213,\n",
       " 'its products': 0.10506840042396394,\n",
       " 'products received': 0.010270413276814647,\n",
       " 'received widespread': 0.010270413276814647,\n",
       " 'widespread critical': 0.010270413276814647,\n",
       " 'critical acclaim': 0.020540826553629293,\n",
       " 'acclaim however': 0.0,\n",
       " 'however the': 0.028808296162351456,\n",
       " 'the high': 0.03897285210021461,\n",
       " 'high price': 0.010270413276814647,\n",
       " 'price of': 0.059634562106720315,\n",
       " 'products and': 0.0835557043686534,\n",
       " 'and limited': 0.010270413276814647,\n",
       " 'limited application': 0.010270413276814647,\n",
       " 'application library': 0.010270413276814647,\n",
       " 'library caused': 0.010270413276814647,\n",
       " 'caused problems': 0.010270413276814647,\n",
       " 'problems as': 0.0,\n",
       " 'as did': 0.010270413276814647,\n",
       " 'did power': 0.010270413276814647,\n",
       " 'power struggles': 0.010270413276814647,\n",
       " 'struggles between': 0.010270413276814647,\n",
       " 'between executives': 0.010270413276814647,\n",
       " 'executives in': 0.0,\n",
       " 'in 1985': 0.06566502344335495,\n",
       " '1985 wozniak': 0.0,\n",
       " 'wozniak departed': 0.010270413276814647,\n",
       " 'departed apple': 0.010270413276814647,\n",
       " 'apple amicably': 0.010270413276814647,\n",
       " 'amicably and': 0.010270413276814647,\n",
       " 'and remained': 0.02604021747736148,\n",
       " 'remained an': 0.010270413276814647,\n",
       " 'an honorary': 0.010270413276814647,\n",
       " 'honorary employee': 0.010270413276814647,\n",
       " 'employee while': 0.0,\n",
       " 'while jobs': 0.010270413276814647,\n",
       " 'and others': 0.10884411148352245,\n",
       " 'others resigned': 0.010270413276814647,\n",
       " 'resigned to': 0.010270413276814647,\n",
       " 'to found': 0.06537334267018537,\n",
       " 'found next': 0.010270413276814647,\n",
       " 'next as': 0.0,\n",
       " 'the market': 0.054314013326862906,\n",
       " 'market for': 0.05218024184338028,\n",
       " 'for personal': 0.02583926587754362,\n",
       " 'personal computers': 0.07450304079932091,\n",
       " 'computers expanded': 0.010270413276814647,\n",
       " 'expanded and': 0.033353746260298654,\n",
       " 'and evolved': 0.010270413276814647,\n",
       " 'evolved through': 0.05067700982184912,\n",
       " 'through the': 0.109104827360935,\n",
       " 'the 1990s': 0.044769669084515185,\n",
       " '1990s apple': 0.0,\n",
       " 'apple lost': 0.010270413276814647,\n",
       " 'lost market': 0.010270413276814647,\n",
       " 'market share': 0.10597626568998789,\n",
       " 'share to': 0.010270413276814647,\n",
       " 'to the': 0.10913518427116402,\n",
       " 'the lower': 0.062260326352557495,\n",
       " 'lower priced': 0.0,\n",
       " 'priced duopoly': 0.010270413276814647,\n",
       " 'duopoly of': 0.010270413276814647,\n",
       " 'of microsoft': 0.010270413276814647,\n",
       " 'microsoft windows': 0.0771561999329229,\n",
       " 'windows on': 0.010270413276814647,\n",
       " 'on intel': 0.062260326352557495,\n",
       " 'intel pc': 0.010270413276814647,\n",
       " 'pc clones': 0.010270413276814647,\n",
       " 'clones the': 0.0,\n",
       " 'the board': 0.06399155044009032,\n",
       " 'board recruited': 0.010270413276814647,\n",
       " 'recruited ceo': 0.010270413276814647,\n",
       " 'ceo gil': 0.010270413276814647,\n",
       " 'gil amelio': 0.010270413276814647,\n",
       " 'amelio to': 0.010270413276814647,\n",
       " 'to what': 0.010270413276814647,\n",
       " 'what would': 0.027125868327877747,\n",
       " 'would be': 0.05337891787605378,\n",
       " 'be a': 0.07801534151115554,\n",
       " 'a 500': 0.010270413276814647,\n",
       " '500 day': 0.0,\n",
       " 'day charge': 0.010270413276814647,\n",
       " 'charge for': 0.010270413276814647,\n",
       " 'for him': 0.010270413276814647,\n",
       " 'him to': 0.010270413276814647,\n",
       " 'to rehabilitate': 0.010270413276814647,\n",
       " 'rehabilitate the': 0.010270413276814647,\n",
       " 'the financially': 0.010270413276814647,\n",
       " 'financially troubled': 0.010270413276814647,\n",
       " 'troubled company': 0.010270413276814647,\n",
       " 'company reshaping': 0.0,\n",
       " 'reshaping it': 0.010270413276814647,\n",
       " 'it with': 0.05786323847978803,\n",
       " 'with layoffs': 0.010270413276814647,\n",
       " 'layoffs executive': 0.0,\n",
       " 'executive restructuring': 0.010270413276814647,\n",
       " 'restructuring and': 0.0628589833367167,\n",
       " 'and product': 0.12765028499065637,\n",
       " 'product focus': 0.010270413276814647,\n",
       " 'focus in': 0.09918284821609573,\n",
       " 'in 1997': 0.04848510420629637,\n",
       " '1997 he': 0.0,\n",
       " 'he led': 0.010270413276814647,\n",
       " 'led apple': 0.010270413276814647,\n",
       " 'apple to': 0.010270413276814647,\n",
       " 'to buy': 0.07174415051491126,\n",
       " 'buy next': 0.010270413276814647,\n",
       " 'next solving': 0.0,\n",
       " 'solving the': 0.010270413276814647,\n",
       " 'the desperately': 0.010270413276814647,\n",
       " 'desperately failed': 0.010270413276814647,\n",
       " 'failed operating': 0.010270413276814647,\n",
       " 'operating system': 0.12236637433615771,\n",
       " 'system strategy': 0.010270413276814647,\n",
       " 'strategy and': 0.010270413276814647,\n",
       " 'and bringing': 0.010270413276814647,\n",
       " 'bringing jobs': 0.010270413276814647,\n",
       " 'jobs back': 0.010270413276814647,\n",
       " 'back jobs': 0.0,\n",
       " 'jobs pensively': 0.010270413276814647,\n",
       " 'pensively regained': 0.010270413276814647,\n",
       " 'regained leadership': 0.010270413276814647,\n",
       " 'leadership status': 0.010270413276814647,\n",
       " 'status becoming': 0.0,\n",
       " 'becoming ceo': 0.010270413276814647,\n",
       " 'ceo in': 0.02608878200542228,\n",
       " 'in 2000': 0.09061760776661189,\n",
       " '2000 apple': 0.0,\n",
       " 'apple swiftly': 0.010270413276814647,\n",
       " 'swiftly returned': 0.010270413276814647,\n",
       " 'returned to': 0.010270413276814647,\n",
       " 'to profitability': 0.010270413276814647,\n",
       " 'profitability under': 0.010270413276814647,\n",
       " 'under the': 0.0905537867232963,\n",
       " 'the revitalizing': 0.010270413276814647,\n",
       " 'revitalizing think': 0.010270413276814647,\n",
       " 'think different': 0.010270413276814647,\n",
       " 'different campaign': 0.010270413276814647,\n",
       " 'campaign as': 0.0,\n",
       " 'as he': 0.10483971724541151,\n",
       " 'he rebuilt': 0.010270413276814647,\n",
       " 'rebuilt apple': 0.010270413276814647,\n",
       " 's status': 0.010270413276814647,\n",
       " 'status by': 0.010270413276814647,\n",
       " 'by launching': 0.010270413276814647,\n",
       " 'launching the': 0.014559764514517898,\n",
       " 'the imac': 0.010270413276814647,\n",
       " 'imac in': 0.010270413276814647,\n",
       " 'in 1998': 0.06312366808789348,\n",
       " '1998 opening': 0.0,\n",
       " 'opening the': 0.010270413276814647,\n",
       " 'the retail': 0.03770443281586188,\n",
       " 'retail chain': 0.03156389997255937,\n",
       " 'chain of': 0.12677492995562775,\n",
       " 'of apple': 0.010270413276814647,\n",
       " 'apple stores': 0.010270413276814647,\n",
       " 'stores in': 0.2498444613035694,\n",
       " 'in 2001': 0.04122761949776512,\n",
       " '2001 and': 0.021231802370418048,\n",
       " 'and acquiring': 0.024702182587220376,\n",
       " 'acquiring numerous': 0.010270413276814647,\n",
       " 'numerous companies': 0.010270413276814647,\n",
       " 'companies to': 0.07660171800493559,\n",
       " 'to broaden': 0.010270413276814647,\n",
       " 'broaden the': 0.010270413276814647,\n",
       " 'the software': 0.06249652194566756,\n",
       " 'software portfolio': 0.010270413276814647,\n",
       " 'portfolio in': 0.06689662215452787,\n",
       " 'january 2007': 0.010270413276814647,\n",
       " '2007 jobs': 0.0,\n",
       " 'jobs renamed': 0.010270413276814647,\n",
       " 'renamed the': 0.09131073701897797,\n",
       " 'company apple': 0.010270413276814647,\n",
       " 'inc reflecting': 0.0,\n",
       " 'reflecting its': 0.010270413276814647,\n",
       " 'its shifted': 0.010270413276814647,\n",
       " 'shifted focus': 0.010270413276814647,\n",
       " 'focus toward': 0.010270413276814647,\n",
       " 'toward consumer': 0.010270413276814647,\n",
       " 'electronics and': 0.0,\n",
       " 'and launched': 0.08601755614498074,\n",
       " 'launched the': 0.010270413276814647,\n",
       " 'iphone to': 0.010270413276814647,\n",
       " 'to great': 0.010270413276814647,\n",
       " 'great critical': 0.010270413276814647,\n",
       " 'acclaim and': 0.010270413276814647,\n",
       " 'and financial': 0.22635191620159295,\n",
       " 'success in': 0.006721006171468249,\n",
       " 'in august': 0.07699838054038181,\n",
       " 'august 2011': 0.010270413276814647,\n",
       " '2011 jobs': 0.0,\n",
       " 'jobs resigned': 0.010270413276814647,\n",
       " 'resigned as': 0.04571562424488487,\n",
       " 'as ceo': 0.09993778452142776,\n",
       " 'ceo due': 0.010270413276814647,\n",
       " 'due to': 0.05948677650084985,\n",
       " 'to health': 0.030905172529500237,\n",
       " 'health complications': 0.010270413276814647,\n",
       " 'complications and': 0.0,\n",
       " 'and tim': 0.010270413276814647,\n",
       " 'tim cook': 0.010270413276814647,\n",
       " 'cook became': 0.010270413276814647,\n",
       " 'became the': 0.12624733617578696,\n",
       " 'the new': 0.1620748700507104,\n",
       " 'new ceo': 0.03452846516335224,\n",
       " 'ceo two': 0.0,\n",
       " 'two months': 0.010270413276814647,\n",
       " 'months later': 0.010270413276814647,\n",
       " 'later jobs': 0.0,\n",
       " 'jobs died': 0.010270413276814647,\n",
       " 'died marking': 0.0,\n",
       " 'marking the': 0.06377196116904853,\n",
       " 'the end': 0.055520991400793196,\n",
       " 'end of': 0.055520991400793196,\n",
       " 'of an': 0.08663064373515515,\n",
       " 'an era': 0.010270413276814647,\n",
       " 'era for': 0.010270413276814647,\n",
       " 'for the': 0.10846399736709215,\n",
       " 'company in': 0.1462665887723243,\n",
       " 'in june': 0.05065787187884887,\n",
       " 'june 2019': 0.0491108158525932,\n",
       " '2019 jony': 0.0,\n",
       " 'jony ive': 0.010270413276814647,\n",
       " 'ive apple': 0.0,\n",
       " 's cdo': 0.010270413276814647,\n",
       " 'cdo left': 0.0,\n",
       " 'left the': 0.04461211516380604,\n",
       " 'company to': 0.13340925587862307,\n",
       " 'to start': 0.010270413276814647,\n",
       " 'start his': 0.010270413276814647,\n",
       " 'his own': 0.010270413276814647,\n",
       " 'own firm': 0.010270413276814647,\n",
       " 'firm but': 0.0,\n",
       " 'but stated': 0.010270413276814647,\n",
       " 'stated he': 0.010270413276814647,\n",
       " 'he would': 0.01815926185282927,\n",
       " 'would work': 0.010270413276814647,\n",
       " 'work with': 0.0899478901977992,\n",
       " 'with apple': 0.021863994204075372,\n",
       " 'apple as': 0.010270413276814647,\n",
       " 'as its': 0.07819179294200343,\n",
       " 'its primary': 0.24147605705833852,\n",
       " 'primary client': 0.010270413276814647,\n",
       " 'client apple': 0.0,\n",
       " 'apple is': 0.020540826553629293,\n",
       " 'is well': 0.010270413276814647,\n",
       " 'well known': 0.05358470710670932,\n",
       " 'known for': 0.11042676827046115,\n",
       " 'its size': 0.010270413276814647,\n",
       " 'size and': 0.07601551473277368,\n",
       " 'and revenues': 0.010270413276814647,\n",
       " 'revenues its': 0.0,\n",
       " 'its worldwide': 0.08601755614498074,\n",
       " 'worldwide annual': 0.010270413276814647,\n",
       " 'annual revenue': 0.0923427593549429,\n",
       " 'revenue totaled': 0.0344070224579923,\n",
       " 'totaled 265': 0.0,\n",
       " '265 nbsp': 0.0,\n",
       " 'nbsp billion': 0.0,\n",
       " 'billion for': 0.035744263525740616,\n",
       " 'the 2018': 0.07788990018739216,\n",
       " '2018 fiscal': 0.05358470710670932,\n",
       " 'fiscal year': 0.08829661765313891,\n",
       " 'year apple': 0.0,\n",
       " 'is the': 0.09216489181011825,\n",
       " 'the world': 0.08895519828752889,\n",
       " 'world s': 0.0229135292908472,\n",
       " 's largest': 0.11489246422353366,\n",
       " 'largest technology': 0.010270413276814647,\n",
       " 'company by': 0.06159870443230545,\n",
       " 'by revenue': 0.08334095718525368,\n",
       " 'revenue and': 0.06892172740642467,\n",
       " 'and one': 0.08732242202964419,\n",
       " 's most': 0.1377691590557869,\n",
       " 'most valuable': 0.03464154126337852,\n",
       " 'valuable companies': 0.04163907176444928,\n",
       " 'companies it': 0.0,\n",
       " 'is also': 0.07810262253245596,\n",
       " 'also the': 0.06750542951485529,\n",
       " 's third': 0.07174415051491126,\n",
       " 'third largest': 0.15492687779453002,\n",
       " 'largest mobile': 0.020622505574190965,\n",
       " 'mobile phone': 0.17856149127333587,\n",
       " 'phone manufacturer': 0.010270413276814647,\n",
       " 'manufacturer after': 0.010270413276814647,\n",
       " 'after samsung': 0.010270413276814647,\n",
       " 'samsung and': 0.010270413276814647,\n",
       " 'and huawei': 0.010270413276814647,\n",
       " 'huawei in': 0.0,\n",
       " 'august 2018': 0.03676265996803974,\n",
       " '2018 apple': 0.0,\n",
       " 'apple became': 0.010270413276814647,\n",
       " 'the first': 0.10828547048342438,\n",
       " 'first public': 0.044776262102866685,\n",
       " 'public u': 0.14049472608966254,\n",
       " 'u s': 0.20088362144175154,\n",
       " 's company': 0.15850192185160314,\n",
       " 'to be': 0.0673285577891017,\n",
       " 'be valued': 0.014150074171035793,\n",
       " 'valued at': 0.04447607854798927,\n",
       " 'at over': 0.014150074171035793,\n",
       " 'over 1': 0.09065760319542507,\n",
       " '1 nbsp': 0.0,\n",
       " 'nbsp trillion': 0.0,\n",
       " 'trillion the': 0.0,\n",
       " 'company employs': 0.15846866244453467,\n",
       " 'employs 123': 0.010270413276814647,\n",
       " '123 000': 0.0,\n",
       " '000 full': 0.010270413276814647,\n",
       " 'full time': 0.0,\n",
       " 'time employees': 0.058894903306473304,\n",
       " 'employees and': 0.11036220459977865,\n",
       " 'and maintains': 0.06550552873100593,\n",
       " 'maintains 504': 0.010270413276814647,\n",
       " '504 retail': 0.010270413276814647,\n",
       " 'retail stores': 0.07902828342543518,\n",
       " 'in 24': 0.1255522634010947,\n",
       " '24 countries': 0.08332869592755675,\n",
       " 'countries it': 0.0,\n",
       " 'it operates': 0.18179616409313323,\n",
       " 'operates the': 0.06659319398087077,\n",
       " 'store which': 0.0,\n",
       " 'which is': 0.0967000872835815,\n",
       " 'largest music': 0.010270413276814647,\n",
       " 'music retailer': 0.010270413276814647,\n",
       " 'retailer more': 0.0,\n",
       " 'more than': 0.09315422836399842,\n",
       " 'than 1': 0.09507992530251898,\n",
       " '1 3': 0.0,\n",
       " '3 nbsp': 0.0,\n",
       " 'billion apple': 0.010270413276814647,\n",
       " 'apple products': 0.010270413276814647,\n",
       " 'products are': 0.09667113087776365,\n",
       " 'are actively': 0.010270413276814647,\n",
       " 'actively in': 0.010270413276814647,\n",
       " 'in use': 0.10390532143538872,\n",
       " 'use worldwide': 0.010270413276814647,\n",
       " 'worldwide the': 0.0,\n",
       " 'company also': 0.1283918973922795,\n",
       " 'also has': 0.1665629742023796,\n",
       " 'has a': 0.11780823622450136,\n",
       " 'a high': 0.021113689846509312,\n",
       " 'high level': 0.010270413276814647,\n",
       " 'level of': 0.010270413276814647,\n",
       " 'of brand': 0.07407446475961944,\n",
       " 'brand loyalty': 0.010270413276814647,\n",
       " 'loyalty and': 0.010270413276814647,\n",
       " 'and is': 0.11337909545123197,\n",
       " 'is ranked': 0.14098671700517404,\n",
       " 'ranked as': 0.0491726107434231,\n",
       " 'valuable brand': 0.03329562786327373,\n",
       " 'brand however': 0.0,\n",
       " 'however apple': 0.0,\n",
       " 'apple receives': 0.010270413276814647,\n",
       " 'receives significant': 0.010270413276814647,\n",
       " 'significant criticism': 0.010270413276814647,\n",
       " 'criticism regarding': 0.010270413276814647,\n",
       " 'regarding the': 0.010270413276814647,\n",
       " 'the labor': 0.09757215323908264,\n",
       " 'labor practices': 0.010270413276814647,\n",
       " 'practices of': 0.012843485789820306,\n",
       " 'its contractors': 0.010270413276814647,\n",
       " 'contractors its': 0.0,\n",
       " 'its environmental': 0.010270413276814647,\n",
       " 'environmental practices': 0.010270413276814647,\n",
       " 'practices and': 0.010270413276814647,\n",
       " 'and unethical': 0.010270413276814647,\n",
       " 'unethical business': 0.010270413276814647,\n",
       " 'business practices': 0.010270413276814647,\n",
       " 'practices including': 0.0,\n",
       " 'including anti': 0.010270413276814647,\n",
       " 'anti competitive': 0.0,\n",
       " 'competitive behavior': 0.010270413276814647,\n",
       " 'behavior as': 0.0,\n",
       " 'the origins': 0.010270413276814647,\n",
       " 'origins of': 0.010270413276814647,\n",
       " 'of source': 0.010270413276814647,\n",
       " 'source materials': 0.010270413276814647,\n",
       " 'american airlines': 0.12885880813539702,\n",
       " 'airlines inc': 0.0,\n",
       " 'inc aa': 0.0,\n",
       " 'aa is': 0.0,\n",
       " 'is a': 0.10735024619929266,\n",
       " 'a major': 0.38805915688183384,\n",
       " 'major american': 0.19844660764310035,\n",
       " 'american airline': 0.15532238771269447,\n",
       " 'airline headquartered': 0.04387472662428548,\n",
       " 'in fort': 0.16342661805902384,\n",
       " 'fort worth': 0.1718878554840762,\n",
       " 'worth texas': 0.0,\n",
       " 'texas within': 0.0,\n",
       " 'within the': 0.07575058685145067,\n",
       " 'the dallas': 0.059520497091111964,\n",
       " 'dallas fort': 0.0,\n",
       " 'worth metroplex': 0.062260326352557495,\n",
       " 'metroplex it': 0.0,\n",
       " 'largest airline': 0.06442940406769851,\n",
       " 'airline when': 0.035787625644982994,\n",
       " 'when measured': 0.08070783045701897,\n",
       " 'measured by': 0.07440134127472278,\n",
       " 'by fleet': 0.035787625644982994,\n",
       " 'fleet size': 0.05836905595552264,\n",
       " 'size revenue': 0.0,\n",
       " 'revenue scheduled': 0.0,\n",
       " 'scheduled passengers': 0.05836905595552264,\n",
       " 'passengers carried': 0.05580046602291746,\n",
       " 'carried scheduled': 0.0,\n",
       " 'scheduled passenger': 0.06442940406769851,\n",
       " 'passenger kilometers': 0.0,\n",
       " 'kilometers flown': 0.05836905595552264,\n",
       " 'flown and': 0.0,\n",
       " 'and a': 0.11950831234422171,\n",
       " 'a number': 0.15609211836056502,\n",
       " 'number of': 0.13508765834359698,\n",
       " 'of destinations': 0.035787625644982994,\n",
       " 'destinations served': 0.035787625644982994,\n",
       " 'served american': 0.0,\n",
       " 'american together': 0.0,\n",
       " 'together with': 0.06352377267889772,\n",
       " 'with its': 0.133278679865342,\n",
       " 'its regional': 0.035787625644982994,\n",
       " 'regional partners': 0.035787625644982994,\n",
       " 'partners operates': 0.0,\n",
       " 'operates an': 0.07022081117490736,\n",
       " 'an extensive': 0.046695244764418116,\n",
       " 'extensive international': 0.035787625644982994,\n",
       " 'international and': 0.11160201191208419,\n",
       " 'and domestic': 0.035787625644982994,\n",
       " 'domestic network': 0.035787625644982994,\n",
       " 'network with': 0.09757215323908264,\n",
       " 'with almost': 0.035787625644982994,\n",
       " 'almost 6': 0.035787625644982994,\n",
       " '6 800': 0.0,\n",
       " '800 flights': 0.035787625644982994,\n",
       " 'flights per': 0.035787625644982994,\n",
       " 'per day': 0.06537064722360954,\n",
       " 'day to': 0.035787625644982994,\n",
       " 'to nearly': 0.035787625644982994,\n",
       " 'nearly 350': 0.035787625644982994,\n",
       " '350 destinations': 0.035787625644982994,\n",
       " 'destinations in': 0.053808112886183444,\n",
       " 'in more': 0.09805936222455847,\n",
       " 'than 50': 0.06442940406769851,\n",
       " '50 countries': 0.10345520739329696,\n",
       " 'countries american': 0.0,\n",
       " 'airlines is': 0.035787625644982994,\n",
       " 'a founding': 0.05580046602291746,\n",
       " 'founding member': 0.05580046602291746,\n",
       " 'member of': 0.10516835073377251,\n",
       " 'the oneworld': 0.035787625644982994,\n",
       " 'oneworld alliance': 0.035787625644982994,\n",
       " 'alliance the': 0.0,\n",
       " 'the third': 0.13883038856488522,\n",
       " 'airline alliance': 0.05580046602291746,\n",
       " 'alliance in': 0.035787625644982994,\n",
       " 'in the': 0.09958210762526656,\n",
       " 'world regional': 0.0,\n",
       " 'regional service': 0.035787625644982994,\n",
       " 'service is': 0.035787625644982994,\n",
       " 'is operated': 0.03369759931452854,\n",
       " 'operated by': 0.05747511521849832,\n",
       " 'by independent': 0.035787625644982994,\n",
       " 'independent and': 0.03676265996803974,\n",
       " 'and subsidiary': 0.035787625644982994,\n",
       " 'subsidiary carriers': 0.035787625644982994,\n",
       " 'carriers under': 0.035787625644982994,\n",
       " 'the brand': 0.14696733017857022,\n",
       " 'brand name': 0.16358055478145514,\n",
       " 'name american': 0.035787625644982994,\n",
       " 'american eagle': 0.07157525128996599,\n",
       " 'eagle american': 0.0,\n",
       " 'airlines and': 0.12822358815430948,\n",
       " 'and american': 0.1323264280611938,\n",
       " 'eagle operate': 0.035787625644982994,\n",
       " 'operate out': 0.035787625644982994,\n",
       " 'out of': 0.11026768087657719,\n",
       " 'of 10': 0.06480116820701663,\n",
       " '10 hubs': 0.035787625644982994,\n",
       " 'hubs with': 0.0,\n",
       " 'with dallas': 0.03369759931452854,\n",
       " 'worth being': 0.035787625644982994,\n",
       " 'being its': 0.05836905595552264,\n",
       " 'its largest': 0.06251404572816582,\n",
       " 'largest handling': 0.0,\n",
       " 'handling more': 0.035787625644982994,\n",
       " 'than 200': 0.0493976118299389,\n",
       " '200 million': 0.05461857090148216,\n",
       " 'million passengers': 0.035787625644982994,\n",
       " 'passengers annually': 0.035787625644982994,\n",
       " 'annually with': 0.035787625644982994,\n",
       " 'with an': 0.06585710647045596,\n",
       " 'an average': 0.058061595986034005,\n",
       " 'average of': 0.03463510714512957,\n",
       " 'of more': 0.06751090459104558,\n",
       " 'than 500': 0.035787625644982994,\n",
       " '500 000': 0.0,\n",
       " '000 passengers': 0.035787625644982994,\n",
       " 'passengers daily': 0.035787625644982994,\n",
       " 'daily american': 0.0,\n",
       " 'american operates': 0.035787625644982994,\n",
       " 'operates its': 0.07601551473277368,\n",
       " 'primary maintenance': 0.035787625644982994,\n",
       " 'maintenance base': 0.035787625644982994,\n",
       " 'base in': 0.04882540777005278,\n",
       " 'in tulsa': 0.13878137577149594,\n",
       " 'tulsa in': 0.035787625644982994,\n",
       " 'in addition': 0.10677682969915035,\n",
       " 'addition to': 0.1171398344300105,\n",
       " 'the maintenance': 0.035787625644982994,\n",
       " 'maintenance locations': 0.035787625644982994,\n",
       " 'locations at': 0.035787625644982994,\n",
       " 'at its': 0.05312897351325992,\n",
       " 'its hubs': 0.035787625644982994,\n",
       " 'hubs as': 0.0,\n",
       " 'as of': 0.07353376819518778,\n",
       " 'of 2019': 0.05498310786281031,\n",
       " '2019 the': 0.061672964783193736,\n",
       " 'employs nearly': 0.039145714173763696,\n",
       " 'nearly 130': 0.035787625644982994,\n",
       " '130 000': 0.0,\n",
       " '000 people': 0.0784730479653314,\n",
       " 'people through': 0.0,\n",
       " 'the airline': 0.1258319233805387,\n",
       " 'airline s': 0.0,\n",
       " 's parent': 0.05028718666937336,\n",
       " 'parent company': 0.0967000872835815,\n",
       " 'company american': 0.055101582342275406,\n",
       " 'airlines group': 0.035787625644982994,\n",
       " 'group it': 0.0,\n",
       " 'is publicly': 0.14550142452467432,\n",
       " 'publicly traded': 0.18077332894515358,\n",
       " 'traded under': 0.03369759931452854,\n",
       " 'under nasdaq': 0.035787625644982994,\n",
       " 'nasdaq aal': 0.0,\n",
       " 'aal with': 0.035787625644982994,\n",
       " 'with a': 0.14204941132589985,\n",
       " 'a market': 0.08586969316210288,\n",
       " 'market capitalization': 0.08191621682084242,\n",
       " 'capitalization of': 0.09580634567964905,\n",
       " 'of about': 0.0646595046208106,\n",
       " 'about 12': 0.0,\n",
       " '12 7': 0.0,\n",
       " '7 billion': 0.08740966128115099,\n",
       " 'billion as': 0.0859439277420381,\n",
       " '2019 and': 0.03634973494830734,\n",
       " 'and included': 0.046293719959753746,\n",
       " 'included in': 0.07591378670852574,\n",
       " 'the s': 0.11179426309486241,\n",
       " 's p': 0.11788521717410676,\n",
       " 'p 500': 0.14643481381529044,\n",
       " '500 index': 0.09981356778180919,\n",
       " 'advanced micro': 0.05580046602291746,\n",
       " 'micro devices': 0.06480116820701663,\n",
       " 'devices inc': 0.06740581917598738,\n",
       " 'inc amd': 0.0,\n",
       " 'amd is': 0.06198928013505983,\n",
       " 'multinational semiconductor': 0.060092809563141884,\n",
       " 'semiconductor company': 0.15378476774679278,\n",
       " 'company based': 0.3525072691513335,\n",
       " 'based in': 0.24884520788731931,\n",
       " 'in santa': 0.11347577580197023,\n",
       " 'santa clara': 0.11144789963592076,\n",
       " 'clara california': 0.0,\n",
       " 'that develops': 0.19987556904285553,\n",
       " 'develops computer': 0.06198928013505983,\n",
       " 'computer processors': 0.06198928013505983,\n",
       " 'processors and': 0.11673811191104529,\n",
       " 'and related': 0.24766070696326112,\n",
       " 'related technologies': 0.06198928013505983,\n",
       " 'technologies for': 0.08223226571798363,\n",
       " 'for business': 0.13596804945876068,\n",
       " 'business and': 0.07368723990071008,\n",
       " 'and consumer': 0.12403166192308374,\n",
       " 'consumer markets': 0.15203102946554736,\n",
       " 'markets while': 0.0,\n",
       " 'while initially': 0.06198928013505983,\n",
       " 'initially it': 0.06198928013505983,\n",
       " 'it manufactured': 0.06198928013505983,\n",
       " 'manufactured its': 0.06198928013505983,\n",
       " 'its own': 0.14968433168169856,\n",
       " 'own processors': 0.06198928013505983,\n",
       " 'processors the': 0.0,\n",
       " 'company later': 0.05580046602291746,\n",
       " 'later outsourced': 0.06198928013505983,\n",
       " 'outsourced its': 0.06198928013505983,\n",
       " 'its manufacturing': 0.05580046602291746,\n",
       " 'manufacturing a': 0.0859439277420381,\n",
       " 'a practice': 0.06198928013505983,\n",
       " 'practice known': 0.06198928013505983,\n",
       " 'known as': 0.1656479045239214,\n",
       " 'as fabless': 0.06198928013505983,\n",
       " 'fabless after': 0.0,\n",
       " 'after globalfoundries': 0.06198928013505983,\n",
       " 'globalfoundries was': 0.06198928013505983,\n",
       " 'was spun': 0.10862802665372581,\n",
       " 'spun off': 0.08933882676240185,\n",
       " 'off in': 0.06274542897285412,\n",
       " 'in 2009': 0.12677492995562775,\n",
       " '2009 amd': 0.0,\n",
       " 'amd s': 0.0,\n",
       " 's main': 0.04905752291332044,\n",
       " 'main products': 0.06198928013505983,\n",
       " 'include microprocessors': 0.06198928013505983,\n",
       " 'microprocessors motherboard': 0.0,\n",
       " 'motherboard chipsets': 0.05836905595552264,\n",
       " 'chipsets embedded': 0.0,\n",
       " 'embedded processors': 0.05580046602291746,\n",
       " 'and graphics': 0.06198928013505983,\n",
       " 'graphics processors': 0.06198928013505983,\n",
       " 'processors for': 0.05580046602291746,\n",
       " 'for servers': 0.08070783045701897,\n",
       " 'servers workstations': 0.0,\n",
       " 'workstations personal': 0.0,\n",
       " 'computers and': 0.05836905595552264,\n",
       " 'and embedded': 0.05580046602291746,\n",
       " 'embedded system': 0.06198928013505983,\n",
       " 'system applications': 0.06198928013505983,\n",
       " 'applications amd': 0.0,\n",
       " 'the second': 0.1033359449924361,\n",
       " 'second largest': 0.11579423412968726,\n",
       " 'largest supplier': 0.05478644221138678,\n",
       " 'supplier and': 0.12334592956638747,\n",
       " 'and only': 0.05836905595552264,\n",
       " 'only significant': 0.06198928013505983,\n",
       " 'significant rival': 0.06198928013505983,\n",
       " 'rival to': 0.06198928013505983,\n",
       " 'to intel': 0.06198928013505983,\n",
       " 'intel in': 0.05836905595552264,\n",
       " 'for x86': 0.06198928013505983,\n",
       " 'x86 based': 0.0,\n",
       " 'based microprocessors': 0.06198928013505983,\n",
       " 'microprocessors since': 0.0,\n",
       " 'since acquiring': 0.06198928013505983,\n",
       " 'acquiring ati': 0.06198928013505983,\n",
       " 'ati in': 0.08526957739589396,\n",
       " 'in 2006': 0.07355069185946919,\n",
       " '2006 amd': 0.0,\n",
       " 'amd and': 0.06198928013505983,\n",
       " 'and its': 0.1669095527226527,\n",
       " 'its competitor': 0.08116431421515267,\n",
       " 'competitor nvidia': 0.06198928013505983,\n",
       " 'nvidia have': 0.06198928013505983,\n",
       " 'have maintained': 0.06198928013505983,\n",
       " 'maintained a': 0.06198928013505983,\n",
       " 'a duopoly': 0.06198928013505983,\n",
       " 'duopoly in': 0.06198928013505983,\n",
       " 'the discrete': 0.06198928013505983,\n",
       " 'discrete graphics': 0.06198928013505983,\n",
       " 'graphics processing': 0.05836905595552264,\n",
       " 'processing unit': 0.05836905595552264,\n",
       " 'unit gpu': 0.0,\n",
       " 'gpu market': 0.0,\n",
       " 'an anthem': 0.10681229807887233,\n",
       " 'anthem is': 0.10681229807887233,\n",
       " 'a musical': 0.10681229807887233,\n",
       " 'musical composition': 0.10681229807887233,\n",
       " 'composition of': 0.10681229807887233,\n",
       " 'of celebration': 0.10681229807887233,\n",
       " 'celebration usually': 0.0,\n",
       " 'usually used': 0.10681229807887233,\n",
       " 'used as': 0.10057437333874672,\n",
       " 'as a': 0.1682064489279697,\n",
       " 'a symbol': 0.10057437333874672,\n",
       " 'symbol for': 0.10057437333874672,\n",
       " 'for a': 0.09011038232542055,\n",
       " 'a distinct': 0.10057437333874672,\n",
       " 'distinct group': 0.10681229807887233,\n",
       " 'group particularly': 0.0,\n",
       " 'particularly the': 0.10057437333874672,\n",
       " 'the national': 0.07924676778305609,\n",
       " 'national anthems': 0.10681229807887233,\n",
       " 'anthems of': 0.10681229807887233,\n",
       " 'of countries': 0.10681229807887233,\n",
       " 'countries originally': 0.0,\n",
       " 'originally and': 0.0,\n",
       " 'and in': 0.15933487473702598,\n",
       " 'in music': 0.10681229807887233,\n",
       " 'music theory': 0.10681229807887233,\n",
       " 'theory and': 0.10681229807887233,\n",
       " 'and religious': 0.10681229807887233,\n",
       " 'religious contexts': 0.10681229807887233,\n",
       " 'contexts it': 0.0,\n",
       " 'it also': 0.07996720791920521,\n",
       " 'also refers': 0.10681229807887233,\n",
       " 'refers more': 0.10681229807887233,\n",
       " 'more particularly': 0.21362459615774465,\n",
       " 'particularly to': 0.21362459615774465,\n",
       " 'to short': 0.10681229807887233,\n",
       " 'short sacred': 0.10681229807887233,\n",
       " 'sacred choral': 0.10681229807887233,\n",
       " 'choral work': 0.10681229807887233,\n",
       " 'work still': 0.0,\n",
       " 'still frequently': 0.10681229807887233,\n",
       " 'frequently seen': 0.10681229807887233,\n",
       " 'seen in': 0.10681229807887233,\n",
       " 'in sacred': 0.10681229807887233,\n",
       " 'sacred harp': 0.10681229807887233,\n",
       " 'harp and': 0.10681229807887233,\n",
       " 'and other': 0.10619810109138589,\n",
       " 'other types': 0.09614849530102702,\n",
       " 'types of': 0.08753902164048205,\n",
       " 'of shape': 0.10681229807887233,\n",
       " 'shape note': 0.10681229807887233,\n",
       " 'note singing': 0.10681229807887233,\n",
       " 'singing and': 0.0,\n",
       " 'and still': 0.10681229807887233,\n",
       " 'still more': 0.10681229807887233,\n",
       " 'to a': 0.1003657914134125,\n",
       " 'a specific': 0.10681229807887233,\n",
       " 'specific form': 0.10681229807887233,\n",
       " 'form of': 0.09271551758850072,\n",
       " 'of anglican': 0.10057437333874672,\n",
       " 'anglican church': 0.10681229807887233,\n",
       " 'church music': 0.10681229807887233,\n",
       " 'coca cola': 0.0,\n",
       " 'cola or': 0.0,\n",
       " 'or coke': 0.0229135292908472,\n",
       " 'coke is': 0.0,\n",
       " 'a carbonated': 0.0229135292908472,\n",
       " 'carbonated soft': 0.0229135292908472,\n",
       " 'soft drink': 0.0525180856686282,\n",
       " 'drink manufactured': 0.0229135292908472,\n",
       " 'manufactured by': 0.0229135292908472,\n",
       " 'by the': 0.06727556892546652,\n",
       " 'the coca': 0.0825036593342146,\n",
       " 'cola company': 0.0795578698779214,\n",
       " 'company originally': 0.0672005612319006,\n",
       " 'originally marketed': 0.0229135292908472,\n",
       " 'marketed as': 0.03672659700572212,\n",
       " 'a temperance': 0.0229135292908472,\n",
       " 'temperance drink': 0.0229135292908472,\n",
       " 'drink and': 0.0229135292908472,\n",
       " 'and intended': 0.0229135292908472,\n",
       " 'intended as': 0.0229135292908472,\n",
       " 'a patent': 0.0229135292908472,\n",
       " 'patent medicine': 0.0229135292908472,\n",
       " 'medicine it': 0.0,\n",
       " 'was invented': 0.0229135292908472,\n",
       " 'invented in': 0.0229135292908472,\n",
       " 'the late': 0.05367958874180503,\n",
       " 'late 19th': 0.061672964783193736,\n",
       " '19th century': 0.07677081074207065,\n",
       " 'century by': 0.0229135292908472,\n",
       " 'by john': 0.05848952646322958,\n",
       " 'john stith': 0.0229135292908472,\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "tf_idf = dict()\n",
    "n = wiki_df.shape[0]\n",
    "for token in bigram_counter.keys():\n",
    "    max_tf = 0\n",
    "    df = 0\n",
    "    \n",
    "    for document in wiki_df['intro_text'].tolist():\n",
    "        \n",
    "        document = document.lower()\n",
    "        tf = document.count(token)/(len(document.split())-1)\n",
    "        if tf > 0: df += 1\n",
    "        max_tf = max(tf, max_tf)\n",
    "        \n",
    "    if token == 'apple inc': print(max_tf, df, n)\n",
    "    \n",
    "    tf_idf[token] = max_tf*(np.log((1+n)/(1+df))+1)\n",
    "\n",
    "# bigram_df = ...\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>tf-idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple inc</td>\n",
       "      <td>0.034528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inc is</td>\n",
       "      <td>0.121065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is an</td>\n",
       "      <td>0.147476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>an american</td>\n",
       "      <td>0.158072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>american multinational</td>\n",
       "      <td>0.282122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>multinational technology</td>\n",
       "      <td>0.077946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>technology company</td>\n",
       "      <td>0.122653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>company headquartered</td>\n",
       "      <td>0.192896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>headquartered in</td>\n",
       "      <td>0.145858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>in cupertino</td>\n",
       "      <td>0.010270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     bigram    tf-idf\n",
       "0                 apple inc  0.034528\n",
       "1                    inc is  0.121065\n",
       "2                     is an  0.147476\n",
       "3               an american  0.158072\n",
       "4    american multinational  0.282122\n",
       "5  multinational technology  0.077946\n",
       "6        technology company  0.122653\n",
       "7     company headquartered  0.192896\n",
       "8          headquartered in  0.145858\n",
       "9              in cupertino  0.010270"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_df = pd.DataFrame(tf_idf.items(), columns=['bigram','tf-idf'])\n",
    "bigram_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find ways to sort and filter your output to bigrams that make sense, such as `wells fargo`, `apple inc` or `puerto rico`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "filtered_bigram_df = bigram_df[bigram_df['tf-idf']>0.01].sort_values(by=['tf-idf'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>tf-idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19817</th>\n",
       "      <td>marathon oil</td>\n",
       "      <td>0.747124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50072</th>\n",
       "      <td>reinsurance company</td>\n",
       "      <td>0.694280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50069</th>\n",
       "      <td>everest re</td>\n",
       "      <td>0.694280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50071</th>\n",
       "      <td>a reinsurance</td>\n",
       "      <td>0.694280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29985</th>\n",
       "      <td>in hamilton</td>\n",
       "      <td>0.653733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49739</th>\n",
       "      <td>b2b it</td>\n",
       "      <td>0.631164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49738</th>\n",
       "      <td>provides b2b</td>\n",
       "      <td>0.631164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49911</th>\n",
       "      <td>alexandria real</td>\n",
       "      <td>0.631164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49912</th>\n",
       "      <td>estate equities</td>\n",
       "      <td>0.631164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49913</th>\n",
       "      <td>equities is</td>\n",
       "      <td>0.631164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    bigram    tf-idf\n",
       "19817         marathon oil  0.747124\n",
       "50072  reinsurance company  0.694280\n",
       "50069           everest re  0.694280\n",
       "50071        a reinsurance  0.694280\n",
       "29985          in hamilton  0.653733\n",
       "49739               b2b it  0.631164\n",
       "49738         provides b2b  0.631164\n",
       "49911      alexandria real  0.631164\n",
       "49912      estate equities  0.631164\n",
       "49913          equities is  0.631164"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_bigram_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Word vectors via Pointwise Mutual Information (PMI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this problem we will investigate another way of creating word representation from word co-occurrences. For this we will create a word-word matrix that counts the number of times that two words appear close to each other.\n",
    "\n",
    "## More formally:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The pointwise mutual information (PMI) for a (word, context) pair in a corpus is defined as the probability of their co-occurrence divided by the probabilities of them appearing individually, \n",
    "## $$\n",
    "{\\rm pmi}(w, c) = \\log \\frac{p(w, c)}{p(w) p(c)}\n",
    "$$\n",
    "\n",
    "## $$\n",
    "p(w, c) = \\frac{\n",
    "f_{i,j}\n",
    "}{\n",
    "\\sum_{i=1}^N \\sum_{j=1}^N f_{i,j}\n",
    "}, \\quad \n",
    "p(w) = \\frac{\n",
    "\\sum_{j=1}^N f_{i,j}\n",
    "}{\n",
    "\\sum_{i=1}^N \\sum_{j=1}^N f_{i,j}\n",
    "}, \\quad\n",
    "p(c) = \\frac{\n",
    "\\sum_{i=1}^N f_{i,j}\n",
    "}{\n",
    "\\sum_{i=1}^N \\sum_{j=1}^N f_{i,j}\n",
    "}\n",
    "$$\n",
    "### where $f_{i,j}$ is the word-word count matrix. <br />\n",
    "### In addition we can define the positive pointwise mutual information as, \n",
    "## $$\n",
    "{\\rm ppmi}(w, c) = {\\rm max}\\left[{\\rm pmi(w,c)}, 0 \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will implement this on our wiki featured articles dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_id</th>\n",
       "      <th>page_title</th>\n",
       "      <th>page_views</th>\n",
       "      <th>intro_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>29180</td>\n",
       "      <td>System Shock</td>\n",
       "      <td>6031</td>\n",
       "      <td>'System Shock' is a 1994 first-person action-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4930</th>\n",
       "      <td>29172960</td>\n",
       "      <td>Chaplain–Medic massacre</td>\n",
       "      <td>385</td>\n",
       "      <td>The Chaplain–Medic massacre was a massacre tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>23984</td>\n",
       "      <td>Pyxis</td>\n",
       "      <td>1106</td>\n",
       "      <td>Pyxis is a small and faint constellation in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3655</th>\n",
       "      <td>8642505</td>\n",
       "      <td>In Rainbows</td>\n",
       "      <td>9863</td>\n",
       "      <td>'In Rainbows' is the seventh studio album by t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5594</th>\n",
       "      <td>50742290</td>\n",
       "      <td>Political Animals and Animal Politics</td>\n",
       "      <td>264</td>\n",
       "      <td>'Political Animals and Animal Politics' is a 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_id                             page_title  page_views  \\\n",
       "332      29180                           System Shock        6031   \n",
       "4930  29172960                Chaplain–Medic massacre         385   \n",
       "286      23984                                  Pyxis        1106   \n",
       "3655   8642505                            In Rainbows        9863   \n",
       "5594  50742290  Political Animals and Animal Politics         264   \n",
       "\n",
       "                                             intro_text  \n",
       "332   'System Shock' is a 1994 first-person action-a...  \n",
       "4930  The Chaplain–Medic massacre was a massacre tha...  \n",
       "286   Pyxis is a small and faint constellation in th...  \n",
       "3655  'In Rainbows' is the seventh studio album by t...  \n",
       "5594  'Political Animals and Animal Politics' is a 2...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "wiki_feat_df = pd.read_csv('/Users/mac/Desktop/MFin Materials/15.S08/data/kdwd_featured_articles.csv')\n",
    "wiki_feat_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = wiki_feat_df['intro_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(text):\n",
    "    token_pattern = r'[a-z0-9]+'\n",
    "    return re.findall(token_pattern, text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 61990\n"
     ]
    }
   ],
   "source": [
    "unigram_counts = Counter()\n",
    "for doc in corpus:\n",
    "    # your code here\n",
    "    tokens = get_tokens(doc)\n",
    "    for token in tokens:\n",
    "        unigram_counts[token] += 1\n",
    "\n",
    "inv_vocab = sorted(list(unigram_counts.keys()))\n",
    "vocab = {inv_vocab[i]: i for i in range(len(inv_vocab))}\n",
    "print('vocabulary size: {}'.format(len(unigram_counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip-grams are a generalization of n-grams: https://en.wikipedia.org/wiki/N-gram#Skip-gram\n",
    "### We will use this term here to find pairs of word within a context window, meaning that all words separated by max N words will be considered a bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of skipgrams: 1940563\n",
      "most common:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('of', 'the'), 41918),\n",
       " (('the', 'of'), 23028),\n",
       " (('in', 'the'), 17924),\n",
       " (('the', 'in'), 17596),\n",
       " (('and', 'the'), 11221)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use skip-2-grams and context length 2 in each direction\n",
    "word_window_len = 2\n",
    "skipgram_counts = Counter()\n",
    "for doc in corpus:\n",
    "    tokens = get_tokens(doc)\n",
    "    for token_idx, token in enumerate(tokens):\n",
    "        for context_token in tokens[token_idx - word_window_len:token_idx + word_window_len]:\n",
    "            #your code here\n",
    "            if context_token != token:\n",
    "                skipgram_counts[(vocab[token], vocab[context_token])] += 1\n",
    "\n",
    "print('number of skipgrams:', len(skipgram_counts))\n",
    "print('most common:')\n",
    "[((inv_vocab[t1], inv_vocab[t2]), v) for (t1, t2), v in skipgram_counts.most_common(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's create a sparse matrix that contains word-word co-occurrence counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse as ssp\n",
    "\n",
    "row_indxs = []\n",
    "col_indxs = []\n",
    "dat_values = []\n",
    "\n",
    "# your code here\n",
    "row_indxs = [t1 for (t1,t2),v in skipgram_counts.items()]\n",
    "col_indxs = [t2 for (t1,t2),v in skipgram_counts.items()]\n",
    "dat_values = [v for (t1,t2),v in skipgram_counts.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wwcnt_mat = ssp.csr_matrix((dat_values, (row_indxs, col_indxs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<61990x61990 sparse matrix of type '<class 'numpy.longlong'>'\n",
       "\twith 1940563 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wwcnt_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, create the PPMI matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reusable quantities\n",
    "num_skipgrams = wwcnt_mat.sum()\n",
    "sum_over_words = np.array(wwcnt_mat.sum(axis=0)).flatten()\n",
    "sum_over_contexts = np.array(wwcnt_mat.sum(axis=1)).flatten()\n",
    "\n",
    "ppmi_dat_values = []   # positive pointwise mutial information\n",
    "row_indxs = []  # for creating sparce matrices\n",
    "col_indxs = []  # for creating sparce matrices\n",
    "for (tok_word, tok_context), sg_count in skipgram_counts.items():\n",
    "\n",
    "    nwc = sg_count\n",
    "    Pwc = nwc/num_skipgrams\n",
    "    nw = sum_over_contexts[tok_word]\n",
    "    Pw = nw/num_skipgrams\n",
    "    nc = sum_over_words[tok_context]\n",
    "    Pc = nc/num_skipgrams\n",
    "    \n",
    "    pmi = np.log2(Pwc / (Pw * Pc))   \n",
    "    ppmi = max(pmi, 0)\n",
    "    \n",
    "    row_indxs.append(tok_word)\n",
    "    col_indxs.append(tok_context)\n",
    "    ppmi_dat_values.append(ppmi)\n",
    "\n",
    "ppmi_mat = ssp.csr_matrix((ppmi_dat_values, (row_indxs, col_indxs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `ppmi_mat` to investigate the most similar values to a few test terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to speed up calculation we do dimentionality reduction here\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=64, random_state=6006)\n",
    "trafo_ppmi_mat = svd.fit_transform(ppmi_mat)\n",
    "sim_mat = cosine_similarity(trafo_ppmi_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<61990x61990 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1940563 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppmi_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000 eminem\n",
      "0.837 timbaland\n",
      "0.805 bale\n",
      "0.800 stravinsky\n",
      "0.789 rihanna\n",
      "0.786 beyonc\n",
      "0.781 santos\n",
      "0.769 crafted\n",
      "0.766 supergroup\n",
      "0.765 choreography\n"
     ]
    }
   ],
   "source": [
    "token = 'eminem'\n",
    "# print most similar terms\n",
    "word_idx = vocab[token]\n",
    "for idx, row in pd.Series(sim_mat[word_idx]).sort_values(ascending=False).head(10).iteritems():\n",
    "    print('%.3f' % row, inv_vocab[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000 quantum\n",
      "0.755 evolution\n",
      "0.742 unique\n",
      "0.739 mechanical\n",
      "0.733 mathematical\n",
      "0.725 theory\n",
      "0.722 nucleic\n",
      "0.716 basic\n",
      "0.716 technical\n",
      "0.713 physical\n"
     ]
    }
   ],
   "source": [
    "token = 'quantum'\n",
    "# print most similar terms\n",
    "word_idx = vocab[token]\n",
    "for idx, row in pd.Series(sim_mat[word_idx]).sort_values(ascending=False).head(10).iteritems():\n",
    "    print('%.3f' % row, inv_vocab[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In what way do these embeddings differ the TfIdf based ones we covered in class? Can you think of advantages/disadvantages for each approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These embeddings are based on cosine similarity with other words in the corpus, and Tf-Idf based embeddings are directly based on word countings.\n",
    "The advantage of new embeddings is that they rely more on relations between different words, but this would require more diverisity of words (i.e. the corpus cannot concentrate on one field).\n",
    "Tf-Idf based embeddings do not depend on the variety of words, and are more reliable when dealing with corpus from one industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Word vectors for different domains\n",
    "\n",
    "\n",
    "### In this problem we will creat embeddings for the `intro_text` column of the datasets `kdwd_featured_articles.csv` and `kdwd_r1k_articles.csv`\n",
    "### We can think of these as examples of 'generic' and 'finance specific' word representations\n",
    "\n",
    "## The goal of this exercise is to compare these two representations and find out which words change meaning the most across these two domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy.sparse as ssp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_df = pd.read_csv('./data/kdwd_featured_articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "finance_df = pd.read_csv('./data/kdwd_r1k_articles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create word representation for our 2 corpora using your favorite method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "generic_vectorizer = CountVectorizer(min_df=1, max_df=1.0)\n",
    "generic_mat = generic_vectorizer.fit_transform(generic_df['intro_text'].tolist());\n",
    "generic_vocab = {token: n for n, token in enumerate(pd.Series(generic_vectorizer.vocabulary_).sort_values().index)}\n",
    "inv_generic_vocab = {v: k for k, v in generic_vocab.items()}\n",
    "\n",
    "# generic_mat = ...\n",
    "# generic_vocab = ...\n",
    "\n",
    "finance_vectorizer = CountVectorizer(min_df=1, max_df=1.0)\n",
    "finance_mat = finance_vectorizer.fit_transform(finance_df['intro_text'].tolist());\n",
    "finance_vocab = {token: n for n, token in enumerate(pd.Series(finance_vectorizer.vocabulary_).sort_values().index)}\n",
    "inv_finance_vocab = {v: k for k, v in finance_vocab.items()}\n",
    "\n",
    "# finance_mat = ...\n",
    "# finance_vocab = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since our two corpora use different vocabulary we want to sub-select each representation matrix to be only of vacabulary tokens that occur in both corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_terms = list(set(generic_vocab) & set(finance_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7473"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_generic_mat = []\n",
    "filtered_finance_mat = []\n",
    "\n",
    "# your code here\n",
    "generic_idx = [generic_vocab[token] for token in common_terms]\n",
    "finance_idx = [finance_vocab[token] for token in common_terms]\n",
    "\n",
    "filtered_generic_mat = generic_mat[:, generic_idx]\n",
    "filtered_finance_mat = finance_mat[:, finance_idx]\n",
    "\n",
    "# filtered_generic_mat = ssp.hstack(filtered_generic_mat)\n",
    "# filtered_finance_mat = ssp.hstack(filtered_finance_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7473"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(finance_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5772x7473 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 713222 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_generic_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our documents for each corpus are different so there is no direct way of comparing our two representations, even though they now have the same dimension. To get them on equal footing, let's look at the word-word similarlity matrix for each domain.\n",
    "### Comparing these two, find terms that seem to have a drastically different meaning within the two domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the term-term similarity matrix\n",
    "generic_term_sim_mat = cosine_similarity(filtered_generic_mat.T)\n",
    "finance_term_sim_mat = cosine_similarity(filtered_finance_mat.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_drift_scores = {}\n",
    "for n, term in enumerate(common_terms):\n",
    "    term_sim = cosine_similarity([generic_term_sim_mat[:, n]], [finance_term_sim_mat[:, n]])\n",
    "    term_drift_scores[term] = term_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_drifts = pd.Series(term_drift_scores).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pancakes        [[0.0465687470074395]]\n",
       "halls          [[0.05271257056187872]]\n",
       "bellamy        [[0.06413322459933515]]\n",
       "unionized      [[0.06479199092767025]]\n",
       "circus         [[0.06604205658626511]]\n",
       "haas           [[0.06641566617675765]]\n",
       "voorhees       [[0.06723120162429506]]\n",
       "revitalized    [[0.06915824926278388]]\n",
       "xl             [[0.06971078807452873]]\n",
       "spyridon        [[0.0697388994062949]]\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_drifts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is      [[0.7659796761925033]]\n",
       "it      [[0.7715029488389068]]\n",
       "to      [[0.7778484621557051]]\n",
       "an      [[0.7837723025705567]]\n",
       "with    [[0.7859395808118057]]\n",
       "as      [[0.7948410070006259]]\n",
       "in      [[0.8027385264872345]]\n",
       "of      [[0.8028953174947108]]\n",
       "the     [[0.8157624343074169]]\n",
       "and     [[0.8158149578396093]]\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_drifts.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4: Corporate Similarity and Returns\n",
    "### In this example we'll explore how to use NLP to measure corporate similarity\n",
    "\n",
    "### In particular we will\n",
    " - ### Make word vectors for firms in order to get an NLP measure of similarity\n",
    " - ### Measure the quality of this similarity metric by predicting future co-movement of returns. \n",
    " \n",
    "## Step X: This problem uses a few concepts of basic modeling such as `sklearn.model_selection.train_test_split` and `sklearn.linear_model.LinearRegression`\n",
    "## Feel free to read some of the sklearn documentation, but otherwise we will cover these concepts next class\n",
    " \n",
    "\n",
    "# $ \\\\ $\n",
    "## Step 0: Load the MD&A section from Form-10-K from 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/mac/Desktop/MFin Materials/15.S08/data/parsed_mda.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'form': '10-K',\n",
       " 'company_name': 'ADOBE SYSTEMS INC',\n",
       " 'acc_id': 796343,\n",
       " 'date': '2016-01-19',\n",
       " 'filename': '0000796343-16-000224.txt',\n",
       " 'cik': '0000796343',\n",
       " 'full_filename': '/home/mikey/tmp/form10k/796343_0000796343-16-000224.txt',\n",
       " 'have_file': True,\n",
       " 'ticker': 'ADBE',\n",
       " 'mda': \"ITEM 7.  MANAGEMENT’S DISCUSSION AND ANALYSIS OF FINANCIAL CONDITION AND RESULTS OF OPERATIONS\\n\\nTHE FOLLOWING DISCUSSION SHOULD BE READ IN CONJUNCTION WITH OUR CONSOLIDATED FINANCIAL STATEMENTS AND NOTES THERETO.\\n\\nACQUISITIONS\\n\\nDURING FISCAL 2015, WE COMPLETED OUR ACQUISITION OF PRIVATELY HELD FOTOLIA, A LEADING MARKETPLACE FOR ROYALTY-FREE PHOTOS, IMAGES, GRAPHICS AND HD VIDEOS, FOR\\n\\n$807.5 MILLION\\n\\n. DURING FISCAL 2015, WE INTEGRATED FOTOLIA INTO OUR DIGITAL MEDIA REPORTABLE SEGMENT.\\n\\nDURING FISCAL 2013, WE COMPLETED OUR ACQUISITIONS OF PRIVATELY HELD NEOLANE, A LEADER IN CROSS-CHANNEL CAMPAIGN MANAGEMENT TECHNOLOGY FOR\\n\\n$616.7 MILLION\\n\\n, AND PRIVATELY HELD BEHANCE, AN ONLINE SOCIAL MEDIA PLATFORM TO SHOWCASE AND DISCOVER CREATIVE WORK FOR\\n\\n$111.1 MILLION\\n\\n. DURING FISCAL 2013, WE INTEGRATED NEOLANE AND BEHANCE INTO OUR DIGITAL MARKETING AND DIGITAL MEDIA REPORTABLE SEGMENTS, RESPECTIVELY.\\n\\nWE ALSO COMPLETED OTHER IMMATERIAL BUSINESS ACQUISITIONS DURING THE FISCAL YEARS PRESENTED. PRO FORMA INFORMATION HAS NOT BEEN PRESENTED FOR ANY OF OUR FISCAL 2015, 2014 AND 2013 ACQUISITIONS AS THE IMPACT TO OUR CONSOLIDATED FINANCIAL STATEMENTS WAS NOT MATERIAL.\\n\\nSEE NOTE 2 OF OUR NOTES TO CONSOLIDATED FINANCIAL STATEMENTS FOR FURTHER INFORMATION REGARDING THESE ACQUISITIONS.\\n\\nCRITICAL ACCOUNTING POLICIES AND ESTIMATES\\n\\nIN PREPARING OUR CONSOLIDATED FINANCIAL STATEMENTS IN ACCORDANCE WITH GAAP AND PURSUANT TO THE RULES AND REGULATIONS OF THE SEC, WE MAKE ASSUMPTIONS, JUDGMENTS AND ESTIMATES THAT AFFECT THE REPORTED AMOUNTS OF ASSETS, LIABILITIES, REVENUE AND EXPENSES, AND RELATED DISCLOSURES OF CONTINGENT ASSETS AND LIABILITIES. WE BASE OUR ASSUMPTIONS, JUDGMENTS AND ESTIMATES ON HISTORICAL EXPERIENCE AND VARIOUS OTHER FACTORS THAT WE BELIEVE TO BE REASONABLE UNDER THE CIRCUMSTANCES. ACTUAL RESULTS COULD DIFFER MATERIALLY FROM THESE ESTIMATES UNDER DIFFERENT ASSUMPTIONS OR CONDITIONS. ON A REGULAR BASIS, WE EVALUATE OUR ASSUMPTIONS, JUDGMENTS AND ESTIMATES. WE ALSO DISCUSS OUR CRITICAL ACCOUNTING POLICIES AND ESTIMATES WITH THE AUDIT COMMITTEE OF THE BOARD OF DIRECTORS.\\n\\nWE BELIEVE THAT THE ASSUMPTIONS, JUDGMENTS AND ESTIMATES INVOLVED IN THE ACCOUNTING FOR REVENUE RECOGNITION, BUSINESS COMBINATIONS, GOODWILL IMPAIRMENT AND INCOME TAXES HAVE THE GREATEST POTENTIAL IMPACT ON OUR CONSOLIDATED FINANCIAL STATEMENTS. THESE AREAS ARE KEY COMPONENTS OF OUR RESULTS OF OPERATIONS AND ARE BASED ON COMPLEX RULES REQUIRING US TO MAKE JUDGMENTS AND ESTIMATES, SO WE CONSIDER THESE TO BE OUR CRITICAL ACCOUNTING POLICIES. HISTORICALLY, OUR ASSUMPTIONS, JUDGMENTS AND ESTIMATES RELATIVE TO OUR CRITICAL ACCOUNTING POLICIES HAVE NOT DIFFERED MATERIALLY FROM ACTUAL RESULTS.\\n\\nREVENUE RECOGNITION\\n\\nOUR REVENUE IS DERIVED FROM THE LICENSING OF SUBSCRIPTION, PERPETUAL AND TIME-BASED SOFTWARE PRODUCTS, ASSOCIATED SOFTWARE MAINTENANCE AND SUPPORT PLANS, NON-SOFTWARE RELATED HOSTED SERVICES, CONSULTING SERVICES, TRAINING AND TECHNICAL SUPPORT.\\n\\nWE RECOGNIZE REVENUE WHEN ALL FOUR REVENUE RECOGNITION CRITERIA HAVE BEEN MET: PERSUASIVE EVIDENCE OF AN ARRANGEMENT EXISTS, WE HAVE DELIVERED THE PRODUCT OR PERFORMED THE SERVICE, THE FEE IS FIXED OR DETERMINABLE AND COLLECTION IS PROBABLE. DETERMINING WHETHER AND WHEN SOME OF THESE CRITERIA HAVE BEEN SATISFIED OFTEN INVOLVES ASSUMPTIONS AND JUDGMENTS THAT CAN HAVE A SIGNIFICANT IMPACT ON THE TIMING AND AMOUNT OF REVENUE WE REPORT.\\n\\nWE ENTER INTO MULTIPLE ELEMENT REVENUE ARRANGEMENTS IN WHICH A CUSTOMER MAY PURCHASE A COMBINATION OF SOFTWARE, UPGRADES, MAINTENANCE AND SUPPORT, HOSTED SERVICES AND CONSULTING.\\n\\nFOR OUR SOFTWARE AND SOFTWARE-RELATED MULTIPLE ELEMENT ARRANGEMENTS, WE MUST: (1) DETERMINE WHETHER AND WHEN EACH ELEMENT HAS BEEN DELIVERED; (2) DETERMINE WHETHER UNDELIVERED PRODUCTS OR SERVICES ARE ESSENTIAL TO THE FUNCTIONALITY OF THE DELIVERED PRODUCTS AND SERVICES; (3) DETERMINE THE FAIR VALUE OF EACH UNDELIVERED ELEMENT USING VENDOR-SPECIFIC OBJECTIVE EVIDENCE (“VSOE”); AND (4) ALLOCATE THE TOTAL PRICE AMONG THE VARIOUS ELEMENTS. VSOE OF FAIR VALUE IS USED TO ALLOCATE A PORTION OF THE PRICE TO THE UNDELIVERED ELEMENTS AND THE RESIDUAL METHOD IS USED TO ALLOCATE THE REMAINING PORTION TO THE DELIVERED ELEMENTS. ABSENT VSOE, REVENUE IS DEFERRED UNTIL THE EARLIER OF THE POINT AT WHICH VSOE OF FAIR VALUE EXISTS FOR ANY UNDELIVERED ELEMENT OR UNTIL ALL ELEMENTS OF THE ARRANGEMENT HAVE BEEN DELIVERED. HOWEVER, IF THE ONLY UNDELIVERED ELEMENT IS MAINTENANCE AND SUPPORT, THE ENTIRE ARRANGEMENT FEE IS RECOGNIZED RATABLY OVER THE PERFORMANCE PERIOD. CHANGES IN ASSUMPTIONS OR JUDGMENTS OR CHANGES TO THE ELEMENTS IN A SOFTWARE ARRANGEMENT COULD CAUSE A MATERIAL INCREASE OR DECREASE IN THE AMOUNT OF REVENUE THAT WE REPORT IN A PARTICULAR PERIOD.\\n\\n35\\n\\nTABLE OF CONTENTS\\n\\nWE DETERMINE VSOE FOR EACH ELEMENT BASED ON HISTORICAL STAND-ALONE SALES TO THIRD PARTIES OR FROM THE STATED RENEWAL RATE FOR THE ELEMENTS CONTAINED IN THE INITIAL ARRANGEMENT. IN DETERMINING VSOE, WE REQUIRE THAT A SUBSTANTIAL MAJORITY OF THE SELLING PRICES FOR A PRODUCT OR SERVICE FALL WITHIN A REASONABLY NARROW PRICING RANGE.\\n\\nWE HAVE ESTABLISHED VSOE FOR OUR SOFTWARE MAINTENANCE AND SUPPORT SERVICES, CUSTOM SOFTWARE DEVELOPMENT SERVICES, CON\\n\\nSULTING SERVICES AND TRAINING, WHEN SUCH SERVICES ARE SOLD OPTIONALLY WITH SOFTWARE LICENSES.\\n\\nFOR MULTIPLE-ELEMENT ARRANGEMENTS CONTAINING OUR NON-SOFTWARE SERVICES, WE MUST: (1) DETERMINE WHETHER AND WHEN EACH ELEMENT HAS BEEN DELIVERED; (2) DETERMINE THE FAIR VALUE OF EACH ELEMENT USING THE SELLING PRICE HIERARCHY OF VSOE OF SELLING PRICE, THIRD-PARTY EVIDENCE (“TPE”) OF SELLING PRICE OR BEST-ESTIMATED SELLING PRICE (“BESP”), AS APPLICABLE; AND (3) ALLOCATE THE TOTAL PRICE AMONG THE VARIOUS ELEMENTS BASED ON THE RELATIVE SELLING PRICE METHOD.\\n\\nFOR MULTIPLE-ELEMENT ARRANGEMENTS THAT CONTAIN BOTH SOFTWARE AND NON-SOFTWARE ELEMENTS, WE ALLOCATE REVENUE TO SOFTWARE OR SOFTWARE-RELATED ELEMENTS AS A GROUP AND ANY NON-SOFTWARE ELEMENTS SEPARATELY BASED ON THE SELLING PRICE HIERARCHY. WE DETERMINE THE SELLING PRICE FOR EACH DELIVERABLE USING VSOE OF SELLING PRICE, IF IT EXISTS, OR TPE OF SELLING PRICE. IF NEITHER VSOE NOR TPE OF SELLING PRICE EXIST FOR A DELIVERABLE, WE USE BESP. ONCE REVENUE IS ALLOCATED TO SOFTWARE OR SOFTWARE-RELATED ELEMENTS AS A GROUP, WE RECOGNIZE REVENUE IN CONFORMANCE WITH SOFTWARE REVENUE ACCOUNTING GUIDANCE. REVENUE IS RECOGNIZED WHEN REVENUE RECOGNITION CRITERIA ARE MET FOR EACH ELEMENT.\\n\\nWE ARE GENERALLY UNABLE TO ESTABLISH VSOE OR TPE FOR NON-SOFTWARE ELEMENTS AND AS SUCH, WE USE BESP. BESP IS GENERALLY USED FOR OFFERINGS THAT ARE NOT TYPICALLY SOLD ON A STAND-ALONE BASIS OR FOR NEW OR HIGHLY CUSTOMIZED OFFERINGS. WE DETERMINE BESP FOR A PRODUCT OR SERVICE BY CONSIDERING MULTIPLE FACTORS INCLUDING, BUT NOT LIMITED TO, MAJOR PRODUCT GROUPINGS, GEOGRAPHIES, MARKET CONDITIONS, COMPETITIVE LANDSCAPE, INTERNAL COSTS, GROSS MARGIN OBJECTIVES AND PRICING PRACTICES. PRICING PRACTICES TAKEN INTO CONSIDERATION INCLUDE HISTORIC CONTRACTUALLY STATED PRICES, VOLUME DISCOUNTS WHERE APPLICABLE AND OUR PRICE LISTS. WE MUST ESTIMATE CERTAIN ROYALTY REVENUE AMOUNTS DUE TO THE TIMING OF SECURING INFORMATION FROM OUR CUSTOMERS. WHILE WE BELIEVE WE CAN MAKE RELIABLE ESTIMATES REGARDING THESE MATTERS, THESE ESTIMATES ARE INHERENTLY SUBJECTIVE. ACCORDINGLY, OUR ASSUMPTIONS AND JUDGMENTS REGARDING FUTURE PRODUCTS AND SERVICES AS WELL AS OUR ESTIMATES OF ROYALTY REVENUE COULD DIFFER FROM ACTUAL EVENTS, THUS MATERIALLY IMPACTING OUR FINANCIAL POSITION AND RESULTS OF OPERATIONS.\\n\\nPRODUCT REVENUE IS RECOGNIZED WHEN THE ABOVE CRITERIA ARE MET. WE REDUCE THE REVENUE RECOGNIZED FOR ESTIMATED FUTURE RETURNS, PRICE PROTECTION AND REBATES AT THE TIME THE RELATED REVENUE IS RECORDED. IN DETERMINING OUR ESTIMATE FOR RETURNS AND IN ACCORDANCE WITH OUR INTERNAL POLICY REGARDING GLOBAL CHANNEL INVENTORY WHICH IS USED TO DETERMINE THE LEVEL OF PRODUCT HELD BY OUR DISTRIBUTORS ON WHICH WE HAVE RECOGNIZED REVENUE, WE RELY UPON HISTORICAL DATA, THE ESTIMATED AMOUNT OF PRODUCT INVENTORY IN OUR DISTRIBUTION CHANNEL, THE RATE AT WHICH OUR PRODUCT SELLS THROUGH TO THE END USER, PRODUCT PLANS AND OTHER FACTORS. OUR ESTIMATED PROVISIONS FOR RETURNS CAN VARY FROM WHAT ACTUALLY OCCURS. PRODUCT RETURNS MAY BE MORE OR LESS THAN WHAT WAS ESTIMATED. THE AMOUNT OF INVENTORY IN THE CHANNEL COULD BE DIFFERENT THAN WHAT IS ESTIMATED. OUR ESTIMATE OF THE RATE OF SELL-THROUGH FOR PRODUCT IN THE CHANNEL COULD BE DIFFERENT THAN WHAT ACTUALLY OCCURS. THERE COULD BE A DELAY IN THE RELEASE OF OUR PRODUCTS. THESE FACTORS AND UNANTICIPATED CHANGES IN THE ECONOMIC AND INDUSTRY ENVIRONMENT COULD MAKE OUR RETURN ESTIMATES DIFFER FROM ACTUAL RETURNS, THUS IMPACTING OUR FINANCIAL POSITION AND RESULTS OF OPERATIONS.\\n\\nIN THE FUTURE, ACTUAL RETURNS AND PRICE PROTECTION MAY EXCEED OUR ESTIMATES AS UNSOLD PRODUCTS IN THE DISTRIBUTION CHANNELS ARE EXPOSED TO RAPID CHANGES IN CONSUMER PREFERENCES, MARKET CONDITIONS OR TECHNOLOGICAL OBSOLESCENCE DUE TO NEW PLATFORMS, PRODUCT UPDATES OR COMPETING PRODUCTS. WHILE WE BELIEVE WE CAN MAKE RELIABLE ESTIMATES REGARDING THESE MATTERS, THESE ESTIMATES ARE INHERENTLY SUBJECTIVE. ACCORDINGLY, IF OUR ESTIMATES CHANGE, OUR RETURNS AND PRICE PROTECTION RESERVES WOULD CHANGE, WHICH WOULD IMPACT THE TOTAL NET REVENUE WE REPORT.\\n\\nWE RECOGNIZE REVENUE FOR HOSTED SERVICES THAT ARE BASED ON A COMMITTED NUMBER OF TRANSACTIONS RATABLY BEGINNING ON THE DATE THE SERVICES ARE FIRST MADE AVAILABLE TO THE CUSTOMER AND CONTINUING THROUGH THE END OF THE CONTRACTUAL SERVICE TERM. OVER-USAGE FEES, AND FEES BILLED BASED ON THE ACTUAL NUMBER OF TRANSACTIONS FROM WHICH WE CAPTURE DATA, ARE BILLED IN ACCORDANCE WITH CONTRACT TERMS AS THESE FEES ARE INCURRED. WE RECORD AMOUNTS THAT HAVE BEEN INVOICED IN ACCOUNTS RECEIVABLE AND IN DEFERRED REVENUE OR REVENUE, DEPENDING ON WHETHER THE REVENUE RECOGNITION CRITERIA HAVE BEEN MET.\\n\\nOUR CONSULTING REVENUE IS RECOGNIZED ON A TIME AND MATERIALS BASIS AND IS MEASURED MONTHLY BASED ON INPUT MEASURES, SUCH AS ON HOURS INCURRED TO DATE COMPARED TO TOTAL ESTIMATED HOURS TO COMPLETE, WITH CONSIDERATION GIVEN TO OUTPUT MEASURES, SUCH AS CONTRACT MILESTONES, WHEN APPLICABLE.\\n\\nBUSINESS COMBINATIONS\\n\\nWE ALLOCATE THE PURCHASE PRICE OF ACQUIRED COMPANIES TO THE TANGIBLE AND INTANGIBLE ASSETS ACQUIRED AND LIABILITIES ASSUMED, ASSUMED EQUITY AWARDS, AS WELL AS TO IN-PROCESS RESEARCH AND DEVELOPMENT BASED UPON THEIR ESTIMATED FAIR VALUES AT THE ACQUISITION\\n\\n36\\n\\nTABLE OF CONTENTS\\n\\nDATE. THE PURCHASE PRICE ALLOCATION PROCESS REQUIRES MANAGEMENT TO MAKE SIGNIFICANT ESTIMATES AND ASSUMPTIONS, ESPECIALLY AT THE ACQUISITION DATE WITH RESPECT TO INTANGIBLE ASSETS, DEFERRED REVENUE OBLIGATIONS AND EQUITY ASSUMED.\\n\\nALTHOUGH WE BELIEVE THE ASSUMPTIONS AND ESTIMATES WE HAVE MADE ARE REASONABLE, THEY ARE BASED IN PART ON HISTORICAL EXPERIENCE AND INFORMATION OBTAINED FROM THE MANAGEMENT OF THE ACQUIRED COMPANIES AND ARE INHERENTLY UNCERTAIN. EXAMPLES OF CRITICAL ESTIMATES IN VALUING CERTAIN OF THE INTANGIBLE ASSETS WE HAVE ACQUIRED OR MAY ACQUIRE IN THE FUTURE INCLUDE BUT ARE NOT LIMITED TO.\\n\\n•\\n\\nFUTURE EXPECTED CASH FLOWS FROM SOFTWARE LICENSE SALES, SUBSCRIPTIONS, SUPPORT AGREEMENTS, CONSULTING CONTRACTS AND ACQUIRED DEVELOPED TECHNOLOGIES AND PATENTS;\\n\\n•\\n\\nEXPECTED COSTS TO DEVELOP THE IN-PROCESS RESEARCH AND DEVELOPMENT INTO COMMERCIALLY VIABLE PRODUCTS AND ESTIMATED CASH FLOWS FROM THE PROJECTS WHEN COMPLETED;\\n\\n•\\n\\nTHE ACQUIRED COMPANY’S TRADE NAME AND TRADEMARKS AS WELL AS ASSUMPTIONS ABOUT THE PERIOD OF TIME THE ACQUIRED TRADE NAME AND TRADEMARKS WILL CONTINUE TO BE USED IN THE COMBINED COMPANY’S PRODUCT PORTFOLIO; AND\\n\\n•\\n\\nDISCOUNT RATES.\\n\\nIN CONNECTION WITH THE PURCHASE PRICE ALLOCATIONS FOR OUR ACQUISITIONS, WE ESTIMATE THE FAIR VALUE OF THE DEFERRED REVENUE OBLIGATIONS ASSUMED. THE ESTIMATED FAIR VALUE OF THE SUPPORT OBLIGATIONS IS DETERMINED UTILIZING A COST BUILD-UP APPROACH. THE COST BUILD-UP APPROACH DETERMINES FAIR VALUE BY ESTIMATING THE COSTS RELATED TO FULFILLING THE OBLIGATIONS PLUS A NORMAL PROFIT MARGIN. THE ESTIMATED COSTS TO FULFILL THE OBLIGATIONS ARE BASED ON THE HISTORICAL COSTS RELATED TO FULFILLING THE OBLIGATIONS.\\n\\nIN CONNECTION WITH THE PURCHASE PRICE ALLOCATIONS FOR OUR ACQUISITIONS, WE ESTIMATE THE FAIR VALUE OF THE EQUITY AWARDS ASSUMED. THE ESTIMATED FAIR VALUE IS DETERMINED UTILIZING A MODIFIED BINOMIAL OPTION PRICING MODEL WHICH ASSUMES EMPLOYEES EXERCISE THEIR STOCK OPTIONS WHEN THE SHARE PRICE EXCEEDS THE STRIKE PRICE BY A CERTAIN DOLLAR THRESHOLD. IF THE ACQUIRED COMPANY HAS SIGNIFICANT HISTORICAL DATA ON THEIR EMPLOYEE’S EXERCISE BEHAVIOR, THEN THIS THRESHOLD IS DETERMINED BASED UPON THE ACQUIRED COMPANY’S HISTORY. OTHERWISE, OUR HISTORICAL EXERCISE EXPERIENCE IS USED TO DETERMINE THE EXERCISE THRESHOLD. ZERO COUPON YIELDS IMPLIED BY U.S. TREASURY ISSUANCES, IMPLIED VOLATILITY FOR OUR COMMON STOCK AND OUR HISTORICAL FORFEITURE RATE ARE OTHER INPUTS TO THE BINOMIAL MODEL.\\n\\nUNANTICIPATED EVENTS AND CIRCUMSTANCES MAY OCCUR WHICH MAY AFFECT THE ACCURACY OR VALIDITY OF SUCH ASSUMPTIONS, ESTIMATES OR ACTUAL RESULTS.\\n\\nGOODWILL IMPAIRMENT\\n\\nWE COMPLETE OUR GOODWILL IMPAIRMENT TEST ON AN ANNUAL BASIS, DURING THE SECOND QUARTER OF OUR FISCAL YEAR, OR MORE FREQUENTLY, IF CHANGES IN FACTS AND CIRCUMSTANCES INDICATE THAT AN IMPAIRMENT IN THE VALUE OF GOODWILL RECORDED ON OUR BALANCE SHEET MAY EXIST. IN ORDER TO ESTIMATE THE FAIR VALUE OF GOODWILL, WE TYPICALLY ESTIMATE FUTURE REVENUE, CONSIDER MARKET FACTORS AND ESTIMATE OUR FUTURE CASH FLOWS. BASED ON THESE KEY ASSUMPTIONS, JUDGMENTS AND ESTIMATES, WE DETERMINE WHETHER WE NEED TO RECORD AN IMPAIRMENT CHARGE TO REDUCE THE VALUE OF THE ASSET CARRIED ON OUR BALANCE SHEET TO ITS ESTIMATED FAIR VALUE. ASSUMPTIONS, JUDGMENTS AND ESTIMATES ABOUT FUTURE VALUES ARE COMPLEX AND OFTEN SUBJECTIVE. THEY CAN BE AFFECTED BY A VARIETY OF FACTORS, INCLUDING EXTERNAL FACTORS SUCH AS INDUSTRY AND ECONOMIC TRENDS, AND INTERNAL FACTORS SUCH AS CHANGES IN OUR BUSINESS STRATEGY OR OUR INTERNAL FORECASTS. ALTHOUGH WE BELIEVE THE ASS\\n\\nUMPTIONS, JUDGME\\n\\nNTS AND ESTIMATES WE HAVE MADE IN THE PAST HAVE BEEN REASONABLE AND APPROPRIATE, DIFFERENT ASSUMPTIONS, JUDGMENTS AND ESTIMATES COULD MATERIALLY AFFECT OUR REPORTED FINANCIAL RESULTS.\\n\\nWE COMPLETED OUR ANNUAL IMPAIRMENT TEST IN THE SECOND QUARTER OF FISCAL\\n\\n2015\\n\\nAND DETERMINED THERE WAS NO IMPAIRMENT. THE RESULTS OF OUR ANNUAL IMPAIRMENT TEST INDICATE THAT THE FAIR VALUES OF OUR REPORTING UNITS ARE SIGNIFICANTLY IN EXCESS OF THEIR CARRYING VALUES.\\n\\nACCOUNTING FOR INCOME TAXES\\n\\nWE USE THE ASSET AND LIABILITY METHOD OF ACCOUNTING FOR INCOME TAXES. UNDER THIS METHOD, INCOME TAX EXPENSE IS RECOGNIZED FOR THE AMOUNT OF TAXES PAYABLE OR REFUNDABLE FOR THE CURRENT YEAR. IN ADDITION, DEFERRED TAX ASSETS AND LIABILITIES ARE RECOGNIZED FOR THE EXPECTED FUTURE TAX CONSEQUENCES OF TEMPORARY DIFFERENCES BETWEEN THE FINANCIAL REPORTING AND TAX BASES OF ASSETS AND LIABILITIES, AND FOR OPERATING LOSSES AND TAX CREDIT CARRYFORWARDS. MANAGEMENT MUST MAKE ASSUMPTIONS, JUDGMENTS AND ESTIMATES TO DETERMINE OUR CURRENT PROVISION FOR INCOME TAXES AND ALSO OUR DEFERRED TAX ASSETS AND LIABILITIES AND ANY VALUATION ALLOWANCE TO BE RECORDED AGAINST A DEFERRED TAX ASSET.\\n\\nOUR ASSUMPTIONS, JUDGMENTS AND ESTIMATES RELATIVE TO THE CURRENT PROVISION FOR INCOME TAXES TAKE INTO ACCOUNT CURRENT TAX LAWS, OUR INTERPRETATION OF CURRENT TAX LAWS AND POSSIBLE OUTCOMES OF CURRENT AND FUTURE AUDITS CONDUCTED BY FOREIGN AND DOMESTIC\\n\\n37\\n\\nTABLE OF CONTENTS\\n\\nTAX AUTHORITIES. WE HAVE ESTABLISHED RESERVES FOR INCOME TAXES TO ADDRESS POTENTIAL EXPOSURES INVOLVING TAX POSITIONS THAT COULD BE CHALLENGED BY TAX AUTHORITIES. IN ADDITION, WE ARE SUBJECT TO THE CONTINUAL EXAMINATION OF OUR INCOME TAX RETURNS BY THE IRS AND OTHER DOMESTIC AND FOREIGN TAX AUTHORITIES, INCLUDING A CURRENT EXAMINATION BY THE IRS OF OUR FISCAL 2010, 2011 AND 2012 TAX RETURNS. WE EXPECT FUTURE EXAMINATIONS TO FOCUS ON OUR INTERCOMPANY TRANSFER PRICING PRACTICES AS WELL AS OTHER MATTERS. WE REGULARLY ASSESS THE LIKELIHOOD OF OUTCOMES RESULTING FROM THESE EXAMINATIONS TO DETERMINE THE ADEQUACY OF OUR PROVISION FOR INCOME TAXES AND HAVE RESERVED FOR POTENTIAL ADJUSTMENTS THAT MAY RESULT FROM THE CURRENT EXAMINATIONS. WE BELIEVE SUCH ESTIMATES TO BE REASONABLE; HOWEVER,  THE FINAL DETERMINATION OF ANY OF THESE EXAMINATIONS COULD SIGNIFICANTLY IMPACT THE AMOUNTS PROVIDED FOR INCOME TAXES IN OUR CONSOLIDATED FINANCIAL STATEMENTS.\\n\\nOUR ASSUMPTIONS, JUDGMENTS AND ESTIMATES RELATIVE TO THE VALUE OF A DEFERRED TAX ASSET TAKE INTO ACCOUNT PREDICTIONS OF THE AMOUNT AND CATEGORY OF FUTURE TAXABLE INCOME, SUCH AS INCOME FROM OPERATIONS OR CAPITAL GAINS INCOME. ACTUAL OPERATING RESULTS AND THE UNDERLYING AMOUNT AND CATEGORY OF INCOME IN FUTURE YEARS COULD RENDER OUR CURRENT ASSUMPTIONS, JUDGMENTS AND ESTIMATES OF RECOVERABLE NET DEFERRED TAXES INACCURATE. ANY OF THE ASSUMPTIONS, JUDGMENTS AND ESTIMATES MENTIONED ABOVE COULD CAUSE OUR ACTUAL INCOME TAX OBLIGATIONS TO DIFFER FROM OUR ESTIMATES, THUS MATERIALLY IMPACTING OUR FINANCIAL POSITION AND RESULTS OF OPERATIONS.\\n\\nWE ARE A UNITED STATES-BASED MULTINATIONAL COMPANY SUBJECT TO TAX IN MULTIPLE U.S. AND FOREIGN TAX JURISDICTIONS. A SIGNIFICANT PORTION OF OUR FOREIGN EARNINGS FOR THE CURRENT FISCAL YEAR WERE EARNED BY OUR IRISH SUBSIDIARIES. IN ADDITION TO PROVIDING FOR U.S. INCOME TAXES ON EARNINGS FROM THE UNITED STATES, WE PROVIDE FOR U.S. INCOME TAXES ON THE EARNINGS OF FOREIGN SUBSIDIARIES UNLESS THE SUBSIDIARIES’ EARNINGS ARE CONSIDERED PERMANENTLY REINVESTED OUTSIDE THE UNITED STATES. WHILE WE DO NOT ANTICIPATE CHANGING OUR INTENTION REGARDING PERMANENTLY REINVESTED EARNINGS, IF CERTAIN FOREIGN EARNINGS PREVIOUSLY TREATED AS PERMANENTLY REINVESTED ARE REPATRIATED, THE RELATED U.S. TAX LIABILITY MAY BE REDUCED BY ANY FOREIGN INCOME TAXES PAID ON THESE EARNINGS.\\n\\nOUR INCOME TAX EXPENSE HAS DIFFERED FROM THE TAX COMPUTED AT THE U.S. FEDERAL STATUTORY INCOME TAX RATE DUE PRIMARILY TO DISCRETE ITEMS AND TO EARNINGS CONSIDERED AS PERMANENTLY REINVESTED IN FOREIGN OPERATIONS. UNANTICIPATED CHANGES IN OUR TAX RATES COULD AFFECT OUR FUTURE RESULTS OF OPERATIONS. OUR FUTURE EFFECTIVE TAX RATES COULD BE UNFAVORABLY AFFECTED BY CHANGES IN THE TAX RATES IN JURISDICTIONS WHERE OUR INCOME IS EARNED, BY CHANGES IN, OR OUR INTERPRETATION OF, TAX RULES AND REGULATIONS IN THE JURISDICTIONS IN WHICH WE DO BUSINESS, BY UNANTICIPATED DECREASES IN THE AMOUNT OF EARNINGS IN COUNTRIES WITH LOW STATUTORY TAX RATES, OR BY CHANGES IN THE VALUATION OF OUR DEFERRED TAX ASSETS AND LIABILITIES. THE UNITED STATES, COUNTRIES IN THE EUROPEAN UNION AND OTHER COUNTRIES WHERE WE DO BUSINESS HAVE BEEN CONSIDERING CHANGES IN RELEVANT TAX, ACCOUNTING AND OTHER LAWS, REGULATIONS AND INTERPRETATIONS, INCLUDING CHANGES TO TAX LAWS APPLICABLE TO CORPORATE MULTINATIONALS SUCH AS ADOBE. THESE POTENTIAL CHANGES COULD ADVERSELY AFFECT OUR EFFECTIVE TAX RATES OR RESULT IN OTHER COSTS TO US.\\n\\nRECENT ACCOUNTING PRONOUNCEMENTS\\n\\nON NOVEMBER 20, 2015, THE FINANCIAL ACCOUNTING STANDARDS BOARD (“FASB”) ISSUED ASU NO. 2015-17, BALANCE SHEET CLASSIFICATION OF DEFERRED TAXES, REQUIRING ALL DEFERRED TAX ASSETS AND LIABILITIES, AND ANY RELATED VALUATION ALLOWANCE, TO BE CLASSIFIED AS NON-CURRENT ON THE BALANCE SHEET. THE CLASSIFICATION CHANGE FOR ALL DEFERRED TAXES AS NON-CURRENT SIMPLIFIES ENTITIES’ PROCESSES AS IT ELIMINATES THE NEED TO SEPARATELY IDENTIFY THE NET CURRENT AND NET NON-CURRENT DEFERRED TAX ASSET OR LIABILITY IN EACH JURISDICTION AND ALLOCATE VALUATION ALLOWANCES. WE ELECTED TO PROSPECTIVELY ADOPT THE ACCOUNTING STANDARD IN THE BEGINNING OF OUR FOURTH QUARTER OF FISCAL 2015. PRIOR PERIODS IN OUR CONSOLIDATED FINANCIAL STATEMENTS WERE NOT RETROSPECTIVELY ADJUSTED.\\n\\nRECENT ACCOUNTING PRONOUNCEMENTS NOT YET EFFECTIVE\\n\\nON MAY 28, 2014, THE FASB ISSUED ASU NO. 2014-09, REVENUE FROM CONTRACTS WITH CUSTOMERS, REQUIRING AN ENTITY TO RECOGNIZE THE AMOUNT OF REVENUE TO WHICH IT EXPECTS TO BE ENTITLED FOR THE TRANSFER OF PROMISED GOODS OR SERVICES TO CUSTOMERS. THE UPDATED STANDARD WILL REPLACE MOST EXISTING REVENUE RECOGNITION GUIDANCE IN U.S. GAAP WHEN IT BECOMES EFFECTIVE AND PERMITS THE USE OF EITHER THE RETROSPECTIVE OR CUMULATIVE EFFECT TRANSITION METHOD. IN AUGUST 2015, THE FASB ISSUED ASU NO. 2015-14, REVENUE FROM CONTRACTS WITH CUSTOMERS: DEFERRAL OF THE EFFECTIVE DATE, WHICH DEFERRED THE EFFECTIVE DATE OF THE NEW REVENUE STANDARD FOR PERIODS BEGINNING AFTER DECEMBER 15, 2016 TO DECEMBER 15, 2017, WITH EARLY ADOPTION PERMITTED BUT NOT EARLIER THAN THE ORIGINAL EFFECTIVE DATE. ACCORDINGLY, THE UPDATED STANDARD IS EFFECTIVE FOR US IN THE FIRST QUARTER OF FISCAL 2019. WE HAVE NOT YET SELECTED A TRANSITION METHOD AND WE ARE CURRENTLY EVALUATING THE EFFECT THAT THE UPDATED STANDARD WILL HAVE ON OUR CONSOLIDATED FINANCIAL STATEMENTS AND RELATED DISCLOSURES.\\n\\nWITH THE EXCEPTION OF THE NEW REVENUE STANDARD DISCUSSED ABOVE, THERE HAVE BEEN NO NEW ACCOUNTING PRONOUNCEMENTS NOT YET EFFECTIVE THAT HAVE SIGNIFICANCE, OR POTENTIAL SIGNIFICANCE, TO OUR CONSOLIDATED FINANCIAL STATEMENTS.\\n\\n38\\n\\nTABLE OF CONTENTS\\n\\nRESULTS OF OPERATIONS\\n\\nOVERVIEW OF\\n\\n2015\\n\\nFOR FISCAL 2015, WE REPORTED FINANCIAL RESULTS CONSISTENT WITH THE CONTINUED EXECUTION OF OUR LONG-TERM PLANS FOR OUR TWO STRATEGIC GROWTH AREAS, DIGITAL MEDIA AND DIGITAL MARKETING, WHILE CONTINUING TO MARKET AND LICENSE A BROAD PORTFOLIO OF PRODUCTS AND SOLUTIONS.\\n\\nIN OUR DIGITAL MEDIA SEGMENT, WE ARE A MARKET LEADER WITH ADOBE CREATIVE CLOUD, OUR SUBSCRIPTION-BASED OFFERING FOR CREATING AND PUBLISHING CONTENT AND APPLICATIONS. CREATIVE CLOUD, FIRST DELIVERED IN MAY 2012, IS OUR NEXT-GENERATION OFFERING THAT SUPERSEDES OUR HISTORICAL MODEL OF LICENSING OUR CREATIVE PRODUCTS WITH PERPETUAL LICENSES. CREATIVE CLOUD DELIVERS VALUE THROUGH MORE FREQUENT PRODUCT UPDATES, STORAGE AND ACCESS TO USER FILES STORED IN THE CLOUD WITH SYNCING OF FILES ACROSS USERS' MACHINES, ACCESS TO MARKETPLACE, SOCIAL AND COMMUNITY-BASED FEATURES WITH OUR ADOBE STOCK AND BEHANCE SERVICES, APP CREATION CAPABILITIES AND LOWER ENTRY POINT PRICING FOR COST-SENSITIVE CUSTOMERS.\\n\\nWE OFFER CREATIVE CLOUD FOR INDIVIDUALS AND FOR TEAMS, AND WE ENABLE LARGER ENTERPRISE CUSTOMERS TO ACQUIRE CREATIVE CLOUD CAPABILITIES THROUGH ENTERPRISE TERM LICENSE AGREEMENTS (“ETLAS”). THE THREE CREATIVE CLOUD OFFERINGS ADDRESS THE MULTIPLE ROUTES TO MARKET WE USE TO LICENSE OUR CREATIVE SOFTWARE TO TARGETED CUSTOMERS. ADOPTION OF CREATIVE CLOUD HAS TRANSFORMED OUR BUSINESS MODEL, AND WE CONTINUE TO EXPECT THIS TO DRIVE HIGHER LONG-TERM REVENUE GROWTH THROUGH AN EXPANSION OF OUR CUSTOMER BASE BY ACQUIRING NEW USERS THROUGH A LOWER COST OF ENTRY AND DELIVERY OF ADDITIONAL FEATURES AND VALUE, AS WELL AS KEEPING EXISTING CUSTOMERS CURRENT ON OUR LATEST RELEASE. WE HAVE ALSO BUILT OUT A MARKETPLACE FOR CREATIVE CLOUD SUBSCRIBERS, MOST NOTABLY WITH OUR ACQUISITION OF FOTOLIA IN JANUARY OF 2015, TO ENABLE THE DELIVERY AND PURCHASE OF STOCK ASSETS IN OUR NEW SERVICE CALLED ADOBE STOCK.  OVERALL, OUR STRATEGY WITH CREATIVE CLOUD IS DESIGNED TO ENABLE US TO INCREASE OUR REVENUE WITH USERS, ATTRACT MORE NEW CUSTOMERS, AND SHIFT OUR REVENUE TO BE MORE RECURRING AND PREDICTABLE AS REVENUE IS RECOGNIZED RATABLY.\\n\\nWE CONTINUE TO IMPLEMENT STRATEGIES THAT WILL ACCELERATE AWARENESS, CONSIDERATION AND PURCHASE OF SUBSCRIPTIONS TO OUR CREATIVE CLOUD OFFERING. THESE STRATEGIES INCLUDE INCREASING THE VALUE CREATIVE CLOUD USERS RECEIVE SUCH AS OFFERING NEW MOBILE APPLICATIONS, AS WELL AS TARGETED PROMOTIONS AND OFFERS THAT ATTRACT PAST CUSTOMERS AND POTENTIAL USERS TO TRY OUT AND ULTIMATELY SUBSCRIBE TO CREATIVE CLOUD.  BECAUSE OF THE SHIFT TOWARDS CREATIVE CLOUD SUBSCRIPTIONS AND ETLAS, PERPETUAL REVENUE FOR OLDER CREATIVE PRODUCTS HAS CONTINUED TO DECLINE, AND REVENUE FROM PERPETUAL LICENSING OF THESE PRODUCTS WAS IMMATERIAL FOR FISCAL 2015.\\n\\nWE ARE ALSO A MARKET LEADER WITH OUR DOCUMENT CLOUD OFFERINGS BUILT AROUND OUR ACROBAT FAMILY OF PRODUCTS, THE ADOBE READER DC AND A SET OF INTEGRATED CLOUD-BASED DOCUMENT SERVICES, INCLUDING ADOBE ESIGN. ADOBE ACROBAT PROVIDES RELIABLE CREATION AND EXCHANGE OF ELECTRONIC DOCUMENTS, REGARDLESS OF PLATFORM OR APPLICATION SOURCE TYPE.  IN THE SECOND QUARTER OF FISCAL 2015, WE DELIVERED THE NEXT GENERATION OF THIS OFFERING CALLED ADOBE DOCUMENT CLOUD, WHICH WE BELIEVE ENHANCES THE WAY PEOPLE MANAGE CRITICAL DOCUMENTS AT HOME, IN THE OFFICE AND ACROSS DEVICES.  ADOBE DOCUMENT CLOUD INCLUDES ALL-NEW ADOBE ACROBAT DC AND ADOBE ESIGN RELEASES AND A SET OF INTEGRATED SERVICES ENABLE USERS TO CREATE, REVIEW, APPROVE, SIGN AND TRACK DOCUMENTS WHETHER ON A DESKTOP OR MOBILE DEVICE. ACROBAT DC, WITH A TOUCH-ENABLED USER INTERFACE, IS LICENSED BOTH THROUGH SUBSCRIPTION AND PERPETUAL PRICING.\\n\\nANNUALIZED RECURRING REVENUE (“ARR”) IS CURRENTLY OUR KEY PERFORMANCE METRIC TO ASSESS THE HEALTH AND TRAJECTORY OF OUR OVERALL DIGITAL MEDIA SEGMENT. ARR SHOULD BE VIEWED INDEPENDENTLY OF REVENUE, DEFERRED REVENUE AND UNBILLED DEFERRED REVENUE AS ARR IS A PERFORMANCE METRIC AND IS NOT INTENDED TO BE COMBINED WITH ANY OF THESE ITEMS. WE PLAN TO ADJUST OUR REPORTED ARR ON AN ANNUAL BASIS TO REFLECT ANY MATERIAL EXCHANGE RATES CHANGES. WE CALCULATE ARR AS FOLLOWS.\\n\\nCREATIVE ARR\\n\\nANNUAL VALUE OF CREATIVE CLOUD SUBSCRIPTIONS AND SERVICES\\n\\n+\\n\\nANNUAL DIGITAL PUBLISHING SUITE CONTRACT VALUE\\n\\n+\\n\\nANNUAL CREATIVE ETLA CONTRACT VALUE\\n\\nDOCUMENT CLOUD ARR\\n\\nANNUAL VALUE OF DOCUMENT CLOUD SUBSCRIPTIONS AND SERVICES\\n\\n+\\n\\nANNUAL DOCUMENT CLOUD ETLA CONTRACT VALUE\\n\\nDIGITAL MEDIA ARR\\n\\nCREATIVE ARR\\n\\n+\\n\\nDOCUMENT CLOUD ARR\\n\\n39\\n\\nTABLE OF CONTENTS\\n\\nTOTAL CREATIVE ARR EXITING FISCAL 2015 WAS\\n\\n$2.60 BILLION\\n\\n, UP FROM\\n\\n$1.61 BILLION\\n\\nAT THE END OF FISCAL 2014. WE EXITED FISCAL 2015 WITH\\n\\n6.167 MILLION\\n\\nPAID CREATIVE CLOUD SUBSCRIPTIONS, UP\\n\\n78%\\n\\nFROM\\n\\n3.458 MILLION\\n\\nAT THE END OF FISCAL 2014.\\n\\nOUR DIGITAL MEDIA SEGMENT ALSO INCLUDES OUR DOCUMENT CLOUD PRODUCTS AND SOLUTIONS, INCLUDING OUR NEWLY RELEASED ACROBAT DC PRODUCT WHICH HELPED GROW DOCUMENT CLOUD ARR TO\\n\\n$397 MILLION\\n\\nEXITING FISCAL 2015, UP FROM\\n\\n$265 MILLION\\n\\nAT THE END OF FISCAL 2014.\\n\\nTOTAL DIGITAL MEDIA ARR GREW TO APPROXIMATELY\\n\\n$3.00 BILLION\\n\\nAT THE END OF FISCAL 2015, UP FROM\\n\\n$1.88 BILLION\\n\\nAT THE END OF FISCAL 2014, DEMONSTRATING THE PROGRESS WE HAVE MADE WITH THE TRANSFORMATION OF OUR BUSINESS TO A MORE RECURRING, RATABLE AND PREDICTABLE REVENUE MODEL. OUR REPORTED ARR RESULTS IN FISCAL 2015 ARE BASED ON CURRENCY RATES SET AT THE START OF FISCAL 2015 AND HELD CONSTANT THROUGHOUT THE YEAR. REVALUING OUR ENDING ARR FOR FISCAL 2015 USING CURRENCY RATES AT THE BEGINNING OF FISCAL 2016, OUR DIGITAL MEDIA ARR AT THE END OF FISCAL 2015 WOULD BE\\n\\n$2.88 BILLION\\n\\nOR APPROXIMATELY\\n\\n$114 MILLION\\n\\nLOWER THAN THE ARR REPORTED ABOVE.\\n\\nWE ARE A MARKET LEADER IN THE FAST-GROWING CATEGORY ADDRESSED BY OUR DIGITAL MARKETING SEGMENT. OUR ADOBE MARKETING CLOUD NOW INCLUDES EIGHT SOLUTIONS WHICH ADDRESS THE EXPANDING NEEDS OF MARKETERS.  IN FISCAL 2015, WE ACHIEVED RECORD MARKETING CLOUD REVENUE OF\\n\\n$1.36 BILLION\\n\\n, WHICH REPRESENTS\\n\\n16%\\n\\nYEAR-OVER-YEAR REVENUE GROWTH. IN ADDITION, WE DROVE STRONG DEMAND AND BOOKINGS GROWTH FOR OUR MARKETING CLOUD SOLUTIONS, WHICH WE EXPECT WILL POSITIVELY BENEFIT REVENUE GROWTH IN FUTURE QUARTERS.\\n\\nFINANCIAL PERFORMANCE SUMMARY FOR FISCAL\\n\\n2015\\n\\n•\\n\\nDURING FISCAL\\n\\n2015\\n\\n, OUR SUBSCRIPTION REVENUE AS A PERCENTAGE OF TOTAL REVENUE\\n\\nINCREASED\\n\\nTO\\n\\n67%\\n\\nFROM\\n\\n50%\\n\\nCOMPARED WITH FISCAL\\n\\n2014\\n\\n, AS WE TRANSITIONED MORE OF OUR BUSINESS TO A SUBSCRIPTION-BASED MODEL.\\n\\n•\\n\\nTOTAL DIGITAL MEDIA ARR OF APPROXIMATELY\\n\\n$3.00 BILLION\\n\\nAS OF\\n\\nNOVEMBER 27, 2015\\n\\nINCREASED\\n\\nBY\\n\\n$1.12 BILLION\\n\\n, OR\\n\\n60%\\n\\n, FROM\\n\\n$1.88 BILLION\\n\\nAS OF\\n\\nNOVEMBER 28, 2014\\n\\n. THE CHANGE IN OUR DIGITAL MEDIA ARR WAS PRIMARILY DUE TO INCREASES IN THE NUMBER OF PAID CREATIVE CLOUD INDIVIDUAL AND TEAM SUBSCRIPTIONS AND CONTINUED ADOPTION OF OUR ETLAS, AND TO A LESSER EXTENT, THE ADOPTION OF OUR DOCUMENT CLOUD OFFERING THROUGH OUR ETLAS AND INCREASES IN DOCUMENT CLOUD SUBSCRIPTIONS.\\n\\n•\\n\\nADOBE MARKETING CLOUD REVENUE OF\\n\\n$1.36 BILLION\\n\\nINCREASED\\n\\nBY\\n\\n$188.5 MILLION\\n\\n, OR\\n\\n16%\\n\\n, DURING FISCAL\\n\\n2015\\n\\n, FROM\\n\\n$1.17 BILLION\\n\\nIN FISCAL\\n\\n2014\\n\\n. THE INCREASES WERE PRIMARILY DUE TO CONTINUED ADOPTION OF OUR ADOBE EXPERIENCE MANAGER (“AEM”) OFFERING AND INCREASES IN ADOBE CAMPAIGN AND ADOBE ANALYTICS REVENUE.\\n\\n•\\n\\nOUR TOTAL DEFERRED REVENUE OF\\n\\n$1.49 BILLION\\n\\nAS OF\\n\\nNOVEMBER 27, 2015\\n\\nINCREASED\\n\\nBY\\n\\n$330.0 MILLION\\n\\n, OR\\n\\n29%\\n\\n, FROM\\n\\n$1.16 BILLION\\n\\nAS OF\\n\\nNOVEMBER 28, 2014\\n\\n, PRIMARILY DUE TO INCREASES IN CREATIVE CLOUD INDIVIDUAL AND TEAM SUBSCRIPTIONS, ETLAS AND NEW CONTRACTS AND EXISTING RENEWALS FOR OUR ADOBE MARKETING CLOUD SERVICES. ALSO CONTRIBUTING TO THE INCREASE IN DEFERRED REVENUE WERE THE INCREASES ASSOCIATED WITH OUR STOCK PHOTOGRAPHY OFFERING FROM THE ACQUISITION OF FOTOLIA IN FISCAL 2015.\\n\\n•\\n\\nCOST OF REVENUE OF\\n\\n$744.3 MILLION\\n\\nINCREASED\\n\\nBY\\n\\n$122.2 MILLION\\n\\n, OR\\n\\n20%\\n\\n, DURING FISCAL\\n\\n2015\\n\\n, FROM\\n\\n$622.1 MILLION\\n\\nIN FISCAL\\n\\n2014\\n\\n. THE INCREASES WERE PRIMARILY DUE TO INCREASES IN COSTS ASSOCIATED WITH COMPENSATION AND RELATED BENEFITS DRIVEN BY ADDITIONAL HEADCOUNT AND COSTS OF PROFESSIONAL SERVICES DRIVEN BY THE INCREASE IN OUR PROFESSIONAL SERVICES BUSINESS.\\n\\n•\\n\\nOPERATING EXPENSES OF\\n\\n$3.15 BILLION\\n\\nINCREASED\\n\\nBY\\n\\n$35.8 MILLION\\n\\nDURING FISCAL\\n\\n2015\\n\\n, FROM\\n\\n$3.11 BILLION\\n\\nIN FISCAL\\n\\n2014\\n\\n. THE INCREASE IS DUE TO HIGHER COSTS ASSOCIATED WITH COMPENSATION AND RELATED BENEFITS DRIVEN BY ADDITIONAL HEADCOUNT AND AMORTIZATION OF INTANGIBLES FROM THE FOTOLIA ACQUISITION IN FISCAL 2015.\\n\\n•\\n\\nNET INCOME OF\\n\\n$629.6 MILLION\\n\\nINCREASED\\n\\nBY\\n\\n$361.2 MILLION\\n\\n, OR\\n\\n135%\\n\\n, DURING FISCAL\\n\\n2015\\n\\nFROM\\n\\n$268.4 MILLION\\n\\nIN FISCAL\\n\\n2014\\n\\nPRIMARILY DUE TO REVENUE GROWTH.\\n\\n•\\n\\nNET CASH FLOW FROM OPERATIONS OF\\n\\n$1.47 BILLION\\n\\nDURING FISCAL\\n\\n2015\\n\\nINCREASED\\n\\nBY\\n\\n$182.0 MILLION\\n\\n, OR\\n\\n14%\\n\\n, FROM\\n\\n$1.29 BILLION\\n\\nDURING FISCAL\\n\\n2014\\n\\nPRIMARILY DUE TO HIGHER NET INCOME.\\n\\n40\\n\\nTABLE OF CONTENTS\\n\\nREVENUE (DOLLARS IN MILLIONS)\\n\\nFISCAL\\n\\n2015\\n\\nFISCAL\\n\\n2014\\n\\nFISCAL\\n\\n2013% CHANGE\\n\\n2015-2014% CHANGE\\n\\n2014-2013\\n\\nSUBSCRIPTION\\n\\n$3,223.9\\n\\n$2,076.6\\n\\n$1,137.9\\n\\n55%\\n\\n82%\\n\\nPERCENTAGE OF TOTAL REVENUE\\n\\n67%\\n\\n50%\\n\\n28%\\n\\nPRODUCT\\n\\n1,125.1\\n\\n1,627.8\\n\\n2,470.1\\n\\n(31\\n\\n)%\\n\\n(34\\n\\n)%\\n\\nPERCENTAGE OF TOTAL REVENUE\\n\\n24%\\n\\n39%\\n\\n61%\\n\\nSERVICES AND SUPPORT\\n\\n446.5\\n\\n442.7\\n\\n447.2\\n\\n1%\\n\\n(1\\n\\n)%\\n\\nPERCENTAGE OF TOTAL REVENUE\\n\\n9%\\n\\n11%\\n\\n11%\\n\\nTOTAL REVENUE\\n\\n$4,795.5\\n\\n$4,147.1\\n\\n$4,055.2\\n\\n16%\\n\\n2%\\n\\nOUR SUBSCRIPTION REVENUE IS COMPRISED PRIMARILY OF FEES WE CHARGE FOR OUR SUBSCRIPTION AND HOSTED SERVICE OFFERINGS INCLUDING CREATIVE CLOUD AND CERTAIN OF OUR ADOBE MARKETING CLOUD AND DOCUMENT CLOUD SERVICES. WE RECOGNIZE SUBSCRIPTION REVENUE RATABLY OVER THE TERM OF AGREEMENTS WITH OUR CUSTOMERS, BEGINNING WITH COMMENCEMENT OF THE SERVICE. WE EXPECT OUR SUBSCRIPTION REVENUE WILL CONTINUE TO INCREASE AS A RESULT OF OUR INVESTMENTS IN NEW SOFTWARE-AS-A-SERVICE (“SAAS”) AND SUBSCRIPTION MODELS.\\n\\nWE HAVE THE FOLLOWING REPORTABLE SEGMENTS—DIGITAL MEDIA, DIGITAL MARKETING AND PRINT AND PUBLISHING. SUBSCRIPTION REVENUE BY REPORTABLE SEGMENT FOR FISCAL\\n\\n2015\\n\\n,\\n\\n2014\\n\\nAND\\n\\n2013\\n\\nIS AS FOLLOWS (DOLLARS IN MILLIONS).\\n\\nFISCAL\\n\\n2015\\n\\nFISCAL\\n\\n2014\\n\\nFISCAL\\n\\n2013% CHANGE\\n\\n2015-2014% CHANGE\\n\\n2014-2013\\n\\nDIGITAL MEDIA\\n\\n$2,264.7\\n\\n$1,268.3\\n\\n$471.9\\n\\n79%\\n\\n169%\\n\\nDIGITAL MARKETING\\n\\n937.0\\n\\n797.5\\n\\n663.1\\n\\n17%\\n\\n20%\\n\\nPRINT AND PUBLISHING\\n\\n22.2\\n\\n10.8\\n\\n2.9\\n\\n*\\n\\n*\\n\\nTOTAL SUBSCRIPTION REVENUE\\n\\n$3,223.9\\n\\n$2,076.6\\n\\n$1,137.9\\n\\n55%\\n\\n82%\\n\\n_________________________________________\\n\\n(*)\\n\\nPERCENTAGE IS NOT MEANINGFUL.\\n\\nOUR SERVICES AND SUPPORT REVENUE IS COMPRISED OF CONSULTING, TRAINING AND MAINTENANCE AND SUPPORT, PRIMARILY RELATED TO THE LICENSING OF OUR ENTERPRISE, DEVELOPER AND PLATFORM PRODUCTS AND THE SALE OF OUR HOSTED ADOBE MARKETING CLOUD SERVICES. OUR SUPPORT REVENUE ALSO INCLUDES TECHNICAL SUPPORT AND DEVELOPER SUPPORT TO PARTNERS AND DEVELOPER ORGANIZATIONS RELATED TO OUR DESKTOP PRODUCTS. OUR MAINTENANCE AND SUPPORT OFFERINGS, WHICH ENTITLE CUSTOMERS TO RECEIVE DESKTOP PRODUCT UPGRADES AND ENHANCEMENTS OR TECHNICAL SUPPORT, DEPENDING ON THE OFFERING, ARE GENERALLY RECOGNIZED RATABLY OVER THE TERM OF THE ARRANGEMENT.\\n\\nSEGMENTS\\n\\nIN FISCAL\\n\\n2015\\n\\n, WE CATEGORIZED OUR PRODUCTS INTO THE FOLLOWING REPORTABLE SEGMENTS.\\n\\n•\\n\\nDIGITAL MEDIA\\n\\n—OUR DIGITAL MEDIA SEGMENT PROVIDES TOOLS AND SOLUTIONS THAT ENABLE INDIVIDUALS, SMALL AND MEDIUM BUSINESSES AND ENTERPRISES TO CREATE, PUBLISH, PROMOTE AND MONETIZE THEIR DIGITAL CONTENT ANYWHERE. OUR CUSTOMERS INCLUDE TRADITIONAL CONTENT CREATORS, WEB APPLICATION DEVELOPERS AND DIGITAL MEDIA PROFESSIONALS, AS WELL AS THEIR MANAGEMENT IN MARKETING DEPARTMENTS AND AGENCIES, COMPANIES AND PUBLISHERS. OUR CUSTOMERS ALSO INCLUDE KNOWLEDGE WORKERS WHO CREATE, COLLABORATE AND DISTRIBUTE DOCUMENTS.\\n\\n•\\n\\nDIGITAL MARKETING\\n\\n—OUR DIGITAL MARKETING SEGMENT PROVIDES SOLUTIONS AND SERVICES FOR HOW DIGITAL ADVERTISING AND MARKETING ARE CREATED, MANAGED, EXECUTED, MEASURED AND OPTIMIZED. OUR CUSTOMERS INCLUDE DIGITAL MARKETERS, ADVERTISERS, PUBLISHERS, MERCHANDISERS, WEB ANALYSTS, CHIEF MARKETING OFFICERS, CHIEF INFORMATION OFFICERS AND CHIEF REVENUE OFFICERS.\\n\\n•\\n\\nPRINT AND PUBLISHING\\n\\n—OUR PRINT AND PUBLISHING SEGMENT ADDRESSES MARKET OPPORTUNITIES RANGING FROM THE DIVERSE AUTHORING AND PUBLISHING NEEDS OF TECHNICAL AND BUSINESS PUBLISHING TO OUR LEGACY TYPE AND OEM PRINTING BUSINESSES.\\n\\n41\\n\\nTABLE OF CONTENTS\\n\\nSEGMENT INFORMATION (DOLLARS IN MILLIONS)\\n\\nFISCAL\\n\\n2015\\n\\nFISCAL\\n\\n2014\\n\\nFISCAL\\n\\n2013% CHANGE\\n\\n2015-2014% CHANGE\\n\\n2014-2013\\n\\nDIGITAL MEDIA\\n\\n$3,095.2\\n\\n$2,603.2\\n\\n$2,625.9\\n\\n19%\\n\\n(1\\n\\n)%\\n\\nPERCENTAGE OF TOTAL REVENUE\\n\\n65%\\n\\n63%\\n\\n65%\\n\\nDIGITAL MARKETING\\n\\n1,508.9\\n\\n1,355.2\\n\\n1,228.8\\n\\n11%\\n\\n10%\\n\\nPERCENTAGE OF TOTAL REVENUE\\n\\n31%\\n\\n33%\\n\\n30%\\n\\nPRINT AND PUBLISHING\\n\\n191.4\\n\\n188.7\\n\\n200.5\\n\\n1%\\n\\n(6\\n\\n)%\\n\\nPERCENTAGE OF TOTAL REVENUE\\n\\n4%\\n\\n4%\\n\\n5%\\n\\nTOTAL REVENUE\\n\\n$4,795.5\\n\\n$4,147.1\\n\\n$4,055.2\\n\\n16%\\n\\n2%\\n\\nFISCAL 2015 REVENUE COMPARED TO FISCAL 2014 REVENUE\\n\\nDIGITAL MEDIA\\n\\nREVENUE FROM DIGITAL MEDIA\\n\\nINCREASED\\n\\n$492.0 MILLION\\n\\nDURING FISCAL 2015 AS COMPARED TO FISCAL 2014, PRIMARILY DRIVEN BY INCREASES IN REVENUE ASSOCIATED WITH OUR CREATIVE OFFERINGS DUE TO CONTINUED STRONG ADOPTION OF CREATIVE CLOUD. DOCUMENT CLOUD REVENUE REMAINED STABLE DURING FISCAL 2015 AS COMPARED TO FISCAL 2014.\\n\\nCREATIVE REVENUE, WHICH INCLUDES OUR CREATIVE CLOUD AND PERPETUAL CREATIVE OFFERINGS, INCREASED DURING FISCAL 2015 AS COMPARED TO FISCAL 2014, PRIMARILY DUE TO THE INCREASE IN SUBSCRIPTION REVENUE ASSOCIATED WITH OUR CREATIVE CLOUD OFFERINGS DRIVEN BY THE INCREASE IN NUMBER OF PAID CREATIVE CLOUD TEAM, INDIVIDUAL AND ENTERPRISE SUBSCRIPTIONS. THE INCREASES ASSOCIATED WITH OUR CREATIVE PRODUCTS WERE OFFSET IN PART BY EXPECTED DECLINES IN REVENUE ASSOCIATED WITH OUR PERPETUAL CREATIVE OFFERINGS.\\n\\nDOCUMENT CLOUD REVENUE, WHICH INCLUDES OUR ACROBAT PRODUCT FAMILY, REMAINED STABLE DURING FISCAL 2015 AS COMPARED TO THE YEAR AGO PERIOD, AS INCREASES IN REVENUE ASSOCIATED WITH ESIGN AND OUR DOCUMENT CLOUD SUBSCRIPTION OFFERING WERE OFFSET BY DECREASES IN REVENUE ASSOCIATED WITH OUR DOCUMENT CLOUD PERPETUAL LICENSE OFFERINGS. DRIVING THE INCREASE IN OUR DOCUMENT CLOUD SUBSCRIPTION REVENUE WAS THE ADOPTION OF OUR CLOUD OFFERING THROUGH SUBSCRIPTIONS AND ETLAS.\\n\\nDIGITAL MARKETING\\n\\nREVENUE FROM DIGITAL MARKETING\\n\\nINCREASED\\n\\n$153.7 MILLION\\n\\nDURING FISCAL 2015 AS COMPARED TO FISCAL 2014 PRIMARILY DUE TO CONTINUED REVENUE GROWTH ASSOCIATED WITH OUR ADOBE MARKETING CLOUD, WHICH INCREASED\\n\\n16%\\n\\nAS COMPARED WITH THE YEAR-AGO PERIOD. CONTRIBUTING TO THIS INCREASE WAS THE CONTINUED ADOPTION OF OUR AEM TERM-BASED OFFERING, AND TO A LESSER EXTENT, INCREASES IN REVENUE ASSOCIATED WITH ADOBE CAMPAIGN, ADOBE ANALYTICS AND ADOBE TARGET.\\n\\nPRINT AND PUBLISHING\\n\\nREVENUE FROM PRINT AND PUBLISHING REMAINED STABLE DURING FISCAL 2015 AS COMPARED TO FISCAL 2014.\\n\\nFISCAL 2014 REVENUE COMPARED TO FISCAL 2013 REVENUE\\n\\nDIGITAL MEDIA\\n\\nREVENUE FROM DIGITAL MEDIA DECREASED SLIGHTLY DURING FISCAL 2014 AS COMPARED TO FISCAL 2013. THE SLIGHT DECREASE WAS PRIMARILY DRIVEN BY DECLINES IN REVENUE ASSOCIATED WITH OUR PERPETUAL CREATIVE OFFERINGS, DISTRIBUTION OF THIRD-PARTY SOFTWARE DOWNLOADS AND HOBBYIST PRODUCTS LAUNCHED IN FISCAL 2013. WITH RESPECT TO THE HOBBYIST PRODUCT REVENUE DECLINE, WE BEGAN ACTIVELY MIGRATING CUSTOMERS TO OUR CREATIVE CLOUD PHOTOGRAPHY PLAN IN FISCAL 2014, FOR WHICH REVENUE IS RECOGNIZED RATABLY. LARGELY OFFSETTING THESE DECREASES WERE INCREASES IN CREATIVE CLOUD AND DOCUMENT CLOUD REVENUE.\\n\\nCREATIVE REVENUE, WHICH INCLUDES OUR CREATIVE CLOUD, CREATIVE SUITE EDITIONS AND CS POINT PRODUCTS, DECREASED SLIGHTLY DURING FISCAL 2014 AS COMPARED TO FISCAL 2013 DUE TO DECREASES IN REVENUE FROM CS POINT PRODUCTS AND CREATIVE SUITE EDITIONS, AS WE DISCONTINUED THE GENERAL AVAILABILITY OF OUR PERPETUALLY LICENSED CS6 PRODUCTS IN THE SECOND QUARTER OF FISCAL 2014. ALSO CONTRIBUTING TO THE DECLINE IN CREATIVE REVENUE WERE DECREASES IN REVENUE ASSOCIATED WITH THE DISTRIBUTION OF THIRD-PARTY SOFTWARE DOWNLOADS AND HOBBYIST PRODUCTS LAUNCHED IN FISCAL 2013. DECREASES WERE LARGELY OFFSET BY INCREASES IN REVENUE FROM SUBSCRIPTIONS AND ETLAS AND REVENUE FROM OUR DIGITAL PUBLISHING SUITE.\\n\\nDOCUMENT CLOUD REVENUE, WHICH INCLUDES OUR ACROBAT PRODUCT FAMILY, INCREASED DURING FISCAL 2014 AS COMPARED TO FISCAL 2013 PRIMARILY DUE TO INCREASES IN OUR DOCUMENT CLOUD SUBSCRIPTION REVENUE.  INCREASES WERE SLIGHTLY OFFSET BY DECREASES DUE TO OUR CONTINUED SHIFT TO ETLAS.\\n\\n42\\n\\nTABLE OF CONTENTS\\n\\nDIGITAL MARKETING\\n\\nREVENUE FROM DIGITAL MARKETING INCREASED $126.3 MILLION DURING FISCAL 2014 AS COMPARED TO FISCAL 2013 DUE TO CONTINUED REVENUE GROWTH ASSOCIATED WITH OUR ADOBE MARKETING CLOUD, WHICH INCREASED 15% DURING FISCAL 2014 AS COMPARED TO FISCAL 2013. CONTRIBUTING TO THIS INCREASE WAS ADOBE CAMPAIGN AND THE STRONG ADOPTION OF AEM.\\n\\nPRINT AND PUBLISHING\\n\\nREVENUE FROM PRINT AND PUBLISHING DECREASED DURING FISCAL 2014 AS COMPARED TO FISCAL 2013 PRIMARILY DUE TO DECREASES IN LEGACY PRODUCT REVENUE AND INCREASED ETLAS FOR CERTAIN PRODUCTS IN THIS GROUP.\\n\\nGEOGRAPHICAL INFORMATION (DOLLARS IN MILLIONS)\\n\\nFISCAL\\n\\n2015\\n\\nFISCAL\\n\\n2014\\n\\nFISCAL\\n\\n2013% CHANGE\\n\\n2015-2014% CHANGE\\n\\n2014-2013\\n\\nAMERICAS\\n\\n$2,788.1\\n\\n$2,314.4\\n\\n$2,134.4\\n\\n20%\\n\\n8%\\n\\nPERCENTAGE OF TOTAL REVENUE\\n\\n58%\\n\\n56%\\n\\n53%\\n\\nEMEA\\n\\n1,336.4\\n\\n1,179.9\\n\\n1,129.2\\n\\n13%\\n\\n4%\\n\\nPERCENTAGE OF TOTAL REVENUE\\n\\n28%\\n\\n28%\\n\\n28%\\n\\nAPAC\\n\\n671.0\\n\\n652.8\\n\\n791.6\\n\\n3%\\n\\n(18\\n\\n)%\\n\\nPERCENTAGE OF TOTAL REVENUE\\n\\n14%\\n\\n16%\\n\\n19%\\n\\nTOTAL REVENUE\\n\\n$4,795.5\\n\\n$4,147.1\\n\\n$4,055.2\\n\\n16%\\n\\n2%\\n\\nFISCAL 2015 REVENUE BY GEOGRAPHY COMPARED TO FISCAL 2014 REVENUE BY GEOGRAPHY\\n\\nREVENUE INCREASED IN THE AMERICAS AND EMEA DURING FISCAL 2015 AS COMPARED TO FISCAL 2014 WHILE REVENUE IN APAC REMAINED STABLE DURING FISCAL 2015 COMPARED WITH THE YEAR-AGO PERIOD. REVENUE IN THE AMERICAS AND EMEA INCREASED PRIMARILY DUE TO GROWTH IN DIGITAL MEDIA AND DIGITAL MARKETING REVENUE. THE OVERALL INCREASE IN EMEA REVENUE WAS SLIGHTLY OFFSET BY DECLINES DUE TO STRENGTHENING OF THE U.S. DOLLAR AGAINST THE EURO, BRITISH POUND AND OTHER EMEA CURRENCIES IN FISCAL 2015. WITHIN THE AMERICAS AND EMEA, FLUCTUATIONS IN REVENUE BY REPORTABLE SEGMENT WERE ATTRIBUTABLE TO THE FACTORS NOTED IN THE SEGMENT INFORMATION ABOVE.\\n\\nREVENUE IN APAC REMAINED STABLE DURING FISCAL 2015 AS COMPARED TO FISCAL 2014 DUE TO AN INCREASE IN DIGITAL MARKETING REVENUE OFFSET BY A DECREASE IN DIGITAL MEDIA REVENUE.THE INCREASE IN DIGITAL MARKETING REVENUE IN APAC WAS ATTRIBUTABLE TO THE FACTORS NOTED IN THE SEGMENT INFORMATION ABOVE. THE DECLINE IN DIGITAL MEDIA REVENUE WAS PRIMARILY DUE TO EXPECTED DECREASES IN PERPETUAL LICENSE REVENUE, PARTIALLY OFFSET BY INCREASES IN SUBSCRIPTION REVENUE DURING FISCAL 2015 AS COMPARED TO FISCAL 2014.\\n\\nFISCAL 2014 REVENUE BY GEOGRAPHY COMPARED TO FISCAL 2013 REVENUE BY GEOGRAPHY\\n\\nOVERALL REVENUE INCREASED IN THE AMERICAS AND EMEA DURING FISCAL 2014 AS COMPARED TO FISCAL 2013. REVENUE IN THE AMERICAS INCREASED DUE TO GROWTH IN DIGITAL MEDIA AND DIGITAL MARKETING REVENUE. REVENUE IN EMEA INCREASED PRIMARILY DUE TO GROWTH IN DIGITAL MARKETING REVENUE. DIGITAL MEDIA AND PRINT AND PUBLISHING REVENUE IN EMEA REMAINED RELATIVELY STABLE. DESPITE STRENGTHENING OF THE U.S. DOLLAR AGAINST THE EURO AND THE BRITISH POUND DURING THE LATTER PART OF FISCAL 2014, THE OVERALL WEAKENING OF THE U.S. DOLLAR AGAINST THESE CURRENCIES DURING FISCAL 2014 ALSO CAUSED REVENUE IN EMEA TO INCREASE AS COMPARED TO FISCAL 2013. WITHIN THE AMERICAS AND EMEA, THE FLUCTUATIONS IN REVENUE BY REPORTABLE SEGMENT WERE ATTRIBUTABLE TO THE FACTORS NOTED IN THE SEGMENT INFORMATION ABOVE.\\n\\nREVENUE IN APAC DECREASED DURING FISCAL 2014 AS COMPARED TO FISCAL 2013 PRIMARILY AS A RESULT OF DECREASES IN DIGITAL MEDIA REVENUE DUE TO SLOWER ADOPTION OF CREATIVE CLOUD IN JAPAN COMPARED TO OTHER COUNTRIES AND THE STRENGTHENING OF THE U.S. DOLLAR AGAINST THE JAPANESE YEN AND OTHER ASIAN CURRENCIES. DIGITAL MARKETING AND PRINT AND PUBLISHING REVENUE IN APAC REMAINED RELATIVELY STABLE DURING FISCAL 2014 COMPARED TO FISCAL 2013.\\n\\n43\\n\\nTABLE OF CONTENTS\\n\\nINCLUDED IN THE OVERALL CHANGE IN REVENUE FOR FISCAL\\n\\n2015\\n\\nAND FISCAL\\n\\n2014\\n\\nWERE IMPACTS ASSOCIATED WITH FOREIGN CURRENCY AS SHOWN BELOW. OUR CURRENCY HEDGING PROGRAM IS USED TO MITIGATE A PORTION OF THE FOREIGN CURRENCY IMPACT TO REVENUE.\\n\\n(IN MILLIONS)\\n\\nFISCAL\\n\\n2015\\n\\nFISCAL\\n\\n2014\\n\\nREVENUE IMPACT.\\n\\nINCREASE/(DECREASE)\\n\\nEMEA.\\n\\nEURO\\n\\n$(104.3\\n\\n)\\n\\n$12.3\\n\\nBRITISH POUND\\n\\n(16.1\\n\\n)\\n\\n12.9\\n\\nOTHER CURRENCIES\\n\\n(12.3\\n\\n)\\n\\n(0.2\\n\\n)\\n\\nTOTAL EMEA\\n\\n(132.7\\n\\n)\\n\\n25.0\\n\\nJAPANESE YEN\\n\\n(35.0\\n\\n)\\n\\n(25.7\\n\\n)\\n\\nOTHER CURRENCIES\\n\\n(23.9\\n\\n)\\n\\n(8.9\\n\\n)\\n\\nTOTAL REVENUE IMPACT\\n\\n(191.6\\n\\n)\\n\\n(9.6\\n\\n)\\n\\nHEDGING IMPACT.\\n\\nEMEA\\n\\n40.1\\n\\n10.1\\n\\nJAPANESE YEN\\n\\n16.2\\n\\n8.6\\n\\nTOTAL HEDGING IMPACT\\n\\n56.3\\n\\n18.7\\n\\nTOTAL IMPACT\\n\\n$(135.3\\n\\n)\\n\\n$9.1\\n\\nDURING FISCAL 2015, THE U.S. DOLLAR STRENGTHENED AGAINST THE EURO, BRITISH POUND, JAPANESE YEN AND OTHER ASIAN CURRENCIES CAUSING REVENUE IN EMEA AND APAC MEASURED IN U.S. DOLLAR EQUIVALENTS TO DECREASE AS COMPARED TO FISCAL 2014. THESE DECREASES WERE PARTIALLY OFFSET BY HEDGING GAINS FROM OUR EMEA CURRENCIES AND JAPANESE YEN HEDGING PROGRAMS DURING FISCAL 2015.\\n\\nDURING FISCAL 2014, THE U.S. DOLLAR STRENGTHENED AGAINST THE JAPANESE YEN AND OTHER ASIAN CURRENCIES CAUSING REVENUE IN APAC MEASURED IN U.S. DOLLAR EQUIVALENTS TO DECREASE COMPARED TO FISCAL 2013. THIS DECREASE WAS OFFSET IN PART BY THE FAVORABLE IMPACT TO REVENUE MEASURED IN EMEA CURRENCIES AS THE U.S. DOLLAR WEAKENED AGAINST THE EURO AND THE BRITISH POUND FOR THE MAJORITY OF FISCAL 2014. OUR EMEA AND YEN CURRENCY HEDGING PROGRAMS RESULTED IN HEDGING GAINS DURING FISCAL 2014.\\n\\nSEE NOTE 18 OF OUR NOTES TO CONSOLIDATED FINANCIAL STATEMENTS FOR FURTHER GEOGRAPHIC INFORMATION.\\n\\nPRODUCT BACKLOG\\n\\nTHE ACTUAL AMOUNT OF PRODUCT BACKLOG AT ANY PARTICULAR TIME MAY NOT BE A MEANINGFUL INDICATOR OF FUTURE BUSINESS PROSPECTS. SHIPPABLE BACKLOG IS COMPRISED OF UNFULFILLED ORDERS, EXCLUDING THOSE ASSOCIATED WITH NEW PRODUCT RELEASES, THOSE PENDING CREDIT REVIEW AND THOSE NOT SHIPPED DUE TO THE APPLICATION OF OUR GLOBAL INVENTORY POLICY. WE HAD MINIMAL SHIPPABLE BACKLOG AT THE END OF THE FOURTH QUARTER OF FISCAL\\n\\n2015\\n\\nAND FISCAL\\n\\n2014\\n\\n. WE EXPECT THAT OUR SHIPPABLE BACKLOG WILL CONTINUE TO BE INSIGNIFICANT IN FUTURE PERIODS.\\n\\nDEFERRED REVENUE ON OUR CONSOLIDATED BALANCE SHEET DOES NOT REPRESENT THE TOTAL CONTRACT VALUE OF ANNUAL OR MULTI-YEAR, NON-CANCELABLE COMMERCIAL SUBSCRIPTION AGREEMENTS OR GOVERNMENT CONTRACTS WITH FISCAL FUNDING CLAUSES. UNBILLED DEFERRED REVENUE REPRESENTS EXPECTED FUTURE BILLINGS WHICH ARE CONTRACTUALLY COMMITTED UNDER OUR EXISTING SUBSCRIPTION, SAAS AND MANAGED SERVICES AGREEMENTS THAT HAVE NOT BEEN INVOICED AND ARE NOT RECORDED IN DEFERRED REVENUE WITHIN OUR FINANCIAL STATEMENTS. OUR PRESENTATION OF UNBILLED DEFERRED REVENUE BACKLOG MAY DIFFER FROM THAT OF OTHER COMPANIES IN THE INDUSTRY. AS OF\\n\\nNOVEMBER 27, 2015\\n\\n, WE HAD UNBILLED DEFERRED REVENUE BACKLOG OF APPROXIMATELY\\n\\n$2.89 BILLION\\n\\nOF WHICH APPROXIMATELY\\n\\n40% TO 50%\\n\\nIS NOT REASONABLY EXPECTED TO BE BILLED DURING FISCAL 2016. AS OF\\n\\nNOVEMBER 28, 2014\\n\\n, WE HAD UNBILLED DEFERRED REVENUE BACKLOG OF APPROXIMATELY\\n\\n$2.19 BILLION\\n\\n, WHICH HAS BEEN UPDATED TO INCLUDE\\n\\n$433 MILLION\\n\\nOF INDIVIDUAL ANNUAL SUBSCRIPTIONS WHICH WERE NOT CAPTURED IN THE PRIOR YEAR DUE TO CURRENT YEAR ENHANCEMENTS TO OUR MANAGEMENT REPORTING SYSTEM.\\n\\nWE EXPECT THAT THE AMOUNT OF UNBILLED DEFERRED REVENUE BACKLOG WILL CHANGE FROM PERIOD TO PERIOD DUE TO CERTAIN FACTORS, INCLUDING THE TIMING AND DURATION OF LARGE CUSTOMER SUBSCRIPTION, SAAS AND MANAGED SERVICE AGREEMENTS, VARYING BILLING CYCLES OF THESE AGREEMENTS, THE TIMING OF CUSTOMER RENEWALS, THE TIMING OF WHEN UNBILLED DEFERRED REVENUE BACKLOG IS TO BE BILLED, CHANGES IN CUSTOMER FINANCIAL CIRCUMSTANCES AND FOREIGN CURRENCY FLUCTUATIONS. ADDITIONALLY, THE UNBILLED DEFERRED REVENUE BACKLOG FOR MULTI-YEAR SUBSCRIPTION AGREEMENTS THAT ARE BILLED ANNUALLY IS TYPICALLY HIGHER AT THE BEGINNING OF THE CONTRACT PERIOD, LOWER PRIOR TO RENEWAL AND TYPICALLY INCREASES WHEN THE AGREEMENT IS RENEWED. ACCORDINGLY, FLUCTUATIONS IN UNBILLED DEFERRED REVENUE BACKLOG MAY NOT BE A RELIABLE INDICATOR OF FUTURE BUSINESS PROSPECTS AND THE RELATED REVENUE ASSOCIATED WITH THESE CONTRACTUAL COMMITMENTS.\\n\\n44\\n\\nTABLE OF CONTENTS\\n\\nCOST OF REVENUE (DOLLARS IN MILLIONS)\\n\\nFISCAL\\n\\n2015\\n\\nFISCAL\\n\\n2014\\n\\nFISCAL\\n\\n2013% CHANGE\\n\\n2015-2014% CHANGE\\n\\n2014-2013\\n\\nSUBSCRIPTION\\n\\n$409.2\\n\\n$335.5\\n\\n$278.1\\n\\n22%\\n\\n21%\\n\\nPERCENTAGE OF TOTAL REVENUE\\n\\n9%\\n\\n8%\\n\\n7%\\n\\nPRODUCT\\n\\n90.0\\n\\n97.1\\n\\n138.2\\n\\n(7\\n\\n)%\\n\\n(30\\n\\n)%\\n\\nPERCENTAGE OF TOTAL REVENUE\\n\\n2%\\n\\n2%\\n\\n3%\\n\\nSERVICES AND SUPPORT\\n\\n245.1\\n\\n189.5\\n\\n170.3\\n\\n29%\\n\\n11%\\n\\nPERCENTAGE OF TOTAL REVENUE\\n\\n5%\\n\\n5%\\n\\n4%\\n\\nTOTAL COST OF REVENUE\\n\\n$744.3\\n\\n$622.1\\n\\n$586.6\\n\\n20%\\n\\n6%\\n\\nSUBSCRIPTION\\n\\nCOST OF SUBSCRIPTION REVENUE CONSISTS OF THIRD-PARTY ROYALTIES AND EXPENSES RELATED TO OPERATING OUR NETWORK INFRASTRUCTURE, INCLUDING DEPRECIATION EXPENSES AND OPERATING LEASE PAYMENTS ASSOCIATED WITH COMPUTER EQUIPMENT, DATA CENTER COSTS, SALARIES AND RELATED EXPENSES OF NETWORK OPERATIONS, IMPLEMENTATION, ACCOUNT MANAGEMENT AND TECHNICAL SUPPORT PERSONNEL, AMORTIZATION OF INTANGIBLE ASSETS AND ALLOCATED OVERHEAD. WE ENTER INTO CONTRACTS WITH THIRD PARTIES FOR THE USE OF THEIR DATA CENTER FACILITIES AND OUR DATA CENTER COSTS LARGELY CONSIST OF AMOUNTS WE PAY TO THESE THIRD PARTIES FOR RACK SPACE, POWER AND SIMILAR ITEMS.\\n\\nCOST OF SUBSCRIPTION REVENUE INCREASED DUE TO THE FOLLOWING.% CHANGE\\n\\n2015-2014% CHANGE\\n\\n2014-2013\\n\\nDATA CENTER COST\\n\\n4%\\n\\n10%\\n\\nCOMPENSATION COST AND RELATED BENEFITS ASSOCIATED WITH HEADCOUNT\\n\\n4\\n\\n4\\n\\nDEPRECIATION EXPENSE\\n\\n3\\n\\n3\\n\\nROYALTY COST\\n\\n4\\n\\n3\\n\\nAMORTIZATION OF PURCHASED INTANGIBLES\\n\\n3\\n\\n—\\n\\nVARIOUS INDIVIDUALLY INSIGNIFICANT ITEMS\\n\\n4\\n\\n1\\n\\nTOTAL CHANGE\\n\\n22%\\n\\n21%\\n\\nCOST OF SUBSCRIPTION REVENUE INCREASED DURING FISCAL\\n\\n2015\\n\\nAS COMPARED TO FISCAL\\n\\n2014\\n\\nPRIMARILY DUE TO DATA CENTER COSTS, COMPENSATION AND RELATED BENEFITS, ROYALTY COST, DEPRECIATION EXPENSE, AND PURCHASED INTANGIBLE AMORTIZATION. DATA CENTER COSTS INCREASED PRIMARILY DUE TO HIGHER TRANSACTION VOLUMES IN OUR ADOBE MARKETING CLOUD AND CREATIVE CLOUD SERVICES. DEPRECIATION EXPENSE INCREASED PRIMARILY DUE TO HIGHER CAPITAL EXPENDITURES IN RECENT PERIODS AS WE CONTINUE TO INVEST IN OUR NETWORK AND DATA CENTER INFRASTRUCTURE TO SUPPORT THE GROWTH OF OUR SUBSCRIPTION AND HOSTED SERVICES BUSINESS. ROYALTY COST INCREASED PRIMARILY DUE TO INCREASES IN SUBSCRIPTIONS AND DOWNLOADS OF OUR SAAS OFFERINGS AND INCREASED ROYALTIES DUE TO THE INTRODUCTION OF OUR STOCK PHOTOGRAPHY OFFERING FROM OUR ACQUISITION OF FOTOLIA IN FISCAL 2015. AMORTIZATION OF PURCHASED INTANGIBLES INCREASED PRIMARILY DUE TO AMORTIZATION OF INTANGIBLES ACQUIRED FROM OUR ACQUISITION OF FOTOLIA IN FISCAL 2015.\\n\\nCOST OF SUBSCRIPTION REVENUE INCREASED DURING FISCAL\\n\\n2014\\n\\nAS COMPARED TO FISCAL\\n\\n2013\\n\\nPRIMARILY DUE TO DATA CENTER COSTS, COMPENSATION AND RELATED BENEFITS, DEPRECIATION EXPENSE, AND ROYALTY COST.\\n\\nDATA CENTER COSTS INCREASED PRIMARILY DUE TO HIGHER TRANSACTION VOLUMES IN OUR ADOBE MARKETING CLOUD AND CREATIVE CLOUD SERVICES.\\n\\nCOMPENSATION COST AND RELATED BENEFITS INCREASED PRIMARILY DUE TO\\n\\nADDITIONAL HEADCOUNT IN FISCAL 2014, INCLUDING FROM OUR ACQUISITION OF NEOLANE IN THE THIRD QUARTER OF FISCAL 2013. DEPRECIATION EXPENSE INCREASED PRIMARILY DUE TO HIGHER CAPITAL EXPENDITURES AS WE CONTINUED TO INVEST IN OUR NETWORK AND DATA CENTER INFRASTRUCTURE TO SUPPORT THE GROWTH OF OUR BUSINESS. ROYALTY COST INCREASED PRIMARILY DUE TO INCREASES IN SUBSCRIPTIONS AND DOWNLOADS OF OUR SAAS OFFERINGS.\\n\\nPRODUCT\\n\\nCOST OF PRODUCT REVENUE INCLUDES PRODUCT PACKAGING, THIRD-PARTY ROYALTIES, EXCESS AND OBSOLETE INVENTORY, AMORTIZATION RELATED TO LOCALIZATION COSTS, PURCHASED INTANGIBLES AND ACQUIRED RIGHTS TO USE TECHNOLOGY AND THE COSTS ASSOCIATED WITH THE MANUFACTURING OF OUR PRODUCTS.\\n\\n45\\n\\nTABLE OF CONTENTS\\n\\nFLUCTUATIONS IN COST OF PRODUCT REVENUE ARE DUE TO THE FOLLOWING.% CHANGE\\n\\n2015-2014% CHANGE\\n\\n2014-2013\\n\\nCOST OF SALES\\n\\n(3\\n\\n)%\\n\\n(4\\n\\n)%\\n\\nEXCESS AND OBSOLETE INVENTORY\\n\\n(4\\n\\n)\\n\\n1\\n\\nAMORTIZATION OF PURCHASED INTANGIBLES AND TECHNOLOGY LICENSE ARRANGEMENTS\\n\\n(2\\n\\n)\\n\\n(20\\n\\n)\\n\\nROYALTY COST\\n\\n3\\n\\n(2\\n\\n)\\n\\nVARIOUS INDIVIDUALLY INSIGNIFICANT ITEMS\\n\\n(1\\n\\n)\\n\\n(5\\n\\n)\\n\\nTOTAL CHANGE\\n\\n(7\\n\\n)%\\n\\n(30\\n\\n)%\\n\\nCOST OF PRODUCT REVENUE DECREASED DURING FISCAL 2015 AS COMPARED TO FISCAL 2014 PRIMARILY DUE TO DECREASES IN EXCESS AND OBSOLETE INVENTORY, COST OF SALES AND AMORTIZATION OF PURCHASED INTANGIBLES, PARTIALLY OFFSET BY AN INCREASE IN ROYALTY COST. THE INCREASE IN ROYALTY COST WAS DRIVEN BY ROYALTY PAYMENTS RELATED TO OUR STOCK PHOTOGRAPHY PERPETUAL OFFERING FROM OUR ACQUISITION OF FOTOLIA IN FISCAL 2015.\\n\\nCOST OF PRODUCT REVENUE DECREASED DURING FISCAL 2014 AS COMPARED TO FISCAL 2013 PRIMARILY DUE TO DECREASES IN AMORTIZATION OF PURCHASED INTANGIBLES AND TECHNOLOGY LICENSE ARRANGEMENTS, COST OF SALES AND ROYALTY COST, SLIGHTLY OFFSET BY AN INCREASE IN EXCESS AND OBSOLETE INVENTORY. AMORTIZATION OF PURCHASED INTANGIBLES AND TECHNOLOGY LICENSE ARRANGEMENTS DECREASED AS WE ENTERED INTO CERTAIN TECHNOLOGY LICENSING ARRANGEMENTS FOR WHICH PAYMENTS OF $26.5 MILLION RELATED TO HISTORICAL USE OF CERTAIN TECHNOLOGY LICENSING ARRANGEMENTS WERE EXPENSED AS COST OF PRODUCT REVENUE DURING FISCAL 2013. COST OF SALES DECREASED DUE TO DECREASES IN THE NUMBER OF PERPETUAL UNITS SOLD AND ASSOCIATED PACKAGING COSTS AS WE CONTINUED TO FOCUS OUR DEVELOPMENT AND SALES EFFORTS ON CREATIVE CLOUD. ROYALTY COST DECREASED PRIMARILY DUE TO DECREASES IN REVENUE FROM OUR PERPETUAL OFFERINGS. EXCESS AND OBSOLETE INVENTORY INCREASED AS A RESULT OF CHANGES IN RESERVE REQUIREMENTS FOR CS6 SHRINK BOXES AS WE DISCONTINUED THE GENERAL AVAILABILITY OF CS6 ON A PERPETUAL LICENSING BASIS.\\n\\nSERVICES AND SUPPORT\\n\\nCOST OF SERVICES AND SUPPORT REVENUE IS PRIMARILY COMPRISED OF EMPLOYEE-RELATED COSTS AND ASSOCIATED COSTS INCURRED TO PROVIDE CONSULTING SERVICES, TRAINING AND PRODUCT SUPPORT.\\n\\nCOST OF SERVICES AND SUPPORT REVENUE INCREASED IN ALL PERIODS PRESENTED DUE TO INCREASES IN COMPENSATION AND RELATED BENEFITS DRIVEN BY ADDITIONAL HEADCOUNT AND THIRD-PARTY FEES TO SUPPORT THE INCREASE IN OUR PROFESSIONAL SERVICES BUSINESS.\\n\\nOPERATING EXPENSES (DOLLARS IN MILLIONS)\\n\\nFISCAL\\n\\n2015\\n\\nFISCAL\\n\\n2014\\n\\nFISCAL\\n\\n2013% CHANGE\\n\\n2015-2014% CHANGE\\n\\n2014-2013\\n\\nRESEARCH AND DEVELOPMENT\\n\\n$862.7\\n\\n$844.4\\n\\n$826.6\\n\\n2%\\n\\n2%\\n\\nPERCENTAGE OF TOTAL REVENUE\\n\\n18%\\n\\n20%\\n\\n20%\\n\\nSALES AND MARKETING\\n\\n1,683.2\\n\\n1,652.3\\n\\n1,620.5\\n\\n2%\\n\\n2%\\n\\nPERCENTAGE OF TOTAL REVENUE\\n\\n35%\\n\\n40%\\n\\n40%\\n\\nGENERAL AND ADMINISTRATIVE\\n\\n531.9\\n\\n543.3\\n\\n520.1\\n\\n(2\\n\\n)%\\n\\n4%\\n\\nPERCENTAGE OF TOTAL REVENUE\\n\\n11%\\n\\n13%\\n\\n13%\\n\\nRESTRUCTURING AND OTHER CHARGES\\n\\n1.6\\n\\n19.9\\n\\n26.5\\n\\n*\\n\\n(25\\n\\n)%\\n\\nPERCENTAGE OF TOTAL REVENUE\\n\\n**\\n\\n**\\n\\n1%\\n\\nAMORTIZATION OF PURCHASED INTANGIBLES\\n\\n68.7\\n\\n52.4\\n\\n52.3\\n\\n31%\\n\\n—%\\n\\nPERCENTAGE OF TOTAL REVENUE\\n\\n1%\\n\\n1%\\n\\n1%\\n\\nTOTAL OPERATING EXPENSES\\n\\n$3,148.1\\n\\n$3,112.3\\n\\n$3,046.0\\n\\n1%\\n\\n2%\\n\\n_________________________________________\\n\\n(*)\\n\\nPERCENTAGE IS NOT MEANINGFUL.\\n\\n(**)\\n\\nPERCENTAGE IS LESS THAN 1%.\\n\\n46\\n\\nTABLE OF CONTENTS\\n\\nRESEARCH AND DEVELOPMENT, SALES AND MARKETING AND GENERAL AND ADMINISTRATIVE EXPENSES\\n\\nRESEARCH AND DEVELOPMENT AND SALES AND MARKETING EXPENSES INCREASED SLIGHTLY DURING FISCAL 2015 AS COMPARED TO FISCAL 2014 PRIMARILY DUE TO INCREASES IN COMPENSATION AND RELATED BENEFITS ASSOCIATED WITH HEADCOUNT. GENERAL AND ADMINISTRATIVE EXPENSES DECREASED SLIGHTLY DURING FISCAL 2015 AS COMPARED TO FISCAL 2014 PRIMARILY DUE TO THE REVERSAL OF A PREVIOUSLY ANTICIPATED LOSS ASSOCIATED WITH THE HTEAL PROCEEDINGS, OFFSET IN PART BY INCREASES IN COMPENSATION AND RELATED BENEFITS ASSOCIATED WITH HEADCOUNT.\\n\\nTHE INCREASE IN RESEARCH AND DEVELOPMENT AND GENERAL AND ADMINISTRATIVE EXPENSES DURING FISCAL 2014 AS COMPARED TO FISCAL 2013 WAS PRIMARILY DUE TO INCREASES IN CASH INCENTIVE AND STOCK-BASED COMPENSATION. THE INCREASE IN STOCK-BASED COMPENSATION WAS DRIVEN BY A CHANGE IN THE VESTING TERM FOR STOCK AWARDS GRANTED AS PART OF OUR ANNUAL REVIEW PROCESS BEGINNING IN FISCAL 2013, WHICH DECREASED THE TERM FROM FOUR YEARS TO THREE YEARS. THE INCREASE IN SALES AND MARKETING EXPENSE DURING FISCAL 2014 AS COMPARED TO FISCAL 2013 WAS PRIMARILY DUE TO COMPENSATION AND RELATED BENEFITS ASSOCIATED WITH ADDITIONAL HEADCOUNT.\\n\\nRESEARCH AND DEVELOPMENT\\n\\nRESEARCH AND DEVELOPMENT EXPENSES CONSIST PRIMARILY OF SALARY AND BENEFIT EXPENSES FOR SOFTWARE DEVELOPERS, CONTRACTED DEVELOPMENT EFFORTS, RELATED FACILITIES COSTS AND EXPENSES ASSOCIATED WITH COMPUTER EQUIPMENT USED IN SOFTWARE DEVELOPMENT.\\n\\nRESEARCH AND DEVELOPMENT EXPENSES\\n\\nINCREASED\\n\\nDUE TO THE FOLLOWING.% CHANGE\\n\\n2015-2014% CHANGE\\n\\n2014-2013\\n\\nCOMPENSATION AND RELATED BENEFITS ASSOCIATED WITH HEADCOUNT\\n\\n2%\\n\\n—%\\n\\nCOMPENSATION ASSOCIATED WITH CASH AND STOCK-BASED INCENTIVES\\n\\n(1\\n\\n)\\n\\n2\\n\\nVARIOUS INDIVIDUALLY INSIGNIFICANT ITEMS\\n\\n1\\n\\n—\\n\\nTOTAL CHANGE\\n\\n2%\\n\\n2%\\n\\nWE BELIEVE THAT INVESTMENTS IN RESEARCH AND DEVELOPMENT, INCLUDING THE RECRUITING AND HIRING OF SOFTWARE DEVELOPERS, ARE CRITICAL TO REMAIN COMPETITIVE IN THE MARKETPLACE AND ARE DIRECTLY RELATED TO CONTINUED TIMELY DEVELOPMENT OF NEW AND ENHANCED PRODUCTS, SUBSCRIPTION AND SOLUTION OFFERINGS. WE WILL CONTINUE TO FOCUS ON LONG-TERM OPPORTUNITIES AVAILABLE IN OUR END MARKETS AND MAKE SIGNIFICANT INVESTMENTS IN THE DEVELOPMENT OF OUR APPLICATION, TOOL, SUBSCRIPTION AND SERVICE OFFERINGS.\\n\\nSALES AND MARKETING\\n\\nSALES AND MARKETING EXPENSES CONSIST PRIMARILY OF SALARY AND BENEFIT EXPENSES, SALES COMMISSIONS, TRAVEL EXPENSES AND RELATED FACILITIES COSTS FOR OUR SALES, MARKETING, ORDER MANAGEMENT AND GLOBAL SUPPLY CHAIN MANAGEMENT PERSONNEL. SALES AND MARKETING EXPENSES ALSO INCLUDE THE COSTS OF PROGRAMS AIMED AT INCREASING REVENUE, SUCH AS ADVERTISING, TRADE SHOWS, PUBLIC RELATIONS AND OTHER MARKET DEVELOPMENT PROGRAMS.\\n\\nSALES AND MARKETING EXPENSES\\n\\nINCREASED\\n\\nDUE TO THE FOLLOWING.% CHANGE\\n\\n2015-2014% CHANGE\\n\\n2014-2013\\n\\nCOMPENSATION AND RELATED BENEFITS ASSOCIATED WITH HEADCOUNT\\n\\n3%\\n\\n1%\\n\\nCOMPENSATION ASSOCIATED WITH CASH INCENTIVES\\n\\n(2\\n\\n)\\n\\n—\\n\\nPROFESSIONAL AND CONSULTING FEES\\n\\n(2\\n\\n)\\n\\n—\\n\\nMARKETING SPENDING RELATED TO PRODUCT LAUNCHES AND OVERALL MARKETING EFFORTS\\n\\n2\\n\\n—\\n\\nVARIOUS INDIVIDUALLY INSIGNIFICANT ITEMS\\n\\n1\\n\\n1\\n\\nTOTAL CHANGE\\n\\n2%\\n\\n2%\\n\\nGENERAL AND ADMINISTRATIVE\\n\\nGENERAL AND ADMINISTRATIVE EXPENSES CONSIST PRIMARILY OF COMPENSATION AND BENEFIT EXPENSES, TRAVEL EXPENSES AND RELATED FACILITIES COSTS FOR OUR FINANCE, FACILITIES, HUMAN RESOURCES, LEGAL, INFORMATION SERVICES AND EXECUTIVE PERSONNEL. GENERAL AND ADMINISTRATIVE EXPENSES ALSO INCLUDE OUTSIDE LEGAL AND ACCOUNTING FEES, PROVISION FOR BAD DEBTS, EXPENSES ASSOCIATED WITH COMPUTER EQUIPMENT AND SOFTWARE USED IN THE ADMINISTRATION OF THE BUSINESS, CHARITABLE CONTRIBUTIONS AND VARIOUS FORMS OF INSURANCE.\\n\\n47\\n\\nTABLE OF CONTENTS\\n\\nTHE FLUCTUATIONS IN GENERAL AND ADMINISTRATIVE EXPENSES ARE DUE TO THE FOLLOWING.% CHANGE\\n\\n2015-2014% CHANGE\\n\\n2014-2013\\n\\nCOMPENSATION AND RELATED BENEFITS ASSOCIATED WITH HEADCOUNT\\n\\n3%\\n\\n—%\\n\\nCOMPENSATION ASSOCIATED WITH CASH AND STOCK-BASED INCENTIVES\\n\\n(3\\n\\n)\\n\\n3\\n\\nPROFESSIONAL AND CONSULTING FEES\\n\\n1\\n\\n(2\\n\\n)\\n\\nLOSS CONTINGENCY\\n\\n(4\\n\\n)\\n\\n2\\n\\nVARIOUS INDIVIDUALLY INSIGNIFICANT ITEMS\\n\\n1\\n\\n1\\n\\nTOTAL CHANGE\\n\\n(2\\n\\n)%\\n\\n4%\\n\\nTHE DECREASE IN LOSS CONTINGENCY DURING FISCAL 2015 AS COMPARED TO FISCAL 2014 IS DUE TO THE REVERSAL OF A PREVIOUSLY ANTICIPATED LOSS ASSOCIATED WITH THE HTEAL PROCEEDINGS.\\n\\nSEE NOTE 15 OF OUR NOTES TO THE CONSOLIDATED FINANCIAL STATEMENTS FOR FURTHER INFORMATION REGARDING THE HTEAL PROCEEDINGS.\\n\\nRESTRUCTURING AND OTHER CHARGES\\n\\nDURING THE PAST SEVERAL YEARS, WE HAVE INITIATED VARIOUS RESTRUCTURING PLANS CONSISTING OF REDUCTIONS IN WORKFORCE AND THE CONSOLIDATION OF FACILITIES TO BETTER ALIGN OUR RESOURCES AROUND OUR BUSINESS STRATEGIES. AS OF\\n\\nNOVEMBER 27, 2015\\n\\n, WE CONSIDERED ALL OUR RESTRUCTURING PLANS TO BE SUBSTANTIALLY COMPLETE. WE CONTINUE TO MAKE CASH OUTLAYS TO SETTLE OBLIGATIONS UNDER THESE PLANS, HOWEVER THE CURRENT IMPACT TO OUR CONSOLIDATED FINANCIAL STATEMENTS IS NOT MATERIAL.\\n\\nDURING FISCAL 2015, WE RECORDED IMMATERIAL CREDITS AND CHARGES TO OUR RESTRUCTURING PLANS.\\n\\nDURING FISCAL 2014, IN CONNECTION WITH OUR FISCAL 2014 RESTRUCTURING PLAN, WE RECORDED\\n\\n$19.4 MILLION\\n\\nASSOCIATED WITH TERMINATION BENEFITS AND CLOSING REDUNDANT FACILITIES. IN CONNECTION WITH OUR OTHER RESTRUCTURING PLANS, WE RECORDED INSIGNIFICANT CHARGES ASSOCIATED WITH CLOSING REDUNDANT FACILITIES.\\n\\nDURING FISCAL 2013, WE SOLD LAND, BUILDING AND OTHER ASSETS LOCATED IN WALTHAM, MASSACHUSETTS FOR NET PROCEEDS OF\\n\\n$24.3 MILLION\\n\\n. BECAUSE THE TOTAL CARRYING AMOUNT OF THESE ASSETS WAS\\n\\n$47.4 MILLION\\n\\nAT THE TIME IT WAS CLASSIFIED AS HELD FOR SALE, WE RECORDED A WRITE-DOWN OF $23.1 MILLION DURING FISCAL 2013.\\n\\nALSO DURING FISCAL 2013, IN CONNECTION WITH OUR FISCAL 2011 RESTRUCTURING PLAN AND OTHER RESTRUCTURING PLANS, WE RECORDED IMMATERIAL CHARGES AND CREDITS ASSOCIATED WITH TERMINATION BENEFITS AND CLOSING REDUNDANT FACILITIES DURING THE FISCAL YEAR.\\n\\nSEE NOTE 10 OF OUR NOTES TO CONSOLIDATED FINANCIAL STATEMENTS FOR FURTHER INFORMATION REGARDING OUR RESTRUCTURING PLANS.\\n\\nAMORTIZATION OF PURCHASED INTANGIBLES\\n\\nDURING THE LAST SEVERAL YEARS, WE HAVE COMPLETED A NUMBER OF BUSINESS COMBINATIONS AND ASSET ACQUISITIONS. AS A RESULT OF THESE ACQUISITIONS, WE PURCHASED INTANGIBLE ASSETS THAT ARE BEING AMORTIZED OVER THEIR ESTIMATED USEFUL LIVES RANGING FROM\\n\\nONE\\n\\nTO\\n\\nFOURTEEN\\n\\nYEARS.\\n\\nAMORTIZATION EXPENSE\\n\\nINCREASED\\n\\nDURING FISCAL 2015 AS COMPARED TO FISCAL 2014 PRIMARILY DUE TO AMORTIZATION EXPENSE ASSOCIATED WITH INTANGIBLE ASSETS PURCHASED THROUGH OUR ACQUISITION OF FOTOLIA IN FISCAL 2015, PARTIALLY OFFSET BY THE DECREASE IN AMORTIZATION EXPENSE ASSOCIATED WITH CERTAIN INTANGIBLE ASSETS PURCHASED THROUGH OUR ACQUISITION OF EFFICIENT FRONTIER AND DAY SOFTWARE HOLDING AG THAT WERE FULLY AMORTIZED AT THE END OF FISCAL 2014.\\n\\nAMORTIZATION EXPENSE REMAINED STABLE DURING FISCAL 2014 AS COMPARED TO FISCAL 2013.\\n\\n48\\n\\nTABLE OF CONTENTS\\n\\nNON-OPERATING INCOME (EXPENSE), NET (DOLLARS IN MILLIONS)\\n\\nFISCAL\\n\\n2015\\n\\nFISCAL\\n\\n2014\\n\\nFISCAL\\n\\n2013% CHANGE\\n\\n2015-2014% CHANGE\\n\\n2014-2013\\n\\nINTEREST AND OTHER INCOME (EXPENSE), NET\\n\\n$33.9\\n\\n$7.3\\n\\n$4.9\\n\\n*\\n\\n49%\\n\\nPERCENTAGE OF TOTAL REVENUE\\n\\n**\\n\\n**\\n\\n**\\n\\nINTEREST EXPENSE\\n\\n(64.2\\n\\n)\\n\\n(59.7\\n\\n)\\n\\n(67.5\\n\\n)\\n\\n8%\\n\\n(12\\n\\n)%\\n\\nPERCENTAGE OF TOTAL REVENUE\\n\\n(1\\n\\n)%\\n\\n(1\\n\\n)%\\n\\n(2\\n\\n)%\\n\\nINVESTMENT GAINS (LOSSES), NET\\n\\n1.0\\n\\n1.1\\n\\n(4.0\\n\\n)\\n\\n*\\n\\n*\\n\\nPERCENTAGE OF TOTAL REVENUE\\n\\n**\\n\\n**\\n\\n**\\n\\nTOTAL NON-OPERATING INCOME (EXPENSE), NET\\n\\n$(29.3\\n\\n)\\n\\n$(51.3\\n\\n)\\n\\n$(66.6\\n\\n)\\n\\n(43\\n\\n)%\\n\\n(23\\n\\n)%\\n\\n_________________________________________\\n\\n(*)\\n\\nPERCENTAGE IS NOT MEANINGFUL.\\n\\n(**)\\n\\nPERCENTAGE IS LESS THAN 1%.\\n\\nINTEREST AND OTHER INCOME (EXPENSE), NET\\n\\nINTEREST AND OTHER INCOME (EXPENSE), NET CONSISTS PRIMARILY OF INTEREST EARNED ON CASH, CASH EQUIVALENTS AND SHORT-TERM FIXED INCOME INVESTMENTS. INTEREST AND OTHER INCOME (EXPENSE), NET ALSO INCLUDES GAINS AND LOSSES ON FIXED INCOME INVESTMENTS AND FOREIGN EXCHANGE GAINS AND LOSSES OTHER THAN ANY GAINS RECORDED TO REVENUE FROM OUR HEDGING PROGRAMS.\\n\\nINTEREST AND OTHER INCOME (EXPENSE), NET\\n\\nINCREASED\\n\\nIN FISCAL 2015 AS COMPARED TO FISCAL 2014 PRIMARILY DUE TO THE GAIN ON THE SALE OF CERTAIN PROPERTY ASSETS AND, TO A LESSER EXTENT, AN INCREASED AVERAGE INVESTMENT BALANCE AND AVERAGE INTEREST RATE.\\n\\nSEE NOTE 6 OF OUR NOTES TO CONSOLIDATED FINANCIAL STATEMENTS FOR FURTHER DETAILS REGARDING THE SALE OF OUR PROPERTY ASSETS.\\n\\nINTEREST AND OTHER INCOME (EXPENSE), NET\\n\\nINCREASED\\n\\nIN FISCAL 2014 AS COMPARED TO FISCAL 2013 PRIMARILY DUE TO DECREASED FOREIGN CURRENCY LOSSES AND INCREASED REALIZED GAINS ON FIXED INCOME INVESTMENTS. THE INCREASES WERE PARTIALLY OFFSET BY DECREASED INTEREST INCOME ON OUR INVESTMENT IN LEASE RECEIVABLE DUE TO THE PURCHASE OF THE EAST AND WEST TOWERS OF OUR CORPORATE HEADQUARTER OFFICES DURING FISCAL 2014.\\n\\nSEE NOTE 15 OF OUR NOTES TO CONSOLIDATED FINANCIAL STATEMENTS FOR FURTHER DETAILS REGARDING OUR INVESTMENT IN LEASE RECEIVABLES.\\n\\nINTEREST EXPENSE\\n\\nINTEREST EXPENSE PRIMARILY REPRESENTS INTEREST ASSOCIATED WITH OUR SENIOR NOTES AND INTEREST RATE SWAPS. INTEREST ON OUR SENIOR NOTES IS PAYABLE SEMI-ANNUALLY, IN ARREARS, ON FEBRUARY 1 AND AUGUST 1. FLOATING INTEREST PAYMENTS ON THE INTEREST RATE SWAPS ARE PAID MONTHLY. THE FIXED-RATE INTEREST RECEIVABLE ON THE SWAPS IS RECEIVED SEMI-ANNUALLY CONCURRENT WITH THE SENIOR NOTES INTEREST PAYMENTS.\\n\\nINTEREST EXPENSE\\n\\nINCREASED\\n\\nDURING FISCAL 2015 AS COMPARED TO FISCAL 2014 PRIMARILY DUE TO THE INCREASE IN TOTAL DEBT, PARTIALLY OFFSET BY THE FAVORABLE IMPACT OF THE INTEREST RATE SWAPS.\\n\\nINTEREST EXPENSE\\n\\nDECREASED\\n\\nDURING FISCAL 2014 AS COMPARED TO FISCAL 2013 DUE TO THE FAVORABLE IMPACT OF THE INTEREST RATE SWAPS.\\n\\nSEE NOTES 5\\n\\nAND 13 OF OUR NOTES TO CONSOLIDATED FINANCIAL STATEMENTS FOR FURTHER DETAILS REGARDING OUR INTEREST RATE SWAPS.\\n\\nINVESTMENT GAINS (LOSSES), NET\\n\\nINVESTMENT GAINS (LOSSES), NET CONSISTS PRINCIPALLY OF REALIZED GAINS OR LOSSES FROM THE SALE OF MARKETABLE EQUITY INVESTMENTS, OTHER-THAN-TEMPORARY DECLINES IN THE VALUE OF MARKETABLE AND NON-MARKETABLE EQUITY SECURITIES AND UNREALIZED HOLDING GAINS AND LOSSES ASSOCIATED WITH OUR DEFERRED COMPENSATION PLAN ASSETS (CLASSIFIED AS TRADING SECURITIES) AND GAINS AND LOSSES ASSOCIATED WITH OUR DIRECT AND INDIRECT INVESTMENTS IN PRIVATELY HELD COMPANIES.\\n\\nDURING FISCAL 2015, TOTAL INVESTMENT GAINS (LOSSES), NET REMAINED STABLE COMPARED TO FISCAL 2014.\\n\\nDURING FISCAL 2014, TOTAL INVESTMENT GAINS (LOSSES), NET\\n\\nINCREASED\\n\\nTO NET GAINS PRIMARILY DUE TO WRITE-DOWNS FOR OTHER-THAN-TEMPORARY DECLINES IN VALUE OF OUR DIRECT INVESTMENTS IN PRIVATELY HELD COMPANIES IN FISCAL 2013 THAT DID NOT RECUR IN FISCAL 2014, OFFSET IN PART BY A DECREASE IN NET GAINS RELATED TO OUR TRADING SECURITIES.\\n\\n49\\n\\nTABLE OF CONTENTS\\n\\nPROVISION FOR INCOME TAXES (DOLLARS IN MILLIONS)\\n\\nFISCAL\\n\\n2015\\n\\nFISCAL\\n\\n2014\\n\\nFISCAL\\n\\n2013% CHANGE\\n\\n2015-2014% CHANGE\\n\\n2014-2013\\n\\nPROVISION\\n\\n$244.2\\n\\n$93.0\\n\\n$66.2\\n\\n163%\\n\\n40%\\n\\nPERCENTAGE OF TOTAL REVENUE\\n\\n5%\\n\\n2%\\n\\n2%\\n\\nEFFECTIVE TAX RATE\\n\\n28%\\n\\n26%\\n\\n19%\\n\\nOUR EFFECTIVE TAX RATE INCREASED BY APPROXIMATELY TWO PERCENTAGE POINTS DURING FISCAL 2015 AS COMPARED TO FISCAL 2014. THE INCREASE WAS PRIMARILY DUE TO TAX COSTS ASSOCIATED WITH LICENSING ACQUIRED COMPANY ASSETS TO ADOBE’S TRADING COMPANIES. THE INCREASE WAS PARTIALLY OFFSET BY TAX BENEFITS RELATED TO THE REINSTATEMENT OF THE FEDERAL RESEARCH AND DEVELOPMENT TAX CREDIT IN DECEMBER 2014. THE REINSTATEMENT OF THE CREDIT WAS RETROACTIVE TO JANUARY 1, 2014.\\n\\nOUR EFFECTIVE TAX RATE INCREASED BY APPROXIMATELY SEVEN PERCENTAGE POINTS DURING FISCAL 2014 AS COMPARED TO FISCAL 2013. THE INCREASE WAS PRIMARILY DUE TO THE EXPIRATION OF THE FEDERAL RESEARCH AND DEVELOPMENT TAX CREDIT IN DECEMBER 2013 AND STRONGER DOMESTIC PROFITS FOR FISCAL 2014.\\n\\nIN DECEMBER 2015, THE UNITED STATES CONGRESS PASSED THE PERMANENT EXTENSION OF THE FEDERAL RESEARCH AND DEVELOPMENT TAX CREDIT. AS A RESULT, WE EXPECT THAT OUR INCOME TAX PROVISION FOR THE FIRST QUARTER OF FISCAL 2016 WILL INCLUDE A DISCRETE TAX BENEFIT FOR THE 2015 CREDIT WHICH WILL REDUCE OUR EFFECTIVE TAX RATE FOR THE QUARTER AND, TO A LESSER EXTENT, THE EFFECTIVE ANNUAL TAX RATE.\\n\\nWE ARE A UNITED STATES-BASED MULTINATIONAL COMPANY SUBJECT TO TAX IN MULTIPLE U.S. AND FOREIGN TAX JURISDICTIONS. A SIGNIFICANT PORTION OF OUR FOREIGN EARNINGS FOR THE CURRENT FISCAL YEAR WERE EARNED BY OUR IRISH SUBSIDIARIES. IN ADDITION TO PROVIDING FOR U.S. INCOME TAXES ON EARNINGS FROM THE UNITED STATES, WE PROVIDE FOR U.S. INCOME TAXES ON THE EARNINGS OF FOREIGN SUBSIDIARIES UNLESS THE SUBSIDIARIES’ EARNINGS ARE CONSIDERED PERMANENTLY REINVESTED OUTSIDE THE UNITED STATES. WHILE WE DO NOT ANTICIPATE CHANGING OUR INTENTION REGARDING PERMANENTLY REINVESTED EARNINGS, IF CERTAIN FOREIGN EARNINGS PREVIOUSLY TREATED AS PERMANENTLY REINVESTED ARE REPATRIATED, THE RELATED U.S. TAX LIABILITY MAY BE REDUCED BY ANY FOREIGN INCOME TAXES PAID ON THESE EARNINGS. CURRENTLY, THERE ARE A SIGNIFICANT AMOUNT OF FOREIGN EARNINGS UPON WHICH U.S. INCOME TAXES HAVE NOT BEEN PROVIDED.\\n\\nSEE NOTE 9 OF OUR NOTES TO THE CONSOLIDATED FINANCIAL STATEMENTS FOR FURTHER INFORMATION ON OUR PROVISION FOR INCOME TAXES.\\n\\nACCOUNTING FOR UNCERTAINTY IN INCOME TAXES\\n\\nTHE GROSS LIABILITY FOR UNRECOGNIZED TAX BENEFITS AT\\n\\nNOVEMBER 27, 2015\\n\\nWAS\\n\\n$258.7 MILLION\\n\\n, EXCLUSIVE OF INTEREST AND PENALTIES. IF THE TOTAL UNRECOGNIZED TAX BENEFITS AT\\n\\nNOVEMBER 27, 2015\\n\\nWERE RECOGNIZED IN THE FUTURE,\\n\\n$220.2 MILLION\\n\\nOF UNRECOGNIZED TAX BENEFITS WOULD DECREASE THE EFFECTIVE TAX RATE, WHICH IS NET OF AN ESTIMATED\\n\\n$38.5 MILLION\\n\\nFEDERAL BENEFIT RELATED TO DEDUCTING CERTAIN PAYMENTS ON FUTURE FEDERAL AND STATE TAX RETURNS.\\n\\nAS OF\\n\\nNOVEMBER 27, 2015\\n\\n, THE COMBINED AMOUNT OF ACCRUED INTEREST AND PENALTIES RELATED TO TAX POSITIONS TAKEN ON OUR TAX RETURNS WAS APPROXIMATELY\\n\\n$27.8 MILLION\\n\\n. THIS AMOUNT IS INCLUDED IN NON-CURRENT INCOME TAXES PAYABLE.\\n\\nTHE TIMING OF THE RESOLUTION OF INCOME TAX EXAMINATIONS IS HIGHLY UNCERTAIN AS ARE THE AMOUNTS AND TIMING OF TAX PAYMENTS THAT ARE PART OF ANY AUDIT SETTLEMENT PROCESS. THESE EVENTS COULD CAUSE LARGE FLUCTUATIONS IN THE BALANCE SHEET CLASSIFICATION OF CURRENT AND NON-CURRENT ASSETS AND LIABILITIES. WE BELIEVE THAT WITHIN THE NEXT 12 MONTHS, IT IS REASONABLY POSSIBLE THAT EITHER CERTAIN AUDITS WILL CONCLUDE OR STATUTES OF LIMITATIONS ON CERTAIN INCOME TAX EXAMINATION PERIODS WILL EXPIRE, OR BOTH. GIVEN THE UNCERTAINTIES DESCRIBED ABOVE, WE CAN ONLY DETERMINE A RANGE OF ESTIMATED POTENTIAL DECREASES IN UNDERLYING UNRECOGNIZED TAX BENEFITS RANGING FROM\\n\\n$0\\n\\nTO APPROXIMATELY\\n\\n$10 MILLION.\\n\\n50\\n\\nTABLE OF CONTENTS\\n\\nLIQUIDITY AND CAPITAL RESOURCES\\n\\nTHIS DATA SHOULD BE READ IN CONJUNCTION WITH OUR CONSOLIDATED STATEMENTS OF CASH FLOWS.\\n\\nAS OF\\n\\n(IN MILLIONS)\\n\\nNOVEMBER 27, 2015\\n\\nNOVEMBER 28, 2014\\n\\nCASH AND CASH EQUIVALENTS\\n\\n$876.6\\n\\n$1,117.4\\n\\nSHORT-TERM INVESTMENTS\\n\\n$3,111.5\\n\\n$2,622.1\\n\\nWORKING CAPITAL\\n\\n$2,608.3\\n\\n$2,107.9\\n\\nSTOCKHOLDERS’ EQUITY\\n\\n$7,001.6\\n\\n$6,775.9\\n\\nA SUMMARY OF OUR CASH FLOWS IS AS FOLLOWS.\\n\\n(IN MILLIONS)\\n\\nFISCAL\\n\\n2015\\n\\nFISCAL\\n\\n2014\\n\\nFISCAL\\n\\n2013\\n\\nNET CASH PROVIDED BY OPERATING ACTIVITIES\\n\\n$1,469.5\\n\\n$1,287.5\\n\\n$1,151.7\\n\\nNET CASH USED FOR INVESTING ACTIVITIES\\n\\n(1,488.4\\n\\n)\\n\\n(490.7\\n\\n)\\n\\n(1,177.8\\n\\n)\\n\\nNET CASH USED FOR FINANCING ACTIVITIES\\n\\n(200.7\\n\\n)\\n\\n(507.3\\n\\n)\\n\\n(559.1\\n\\n)\\n\\nEFFECT OF FOREIGN CURRENCY EXCHANGE RATES ON CASH AND CASH EQUIVALENTS\\n\\n(21.2\\n\\n)\\n\\n(6.7\\n\\n)\\n\\n(5.2\\n\\n)\\n\\nNET INCREASE (DECREASE) IN CASH AND CASH EQUIVALENTS\\n\\n$(240.8\\n\\n)\\n\\n$282.8\\n\\n$(590.4\\n\\n)\\n\\nOUR PRIMARY SOURCE OF CASH IS RECEIPTS FROM REVENUE. THE PRIMARY USES OF CASH ARE PAYROLL RELATED EXPENSES, GENERAL OPERATING EXPENSES INCLUDING MARKETING, TRAVEL AND OFFICE RENT, AND COST OF REVENUE. OTHER SOURCES OF CASH ARE PROCEEDS FROM THE EXERCISE OF EMPLOYEE OPTIONS AND PARTICIPATION IN THE EMPLOYEE STOCK PURCHASE PLAN. OTHER USES OF CASH INCLUDE OUR STOCK REPURCHASE PROGRAM, WHICH IS DESCRIBED BELOW, BUSINESS ACQUISITIONS AND PURCHASES OF PROPERTY AND EQUIPMENT.\\n\\nCASH FLOWS FROM OPERATING ACTIVITIES\\n\\nFOR FISCAL 2015, NET CASH PROVIDED BY OPERATING ACTIVITIES OF\\n\\n$1.47 BILLION\\n\\nWAS PRIMARILY COMPRISED OF NET INCOME PLUS THE NET EFFECT OF NON-CASH ITEMS. THE PRIMARY WORKING CAPITAL SOURCES OF CASH WERE NET INCOME COUPLED WITH INCREASES IN DEFERRED REVENUE, INCOME TAXES PAYABLE AND TRADE PAYABLES. THE INCREASE IN DEFERRED REVENUE IS PRIMARILY DUE TO INCREASED SUBSCRIPTIONS FOR OUR TEAM, INDIVIDUAL AND ENTERPRISE CREATIVE CLOUD OFFERINGS AND INCREASES IN DIGITAL MARKETING HOSTED SERVICES. THE INCREASE IN INCOME TAXES PAYABLE IS PRIMARILY DUE TO HIGHER TAXABLE INCOME LEVELS DURING FISCAL 2015. TRADE PAYABLES INCREASED PRIMARILY DUE TO THE TIMING OF PAYMENTS TO WEB SERVICES VENDORS AS CERTAIN INVOICES WERE RECEIVED IN THE FINAL WEEKS OF FISCAL 2015. THE PRIMARY WORKING CAPITAL USES OF CASH WERE INCREASES IN TRADE RECEIVABLES WHICH WERE PRINCIPALLY DUE TO HIGHER REVENUE LEVELS.\\n\\nFOR FISCAL 2014, NET CASH PROVIDED BY OPERATING ACTIVITIES OF\\n\\n$1.29 BILLION\\n\\nWAS PRIMARILY COMPRISED OF NET INCOME PLUS THE NET EFFECT OF NON-CASH ITEMS. THE PRIMARY WORKING CAPITAL SOURCES OF CASH WERE NET INCOME COUPLED WITH INCREASES IN DEFERRED REVENUE AND ACCRUED EXPENSES. THE INCREASE IN DEFERRED REVENUE WAS PRIMARILY DUE TO INCREASED SUBSCRIPTION AND ETLA ACTIVITY FOR OUR INDIVIDUAL, TEAM AND ENTERPRISE CREATIVE CLOUD OFFERINGS AND INCREASES IN DIGITAL MARKETING AND DIGITAL PUBLISHING HOSTED SERVICES, OFFSET IN PART BY DECREASES IN BILLINGS FOR OUR MAINTENANCE AND CREATIVE PRODUCT SOFTWARE UPGRADE PLANS WHICH WE DISCONTINUED IN JANUARY 2013. ACCRUED EXPENSES INCREASED PRIMARILY DUE TO ACCRUALS FOR CONTRACT TERMINATIONS AND EMPLOYEE TRANSITION PAYMENTS ASSOCIATED WITH BUSINESS REALIGNMENT INITIATIVES IMPLEMENTED IN THE FOURTH QUARTER OF FISCAL 2014.\\n\\nFOR FISCAL 2013, NET CASH PROVIDED BY OPERATING ACTIVITIES OF\\n\\n$1.15 BILLION\\n\\nWAS PRIMARILY COMPRISED OF NET INCOME PLUS THE NET EFFECT OF NON-CASH ITEMS. THE PRIMARY WORKING CAPITAL SOURCES OF CASH WERE NET INCOME COUPLED WITH INCREASES IN DEFERRED REVENUE AND ACCRUED EXPENSES AND DECREASES IN TRADE RECEIVABLES. DEFERRED REVENUE INCREASED PRIMARILY DUE TO INCREASED SUBSCRIPTION AND ETLA ACTIVITY FOR OUR CREATIVE CLOUD OFFERING AND INCREASES IN DIGITAL MARKETING HOSTED SERVICES, OFFSET IN PART BY DECREASES IN BILLINGS FOR OUR MAINTENANCE AND CREATIVE PRODUCT SOFTWARE UPGRADE PLANS WHICH WERE DISCONTINUED IN JANUARY 2013. ACCRUED EXPENSES INCREASED PRIMARILY DUE TO AMOUNTS DUE UNDER OUR FISCAL 2013 ANNUAL INCENTIVE PLAN AND SALES COMMISSION ACCRUALS ASSOCIATED WITH HIGHER ACHIEVEMENT LEVELS. TRADE RECEIVABLES DECLINED PRIMARILY DUE TO LOWER PERPETUAL LICENSE REVENUE LEVELS AND IMPROVED COLLECTIONS COMPARED TO THE FOURTH QUARTER OF FISCAL 2012.\\n\\nTHE PRIMARY WORKING CAPITAL USES OF CASH FOR FISCAL 2013 WERE DECREASES IN TAXES PAYABLE AND INCREASES IN PREPAID EXPENSES AND OTHER ASSETS. THE DECREASE IN TAXES PAYABLE WAS LARGELY ATTRIBUTED TO TAX PAYMENTS MADE COMBINED WITH AUDIT SETTLEMENT ADJUSTMENTS, OFFSET IN PART BY TAX EXPENSE AND OTHER ADJUSTMENTS DURING FISCAL 2013. PREPAID EXPENSES AND OTHER ASSETS INCREASED PRIMARILY DUE TO INCREASES IN SHORT-TERM INCOME TAX RECEIVABLES RELATED TO THE CARRYBACK OF FEDERAL RESEARCH AND DEVELOPMENT AND FOREIGN TAX CREDITS IN THE FOURTH QUARTER OF FISCAL 2013.\\n\\n51\\n\\nTABLE OF CONTENTS\\n\\nCASH FLOWS FROM INVESTING ACTIVITIES\\n\\nFOR FISCAL 2015, NET CASH USED FOR INVESTING ACTIVITIES OF\\n\\n$1.49 BILLION\\n\\nWAS PRIMARILY DUE TO PURCHASES OF SHORT-TERM INVESTMENTS AND OUR ACQUISITION OF FOTOLIA. OTHER USES OF CASH DURING FISCAL 2015 REPRESENTED PURCHASES OF PROPERTY AND EQUIPMENT, AND LONG-TERM INVESTMENTS AND OTHER ASSETS. THESE CASH OUTFLOWS WERE OFFSET IN PART BY SALES AND MATURITIES OF SHORT-TERM INVESTMENTS AND PROCEEDS RECEIVED FROM THE SALE OF CERTAIN PROPERTY ASSETS.\\n\\nSEE NOTE 2\\n\\nAND\\n\\nNOTE 6\\n\\nOF OUR CONSOLIDATED FINANCIAL STATEMENTS FOR MORE DETAILED INFORMATION REGARDING OUR ACQUISITION OF FOTOLIA AND SALE OF PROPERTY ASSETS, RESPECTIVELY.\\n\\nFOR FISCAL 2014, NET CASH USED FOR INVESTING ACTIVITIES OF\\n\\n$490.7 MILLION\\n\\nWAS PRIMARILY DUE TO PURCHASES OF SHORT-TERM INVESTMENTS, PURCHASES OF PROPERTY AND EQUIPMENT AND A BUSINESS ACQUISITION. THESE CASH OUTFLOWS WERE OFFSET IN PART BY SALES AND MATURITIES OF SHORT-TERM INVESTMENTS.\\n\\nFOR FISCAL 2013, NET CASH USED FOR INVESTING ACTIVITIES OF\\n\\n$1.18 BILLION\\n\\nWAS PRIMARILY DUE TO OUR ACQUISITIONS OF NEOLANE AND BEHANCE. OTHER USES OF CASH DURING FISCAL 2013 REPRESENTED PURCHASES OF SHORT-TERM INVESTMENTS, PURCHASES OF PROPERTY AND EQUIPMENT ASSOCIATED WITH OUR CONSTRUCTION PROJECTS IN OREGON AND INDIA AND PURCHASES OF LONG-TERM TECHNOLOGY LICENSES. THESE CASH OUTFLOWS WERE OFFSET IN PART BY SALES AND MATURITIES OF SHORT-TERM INVESTMENTS AND THE SALE OF CERTAIN PROPERTY ASSETS.\\n\\nSEE NOTE 2 OF OUR NOTES TO THE CONSOLIDATED FINANCIAL STATEMENTS FOR MORE DETAILED INFORMATION REGARDING OUR ACQUISITIONS OF NEOLANE AND BEHANCE.\\n\\nCASH FLOWS FROM FINANCING ACTIVITIES\\n\\nIN JANUARY 2015, WE ISSUED\\n\\n$1 BILLION\\n\\nOF\\n\\n3.25%\\n\\nSENIOR NOTES DUE\\n\\nFEBRUARY 1, 2025\\n\\n(THE “2025 NOTES”). OUR PROCEEDS WERE APPROXIMATELY\\n\\n$989.3 MILLION\\n\\nWHICH IS NET OF AN ISSUANCE DISCOUNT OF\\n\\n$10.7 MILLION\\n\\n. THE 2025 NOTES RANK EQUALLY WITH OUR OTHER UNSECURED AND UNSUBORDINATED INDEBTEDNESS. IN ADDITION, WE INCURRED ISSUANCE COSTS OF\\n\\n$7.9 MILLION\\n\\nIN CONNECTION WITH OUR 2025 NOTES. BOTH THE DISCOUNT AND ISSUANCE COSTS ARE BEING AMORTIZED TO INTEREST EXPENSE OVER THE TERM OF THE 2025 NOTES USING THE EFFECTIVE INTEREST METHOD.\\n\\nWE USED\\n\\n$600 MILLION\\n\\nOF THE PROCEEDS FROM THE 2025 NOTES OFFERING TO REPAY THE OUTSTANDING BALANCE PLUS ACCRUED AND UNPAID INTEREST OF THE\\n\\n$600 MILLION\\n\\n3.25%\\n\\nSENIOR NOTES DUE FEBRUARY 1, 2015 (“2015 NOTES”). THE REMAINING PROCEEDS WERE USED FOR GENERAL CORPORATE PURPOSES.\\n\\nSEE NOTE 16 OF OUR CONSOLIDATED FINANCIAL STATEMENTS FOR MORE DETAILED INFORMATION.\\n\\nIN ADDITION TO THE 2025 NOTES ISSUANCE AND 2015 NOTES REPAYMENT, OTHER FINANCING ACTIVITIES DURING FISCAL\\n\\n2015\\n\\nINCLUDE PAYMENTS FOR OUR TREASURY STOCK REPURCHASES AND COSTS ASSOCIATED WITH THE ISSUANCE OF TREASURY STOCK, OFFSET IN PART BY PROCEEDS FROM THE ISSUANCE OF TREASURY STOCK AND EXCESS TAX BENEFITS FROM STOCK-BASED COMPENSATION.\\n\\nFOR FISCAL\\n\\n2014\\n\\nAND\\n\\n2013\\n\\n, NET CASH USED FOR FINANCING ACTIVITIES OF\\n\\n$507.3 MILLION\\n\\nAND\\n\\n$559.1 MILLION\\n\\n, RESPECTIVELY, WAS PRIMARILY DUE TO PAYMENTS FOR OUR TREASURY STOCK REPURCHASES AND COSTS ASSOCIATED WITH THE ISSUANCE OF TREASURY STOCK, OFFSET IN PART BY PROCEEDS FROM THE ISSUANCE OF TREASURY STOCK AND EXCESS TAX BENEFITS FROM STOCK-BASED COMPENSATION.\\n\\nSEE THE SECTION TITLED “STOCK REPURCHASE PROGRAM” DISCUSSED BELOW.\\n\\nWE EXPECT TO CONTINUE OUR INVESTING ACTIVITIES, INCLUDING SHORT-TERM AND LONG-TERM INVESTMENTS, VENTURE CAPITAL, FACILITIES EXPANSION AND PURCHASES OF COMPUTER SYSTEMS FOR RESEARCH AND DEVELOPMENT, SALES AND MARKETING, PRODUCT SUPPORT AND ADMINISTRATIVE STAFF. FURTHERMORE, CASH RESERVES MAY BE USED TO REPURCHASE STOCK UNDER OUR STOCK REPURCHASE PROGRAM AND TO STRATEGICALLY ACQUIRE COMPANIES, PRODUCTS OR TECHNOLOGIES THAT ARE COMPLEMENTARY TO OUR BUSINESS.\\n\\nRESTRUCTURING\\n\\nDURING THE PAST SEVERAL YEARS, WE HAVE INITIATED VARIOUS RESTRUCTURING PLANS. WE CONSIDER OUR RESTRUCTURING PLANS TO BE SUBSTANTIALLY COMPLETE.\\n\\nAS OF\\n\\nNOVEMBER 27, 2015\\n\\n, WE HAVE ACCRUED TOTAL RESTRUCTURING CHARGES OF\\n\\n$4.7 MILLION\\n\\n, SUBSTANTIALLY ALL OF WHICH RELATE TO THE COST OF CLOSING REDUNDANT FACILITIES AND IS EXPECTED TO BE PAID UNDER CONTRACT THROUGH FISCAL 2021 FOR WHICH APPROXIMATELY\\n\\n75%\\n\\nWILL BE PAID THROUGH FISCAL 2017. DURING FISCAL 2015, WE MADE PAYMENTS RELATED TO OUR RESTRUCTURING PLANS TOTALING\\n\\n$18.2 MILLION\\n\\nWHICH CONSISTED OF\\n\\n$16.6 MILLION\\n\\nIN PAYMENTS ASSOCIATED WITH TERMINATION BENEFITS AND CONTRACT TERMINATIONS AND THE REMAINING PAYMENTS RELATED TO THE CLOSING OF REDUNDANT FACILITIES.\\n\\nAS OF\\n\\nNOVEMBER 28, 2014\\n\\n, WE HAD ACCRUED TOTAL RESTRUCTURING CHARGES OF\\n\\n$22.3 MILLION\\n\\nOF WHICH APPROXIMATELY\\n\\n$15.0 MILLION\\n\\nRELATED TO TERMINATION BENEFITS AND CONTRACT TERMINATIONS. THE REMAINING ACCRUED RESTRUCTURING CHARGES OF\\n\\n$7.3 MILLION\\n\\nRELATED TO THE COST OF CLOSING REDUNDANT FACILITIES. DURING FISCAL 2014, WE MADE PAYMENTS RELATED TO OUR RESTRUCTURING PLANS TOTALING\\n\\n$11.0\\n\\n52\\n\\nTABLE OF CONTENTS\\n\\nMILLION\\n\\nWHICH CONSISTED OF\\n\\n$5.7 MILLION\\n\\nAND\\n\\n$5.3 MILLION\\n\\nIN PAYMENTS RELATED TO TERMINATION BENEFITS AND CONTRACT TERMINATIONS AND THE CLOSING OF REDUNDANT FACILITIES, RESPECTIVELY.\\n\\nAS OF\\n\\nNOVEMBER 29, 2013\\n\\n, WE HAD ACCRUED TOTAL RESTRUCTURING CHARGES OF\\n\\n$13.9 MILLION\\n\\nOF WHICH APPROXIMATELY\\n\\n$11.7 MILLION\\n\\nRELATED TO THE COST OF CLOSING REDUNDANT FACILITIES. THE REMAINING ACCRUED RESTRUCTURING CHARGES OF\\n\\n$2.2 MILLION\\n\\nRELATED TO THE COST OF TERMINATION BENEFITS AND CONTRACT TERMINATIONS. DURING FISCAL 2013, WE MADE PAYMENTS RELATED TO OUR RESTRUCTURING PLANS TOTALING\\n\\n$10.3 MILLION\\n\\nWHICH PRIMARILY CONSISTED OF\\n\\n$9.0 MILLION\\n\\nIN PAYMENTS RELATED TO THE CLOSING OF REDUNDANT FACILITIES.\\n\\nWE BELIEVE THAT OUR EXISTING CASH AND CASH EQUIVALENTS, SHORT-TERM INVESTMENTS AND CASH GENERATED FROM OPERATIONS WILL BE SUFFICIENT TO MEET CASH OUTLAYS FOR THE RESTRUCTURING ACTIONS DESCRIBED ABOVE.\\n\\nSEE NOTE 10 OF OUR NOTES TO CONSOLIDATED FINANCIAL STATEMENTS FOR ADDITIONAL INFORMATION REGARDING OUR RESTRUCTURING PLANS.\\n\\nOTHER LIQUIDITY AND CAPITAL RESOURCES CONSIDERATIONS\\n\\nOUR EXISTING CASH, CASH EQUIVALENTS AND INVESTMENT BALANCES MAY FLUCTUATE DURING FISCAL 2016 DUE TO CHANGES IN OUR PLANNED CASH OUTLAY, INCLUDING CHANGES IN INCREMENTAL COSTS SUCH AS DIRECT AND INTEGRATION COSTS RELATED TO OUR ACQUISITIONS. OUR CASH AND INVESTMENTS TOTALED\\n\\n$3.99 BILLION\\n\\nAS OF\\n\\nNOVEMBER 27, 2015\\n\\n. OF THIS AMOUNT, APPROXIMATELY\\n\\n85%\\n\\nWAS HELD BY OUR FOREIGN SUBSIDIARIES AND SUBJECT TO MATERIAL REPATRIATION TAX EFFECTS. OUR INTENT IS TO PERMANENTLY REINVEST A SIGNIFICANT PORTION OF OUR EARNINGS FROM FOREIGN OPERATIONS, AND CURRENT PLANS DO NOT ANTICIPATE THAT WE WILL NEED FUNDS GENERATED FROM FOREIGN OPERATIONS TO FUND OUR DOMESTIC OPERATIONS. IN THE EVENT FUNDS FROM FOREIGN OPERATIONS ARE NEEDED TO FUND OPERATIONS IN THE UNITED STATES AND IF U.S. TAX HAS NOT ALREADY BEEN PREVIOUSLY PROVIDED, WE WOULD PROVIDE FOR AND PAY ADDITIONAL U.S. TAXES IN CONNECTION WITH REPATRIATING THESE FUNDS.\\n\\nCASH FROM OPERATIONS COULD ALSO BE AFFECTED BY VARIOUS RISKS AND UNCERTAINTIES, INCLUDING, BUT NOT LIMITED TO THE RISKS DETAILED IN PART I, ITEM 1A TITLED “RISK FACTORS”. HOWEVER, BASED ON OUR CURRENT BUSINESS PLAN AND REVENUE PROSPECTS, WE BELIEVE THAT OUR EXISTING CASH, CASH EQUIVALENTS AND INVESTMENT BALANCES, OUR ANTICIPATED CASH FLOWS FROM OPERATIONS AND OUR AVAILABLE CREDIT FACILITY WILL BE SUFFICIENT TO MEET OUR WORKING CAPITAL AND OPERATING RESOURCE EXPENDITURE REQUIREMENTS FOR THE NEXT TWELVE MONTHS.\\n\\nON MARCH 2, 2012, WE ENTERED INTO A FIVE-YEAR $1 BILLION SENIOR UNSECURED REVOLVING CREDIT AGREEMENT (THE “CREDIT AGREEMENT”), PROVIDING FOR LOANS TO US AND CERTAIN OF OUR SUBSIDIARIES. ON MARCH 1, 2013, WE EXERCISED OUR OPTION UNDER THE CREDIT AGREEMENT TO EXTEND THE MATURITY DATE OF THE CREDIT AGREEMENT BY ONE YEAR TO MARCH 2, 2018. ON JULY 27, 2015, WE ENTERED INTO AN AMENDMENT TO FURTHER EXTEND THE MATURITY DATE OF THE CREDIT AGREEMENT TO JULY 27, 2020 AND REALLOCATED THE FACILITY AMONG THE SYNDICATE OF LENDERS THAT ARE PARTIES TO THE CREDIT AGREEMENT. AS OF\\n\\nNOVEMBER 27, 2015\\n\\n, THERE WERE NO OUTSTANDING BORROWINGS UNDER THIS CREDIT AGREEMENT AND THE ENTIRE $1 BILLION CREDIT LINE REMAINS AVAILABLE FOR BORROWING.\\n\\nAS OF\\n\\nNOVEMBER 27, 2015\\n\\n, THE AMOUNT OUTSTANDING UNDER OUR SENIOR NOTES WAS\\n\\n$1.9 BILLION\\n\\n, CONSISTING OF\\n\\n$900 MILLION\\n\\nOF 4.75% SENIOR NOTES DUE FEBRUARY 1, 2020 (THE “2020 NOTES”) AND\\n\\n$1 BILLION\\n\\nOF 3.25% SENIOR NOTES DUE FEBRUARY 1, 2025 (TOGETHER WITH THE 2020 NOTES, THE “NOTES”).\\n\\nOUR SHORT-TERM INVESTMENT PORTFOLIO IS PRIMARILY INVESTED IN CORPORATE BONDS AND COMMERCIAL PAPER, U.S. AGENCY SECURITIES AND U.S. TREASURY SECURITIES, FOREIGN GOVERNMENT SECURITIES, MUNICIPAL SECURITIES AND ASSET-BACKED SECURITIES.WE USE PROFESSIONAL INVESTMENT MANAGEMENT FIRMS TO MANAGE A LARGE PORTION OF OUR INVESTED CASH. EXTERNAL INVESTMENT FIRMS MANAGED, ON AVERAGE,\\n\\n57%\\n\\nOF OUR CONSOLIDATED INVESTED BALANCES DURING FISCAL\\n\\n2015.\\n\\nSTOCK REPURCHASE PROGRAM\\n\\nTO FACILITATE OUR STOCK REPURCHASE PROGRAM, DESIGNED TO RETURN VALUE TO OUR STOCKHOLDERS AND MINIMIZE DILUTION FROM STOCK ISSUANCES, WE MAY REPURCHASE SHARES IN THE OPEN MARKET OR ENTER INTO STRUCTURED REPURCHASE AGREEMENTS WITH THIRD PARTIES. IN THE FIRST QUARTER OF FISCAL 2015, THE BOARD OF DIRECTORS APPROVED A NEW STOCK REPURCHASE PROGRAM GRANTING THE COMPANY AUTHORITY TO REPURCHASE UP TO\\n\\n$2 BILLION\\n\\nIN COMMON STOCK THROUGH THE END OF FISCAL 2017.\\n\\nDURING FISCAL\\n\\n2015\\n\\n,\\n\\n2014\\n\\nAND\\n\\n2013\\n\\n, WE ENTERED INTO SEVERAL STRUCTURED STOCK REPURCHASE AGREEMENTS WITH LARGE FINANCIAL INSTITUTIONS, WHEREUPON WE PROVIDED THEM WITH PREPAYMENTS TOTALING\\n\\n$625 MILLION\\n\\n,\\n\\n$600 MILLION\\n\\nAND\\n\\n$1.1 BILLION\\n\\n, RESPECTIVELY. OF THE $625 MILLION\\n\\nIN PREPAYMENTS MADE DURING FISCAL\\n\\n2015\\n\\n,\\n\\n$425 MILLION\\n\\nWERE UNDER THE NEW\\n\\n$2 BILLION\\n\\nSTOCK REPURCHASE PROGRAM AND THE REMAINING\\n\\n$200 MILLION\\n\\nWERE UNDER THE PREVIOUS\\n\\n$2 BILLION\\n\\nAUTHORITY. THE\\n\\n$600 MILLION\\n\\nAND\\n\\n$1.1 BILLION\\n\\nIN PREPAYMENTS MADE DURING FISCAL\\n\\n2014\\n\\nAND\\n\\n2013\\n\\nWERE UNDER THE PREVIOUS\\n\\n$2 BILLION\\n\\nSTOCK REPURCHASE AUTHORITY. WE ENTER INTO THESE AGREEMENTS IN ORDER TO TAKE ADVANTAGE OF REPURCHASING SHARES AT A GUARANTEED DISCOUNT TO THE VOLUME WEIGHTED AVERAGE PRICE (“VWAP”) OF OUR COMMON STOCK OVER A SPECIFIED PERIOD OF TIME. WE ONLY ENTER INTO SUCH TRANSACTIONS WHEN THE DISCOUNT THAT WE RECEIVE IS HIGHER THAN OUR ESTIMATE OF THE FOREGONE RETURN ON OUR CASH PREPAYMENTS TO THE FINANCIAL INSTITUTIONS. THERE WERE NO EXPLICIT COMMISSIONS\\n\\n53\\n\\nTABLE OF CONTENTS\\n\\nOR FEES ON THESE STRUCTURED REPURCHASES. UNDER THE TERMS OF THE AGREEMENTS, THERE IS NO REQUIREMENT FOR THE FINANCIAL INSTITUTIONS TO RETURN ANY PORTION OF THE PREPAYMENT TO US.\\n\\nTHE FINANCIAL INSTITUTIONS AGREE TO DELIVER SHARES TO US AT MONTHLY INTERVALS DURING THE CONTRACT TERM. THE PARAMETERS USED TO CALCULATE THE NUMBER OF SHARES DELIVERABLE ARE: THE TOTAL NOTIONAL AMOUNT OF THE CONTRACT, THE NUMBER OF TRADING DAYS IN THE CONTRACT, THE NUMBER OF TRADING DAYS IN THE INTERVAL AND THE AVERAGE VWAP OF OUR STOCK DURING THE INTERVAL LESS THE AGREED UPON DISCOUNT. DURING FISCAL\\n\\n2015\\n\\n, WE REPURCHASED APPROXIMATELY\\n\\n8.1 MILLION\\n\\nSHARES AT AN AVERAGE PRICE OF\\n\\n$77.38\\n\\nTHROUGH STRUCTURED REPURCHASE AGREEMENTS ENTERED INTO DURING FISCAL\\n\\n2015\\n\\nAND FISCAL\\n\\n2014\\n\\n. DURING FISCAL\\n\\n2014\\n\\n, WE REPURCHASED APPROXIMATELY\\n\\n10.9 MILLION\\n\\nSHARES AT AN AVERAGE PRICE OF\\n\\n$63.48\\n\\nTHROUGH STRUCTURED REPURCHASE AGREEMENTS ENTERED INTO DURING FISCAL\\n\\n2014\\n\\nAND FISCAL\\n\\n2013\\n\\n. DURING FISCAL\\n\\n2013\\n\\n, WE REPURCHASED APPROXIMATELY\\n\\n21.6 MILLION\\n\\nSHARES AT AN AVERAGE PRICE PER SHARE OF\\n\\n$46.47\\n\\nTHROUGH STRUCTURED REPURCHASE AGREEMENTS ENTERED INTO DURING FISCAL\\n\\n2013\\n\\nAND FISCAL 2012.\\n\\nFOR FISCAL\\n\\n2015\\n\\n,\\n\\n2014\\n\\nAND\\n\\n2013\\n\\n, THE PREPAYMENTS WERE CLASSIFIED AS TREASURY STOCK ON OUR CONSOLIDATED BALANCE SHEETS AT THE PAYMENT DATE, THOUGH ONLY SHARES PHYSICALLY DELIVERED TO US BY\\n\\nNOVEMBER 27, 2015\\n\\n,\\n\\nNOVEMBER 28, 2014\\n\\nAND\\n\\nNOVEMBER 29, 2013\\n\\nWERE EXCLUDED FROM THE COMPUTATION OF EARNINGS PER SHARE. AS OF\\n\\nNOVEMBER 27, 2015\\n\\n,\\n\\n$38.2 MILLION\\n\\nOF PREPAYMENTS REMAINED UNDER THE AGREEMENT.\\n\\nSEE NOTE 13 OF OUR NOTES TO CONSOLIDATED FINANCIAL STATEMENTS FOR FURTHER DISCUSSION OF OUR STOCK REPURCHASE PROGRAMS.\\n\\nSUBSEQUENT TO\\n\\nNOVEMBER 27, 2015\\n\\n, AS PART OF OUR\\n\\n$2 BILLION\\n\\nSTOCK REPURCHASE PROGRAM, WE ENTERED INTO A STRUCTURED STOCK REPURCHASE AGREEMENT WITH A LARGE FINANCIAL INSTITUTION WHEREUPON WE PROVIDED THEM WITH A PREPAYMENT OF\\n\\n$150 MILLION\\n\\n. THIS AMOUNT WILL BE CLASSIFIED AS TREASURY STOCK ON OUR CONSOLIDATED BALANCE SHEETS. UPON COMPLETION OF THE\\n\\n$150 MILLION\\n\\nSTOCK  REPURCHASE AGREEMENT,\\n\\n$1.43 BILLION\\n\\nREMAINS UNDER OUR CURRENT AUTHORITY.\\n\\nSEE ITEM 5, MARKET FOR REGISTRANT’S COMMON EQUITY, RELATED STOCKHOLDER MATTERS AND ISSUER PURCHASES OF EQUITY SECURITIES FOR SHARE REPURCHASES DURING THE QUARTER ENDED NOVEMBER 27, 2015.\\n\\nSUMMARY OF STOCK REPURCHASES FOR FISCAL\\n\\n2015\\n\\n,\\n\\n2014\\n\\nAND\\n\\n2013\\n\\n(IN THOUSANDS, EXCEPT AVERAGE AMOUNTS)\\n\\nBOARD APPROVAL\\n\\nDATE\\n\\nREPURCHASES\\n\\nUNDER THE PLAN\\n\\n2015\\n\\n2014\\n\\n2013\\n\\nSHARES\\n\\nAVERAGE\\n\\nSHARES\\n\\nAVERAGE\\n\\nSHARES\\n\\nAVERAGE\\n\\nAPRIL 2012\\n\\nSTRUCTURED REPURCHASES\\n\\n(1)\\n\\n3,255\\n\\n$73.83\\n\\n10,852\\n\\n$63.48\\n\\n21,603\\n\\n$46.47\\n\\nJANUARY 2015\\n\\nSTRUCTURED REPURCHASES\\n\\n(1)\\n\\n4,849\\n\\n$79.76\\n\\n—\\n\\n$—\\n\\n—\\n\\n$—\\n\\nTOTAL SHARES\\n\\n8,104\\n\\n$77.38\\n\\n10,852\\n\\n$63.48\\n\\n21,603\\n\\n$46.47\\n\\nTOTAL COST\\n\\n$627,082\\n\\n$688,902\\n\\n$1,003,794\\n\\n_________________________________________\\n\\n(1)\\n\\nSTOCK REPURCHASE AGREEMENTS EXECUTED WITH LARGE FINANCIAL INSTITUTIONS.\\n\\nSEE STOCK REPURCHASE PROGRAM ABOVE.\\n\\nOFF-BALANCE SHEET ARRANGEMENTS AND AGGREGATE CONTRACTUAL OBLIGATIONS\\n\\nOUR PRINCIPAL COMMITMENTS AS OF\\n\\nNOVEMBER 27, 2015\\n\\nCONSIST OF OBLIGATIONS UNDER OPERATING LEASES, ROYALTY AGREEMENTS AND VARIOUS SERVICE AGREEMENTS.\\n\\nSEE NOTE 15 OF OUR NOTES TO CONSOLIDATED FINANCIAL STATEMENTS FOR ADDITIONAL INFORMATION REGARDING OUR CONTRACTUAL COMMITMENTS.\\n\\nCONTRACTUAL OBLIGATIONS\\n\\nTHE FOLLOWING TABLE SUMMARIZES OUR CONTRACTUAL OBLIGATIONS AS OF\\n\\nNOVEMBER 27, 2015\\n\\n(IN MILLIONS).\\n\\nPAYMENT DUE BY PERIOD\\n\\nTOTAL\\n\\nLESS THAN\\n\\n1 YEAR\\n\\n1-3 YEARS\\n\\n3-5 YEARS\\n\\nMORE THAN\\n\\n5 YEARS\\n\\nNOTES\\n\\n$2,401.1\\n\\n$75.3\\n\\n$150.5\\n\\n$1,029.1\\n\\n$1,146.2\\n\\nOPERATING LEASE OBLIGATIONS\\n\\n185.2\\n\\n39.5\\n\\n57.1\\n\\n43.2\\n\\n45.4\\n\\nPURCHASE OBLIGATIONS\\n\\n419.8\\n\\n341.3\\n\\n74.6\\n\\n3.9\\n\\n—\\n\\nTOTAL\\n\\n$3,006.1\\n\\n$456.1\\n\\n$282.2\\n\\n$1,076.2\\n\\n$1,191.6\\n\\nSENIOR NOTES\\n\\nIN JANUARY 2015, WE ISSUED THE 2025 NOTES AND SETTLED THE 2015 NOTES. AS OF\\n\\nNOVEMBER 27, 2015\\n\\n, OUR OUTSTANDING NOTES PAYABLE CONSISTS OF THE 2020 NOTES AND 2025 NOTES WITH A TOTAL CARRYING VALUE OF\\n\\n$1.91 BILLION\\n\\n. AT\\n\\nNOVEMBER 27, 2015\\n\\n, OUR\\n\\n54\\n\\nTABLE OF CONTENTS\\n\\nMAXIMUM COMMITMENT FOR INTEREST PAYMENTS UNDER THE NOTES WAS\\n\\n$501.1 MILLION\\n\\nFOR THE REMAINING DURATION OF OUR NOTES. IN JUNE 2014, WE ENTERED INTO INTEREST RATE SWAPS THAT EFFECTIVELY CONVERTED THE FIXED INTEREST RATE ON OUR 2020 NOTES TO A FLOATING INTEREST RATE BASED ON THE LONDON INTERBANK OFFERED RATE (“LIBOR”) PLUS A FIXED NUMBER OF BASIS POINTS THROUGH FEBRUARY 1, 2020.\\n\\nCOVENANTS\\n\\nOUR CREDIT FACILITY AND ALMADEN TOWER LEASE CONTAIN A FINANCIAL COVENANT REQUIRING US NOT TO EXCEED A MAXIMUM LEVERAGE RATIO. AS OF\\n\\nNOVEMBER 27, 2015\\n\\n, WE WERE IN COMPLIANCE WITH ALL OF OUR COVENANTS. WE BELIEVE THESE COVENANTS WILL NOT IMPACT OUR CREDIT OR CASH IN THE COMING FISCAL YEAR OR RESTRICT OUR ABILITY TO EXECUTE OUR BUSINESS PLAN. OUR NOTES DO NOT CONTAIN ANY FINANCIAL COVENANTS.\\n\\nUNDER THE TERMS OF OUR CREDIT AGREEMENT AND LEASE AGREEMENTS, WE ARE NOT PROHIBITED FROM PAYING CASH DIVIDENDS UNLESS PAYMENT WOULD TRIGGER AN EVENT OF DEFAULT OR ONE CURRENTLY EXISTS. WE DO NOT ANTICIPATE PAYING ANY CASH DIVIDENDS IN THE FORESEEABLE FUTURE.\\n\\nACCOUNTING FOR UNCERTAINTY IN INCOME TAXES\\n\\nTHE GROSS LIABILITY FOR UNRECOGNIZED TAX BENEFITS AT\\n\\nNOVEMBER 27, 2015\\n\\nWAS\\n\\n$258.7 MILLION\\n\\n, EXCLUSIVE OF INTEREST AND PENALTIES.\\n\\nTHE TIMING OF THE RESOLUTION OF INCOME TAX EXAMINATIONS IS HIGHLY UNCERTAIN AS ARE THE AMOUNTS AND TIMING OF TAX PAYMENTS THAT ARE PART OF ANY AUDIT SETTLEMENT PROCESS. THESE EVENTS COULD CAUSE LARGE FLUCTUATIONS IN THE BALANCE SHEET CLASSIFICATION OF CURRENT AND NON-CURRENT ASSETS AND LIABILITIES. WE BELIEVE THAT WITHIN THE NEXT 12 MONTHS, IT IS REASONABLY POSSIBLE THAT EITHER CERTAIN AUDITS WILL CONCLUDE OR STATUTES OF LIMITATIONS ON CERTAIN INCOME TAX EXAMINATION PERIODS WILL EXPIRE, OR BOTH. GIVEN THE UNCERTAINTIES DESCRIBED ABOVE, WE CAN ONLY DETERMINE A RANGE OF ESTIMATED POTENTIAL DECREASES IN UNDERLYING UNRECOGNIZED TAX BENEFITS RANGING FROM\\n\\n$0\\n\\nTO APPROXIMATELY\\n\\n$10 MILLION.\\n\\nROYALTIES\\n\\nWE HAVE CERTAIN ROYALTY COMMITMENTS ASSOCIATED WITH THE SHIPMENT AND LICENSING OF CERTAIN PRODUCTS. ROYALTY EXPENSE IS GENERALLY BASED ON A DOLLAR AMOUNT PER UNIT SHIPPED OR A PERCENTAGE OF THE UNDERLYING REVENUE.\\n\\nINDEMNIFICATIONS\\n\\nIN THE NORMAL COURSE OF BUSINESS, WE PROVIDE INDEMNIFICATIONS OF VARYING SCOPE TO CUSTOMERS AGAINST CLAIMS OF INTELLECTUAL PROPERTY INFRINGEMENT MADE BY THIRD PARTIES ARISING FROM THE USE OF OUR PRODUCTS AND FROM TIME TO TIME, WE ARE SUBJECT TO CLAIMS BY OUR CUSTOMERS UNDER THESE INDEMNIFICATION PROVISIONS. HISTORICALLY, COSTS RELATED TO THESE INDEMNIFICATION PROVISIONS HAVE NOT BEEN SIGNIFICANT AND WE ARE UNABLE TO ESTIMATE THE MAXIMUM POTENTIAL IMPACT OF THESE INDEMNIFICATION PROVISIONS ON OUR FUTURE RESULTS OF OPERATIONS.\\n\\nTO THE EXTENT PERMITTED UNDER DELAWARE LAW, WE HAVE AGREEMENTS WHEREBY WE INDEMNIFY OUR DIRECTORS AND OFFICERS FOR CERTAIN EVENTS OR OCCURRENCES WHILE THE DIRECTOR OR OFFICER IS OR WAS SERVING AT OUR REQUEST IN SUCH CAPACITY. THE INDEMNIFICATION PERIOD COVERS ALL PERTINENT EVENTS AND OCCURRENCES DURING THE DIRECTOR’S OR OFFICER’S LIFETIME. THE MAXIMUM POTENTIAL AMOUNT OF FUTURE PAYMENTS WE COULD BE REQUIRED TO MAKE UNDER THESE INDEMNIFICATION AGREEMENTS IS UNLIMITED; HOWEVER, WE HAVE DIRECTOR AND OFFICER INSURANCE COVERAGE THAT LIMITS OUR EXPOSURE AND ENABLES US TO RECOVER A PORTION OF ANY FUTURE AMOUNTS PAID.\"}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, take only the first filing for each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = []\n",
    "seen = set()\n",
    "for item in data:\n",
    "    if item['ticker'] in seen:\n",
    "        continue\n",
    "    else:\n",
    "        seen.add(item['ticker'])\n",
    "        clean.append(item)\n",
    "data = clean\n",
    "del clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now load the price data for 2015-2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = pd.read_csv(\n",
    "    '/Users/mac/Desktop/MFin Materials/15.S08/data/sp500_prices.csv', \n",
    "    index_col=0, \n",
    "    parse_dates=True\n",
    ").loc['2015-01-01':'2018-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MMM</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ATVI</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>AMD</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AES</th>\n",
       "      <th>...</th>\n",
       "      <th>WLTW</th>\n",
       "      <th>WYNN</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>152.857296</td>\n",
       "      <td>41.911850</td>\n",
       "      <td>59.166809</td>\n",
       "      <td>37.31</td>\n",
       "      <td>83.567918</td>\n",
       "      <td>19.647773</td>\n",
       "      <td>72.340</td>\n",
       "      <td>2.69</td>\n",
       "      <td>157.835250</td>\n",
       "      <td>12.207402</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137.601094</td>\n",
       "      <td>32.876454</td>\n",
       "      <td>51.006224</td>\n",
       "      <td>40.568729</td>\n",
       "      <td>36.487373</td>\n",
       "      <td>48.740797</td>\n",
       "      <td>110.052964</td>\n",
       "      <td>27.623683</td>\n",
       "      <td>42.403000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>149.409947</td>\n",
       "      <td>41.921185</td>\n",
       "      <td>58.053335</td>\n",
       "      <td>37.07</td>\n",
       "      <td>82.156933</td>\n",
       "      <td>19.374481</td>\n",
       "      <td>71.980</td>\n",
       "      <td>2.66</td>\n",
       "      <td>155.754803</td>\n",
       "      <td>11.859892</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.259187</td>\n",
       "      <td>32.503272</td>\n",
       "      <td>49.893361</td>\n",
       "      <td>39.819696</td>\n",
       "      <td>34.216494</td>\n",
       "      <td>47.750487</td>\n",
       "      <td>114.158329</td>\n",
       "      <td>26.588649</td>\n",
       "      <td>42.148444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>147.816713</td>\n",
       "      <td>41.445126</td>\n",
       "      <td>57.765986</td>\n",
       "      <td>36.13</td>\n",
       "      <td>81.564320</td>\n",
       "      <td>19.013344</td>\n",
       "      <td>70.530</td>\n",
       "      <td>2.63</td>\n",
       "      <td>155.645306</td>\n",
       "      <td>11.592576</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132.373957</td>\n",
       "      <td>32.676210</td>\n",
       "      <td>49.225643</td>\n",
       "      <td>39.247454</td>\n",
       "      <td>34.015277</td>\n",
       "      <td>47.164385</td>\n",
       "      <td>113.190639</td>\n",
       "      <td>25.573145</td>\n",
       "      <td>41.737240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>148.888186</td>\n",
       "      <td>41.781167</td>\n",
       "      <td>60.100691</td>\n",
       "      <td>37.28</td>\n",
       "      <td>83.276314</td>\n",
       "      <td>18.598525</td>\n",
       "      <td>71.110</td>\n",
       "      <td>2.58</td>\n",
       "      <td>158.989948</td>\n",
       "      <td>11.610397</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136.261523</td>\n",
       "      <td>32.958372</td>\n",
       "      <td>49.856265</td>\n",
       "      <td>39.261411</td>\n",
       "      <td>34.283567</td>\n",
       "      <td>48.727324</td>\n",
       "      <td>116.005740</td>\n",
       "      <td>25.812374</td>\n",
       "      <td>42.598811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>152.456658</td>\n",
       "      <td>42.639940</td>\n",
       "      <td>60.729266</td>\n",
       "      <td>38.96</td>\n",
       "      <td>84.546201</td>\n",
       "      <td>18.788854</td>\n",
       "      <td>72.915</td>\n",
       "      <td>2.61</td>\n",
       "      <td>160.383549</td>\n",
       "      <td>11.788608</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137.900858</td>\n",
       "      <td>33.340656</td>\n",
       "      <td>51.228796</td>\n",
       "      <td>40.136058</td>\n",
       "      <td>34.542275</td>\n",
       "      <td>49.576161</td>\n",
       "      <td>117.237350</td>\n",
       "      <td>26.178542</td>\n",
       "      <td>43.254780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 494 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   MMM        ABT       ABBV   ABMD        ACN       ATVI  \\\n",
       "Date                                                                        \n",
       "2015-01-02  152.857296  41.911850  59.166809  37.31  83.567918  19.647773   \n",
       "2015-01-05  149.409947  41.921185  58.053335  37.07  82.156933  19.374481   \n",
       "2015-01-06  147.816713  41.445126  57.765986  36.13  81.564320  19.013344   \n",
       "2015-01-07  148.888186  41.781167  60.100691  37.28  83.276314  18.598525   \n",
       "2015-01-08  152.456658  42.639940  60.729266  38.96  84.546201  18.788854   \n",
       "\n",
       "              ADBE   AMD         AAP        AES  ...  WLTW        WYNN  \\\n",
       "Date                                             ...                     \n",
       "2015-01-02  72.340  2.69  157.835250  12.207402  ...   NaN  137.601094   \n",
       "2015-01-05  71.980  2.66  155.754803  11.859892  ...   NaN  135.259187   \n",
       "2015-01-06  70.530  2.63  155.645306  11.592576  ...   NaN  132.373957   \n",
       "2015-01-07  71.110  2.58  158.989948  11.610397  ...   NaN  136.261523   \n",
       "2015-01-08  72.915  2.61  160.383549  11.788608  ...   NaN  137.900858   \n",
       "\n",
       "                  XEL        XRX       XLNX        XYL        YUM         ZBH  \\\n",
       "Date                                                                            \n",
       "2015-01-02  32.876454  51.006224  40.568729  36.487373  48.740797  110.052964   \n",
       "2015-01-05  32.503272  49.893361  39.819696  34.216494  47.750487  114.158329   \n",
       "2015-01-06  32.676210  49.225643  39.247454  34.015277  47.164385  113.190639   \n",
       "2015-01-07  32.958372  49.856265  39.261411  34.283567  48.727324  116.005740   \n",
       "2015-01-08  33.340656  51.228796  40.136058  34.542275  49.576161  117.237350   \n",
       "\n",
       "                 ZION        ZTS  \n",
       "Date                              \n",
       "2015-01-02  27.623683  42.403000  \n",
       "2015-01-05  26.588649  42.148444  \n",
       "2015-01-06  25.573145  41.737240  \n",
       "2015-01-07  25.812374  42.598811  \n",
       "2015-01-08  26.178542  43.254780  \n",
       "\n",
       "[5 rows x 494 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tickers = [item['ticker'] for item in data]\n",
    "assert len(data_tickers) == len(set(data_tickers)), 'non-unique tickers, this will not work'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: clean the text\n",
    "### Much of NLP boils down to doing reasonable processing on text.\n",
    "### First, we'll try out very minimial processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_mda_simple(mda):\n",
    "    return mda.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add import here\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=1, max_df=1.0)\n",
    "text_list = [clean_mda_simple(item['mda']) for item in data]\n",
    "word_vecs = vectorizer.fit_transform(text_list)\n",
    "\n",
    "vocab = {token: n for n, token in enumerate(pd.Series(vectorizer.vocabulary_).sort_values().index)}\n",
    "inv_vocab = {v: k for k, v in vocab.items()}\n",
    "# word_vecs = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Pairwise Word similarity\n",
    "### Calculate the pariwise cosine similarity between word vectors\n",
    "### Make the cosine similarities into a dataframe indexed/columned on ticker symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADBE</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AMD</th>\n",
       "      <th>AES</th>\n",
       "      <th>AMG</th>\n",
       "      <th>AFL</th>\n",
       "      <th>AIV</th>\n",
       "      <th>AKAM</th>\n",
       "      <th>SO</th>\n",
       "      <th>ALK</th>\n",
       "      <th>...</th>\n",
       "      <th>JCI</th>\n",
       "      <th>MU</th>\n",
       "      <th>RJF</th>\n",
       "      <th>ROK</th>\n",
       "      <th>SWKS</th>\n",
       "      <th>SBUX</th>\n",
       "      <th>SNPS</th>\n",
       "      <th>TSN</th>\n",
       "      <th>TDG</th>\n",
       "      <th>VIAB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADBE</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.919373</td>\n",
       "      <td>0.918374</td>\n",
       "      <td>0.867142</td>\n",
       "      <td>0.867563</td>\n",
       "      <td>0.880981</td>\n",
       "      <td>0.877659</td>\n",
       "      <td>0.938738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.893183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832302</td>\n",
       "      <td>0.905662</td>\n",
       "      <td>0.875531</td>\n",
       "      <td>0.887068</td>\n",
       "      <td>0.936977</td>\n",
       "      <td>0.873493</td>\n",
       "      <td>0.950022</td>\n",
       "      <td>0.920298</td>\n",
       "      <td>0.852041</td>\n",
       "      <td>0.884839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAP</th>\n",
       "      <td>0.919373</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946086</td>\n",
       "      <td>0.905947</td>\n",
       "      <td>0.895632</td>\n",
       "      <td>0.916336</td>\n",
       "      <td>0.912843</td>\n",
       "      <td>0.943285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.911751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.871063</td>\n",
       "      <td>0.943673</td>\n",
       "      <td>0.913981</td>\n",
       "      <td>0.923592</td>\n",
       "      <td>0.921975</td>\n",
       "      <td>0.904917</td>\n",
       "      <td>0.926982</td>\n",
       "      <td>0.942927</td>\n",
       "      <td>0.898032</td>\n",
       "      <td>0.922768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMD</th>\n",
       "      <td>0.918374</td>\n",
       "      <td>0.946086</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.922994</td>\n",
       "      <td>0.908136</td>\n",
       "      <td>0.907567</td>\n",
       "      <td>0.906314</td>\n",
       "      <td>0.929189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.927133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882126</td>\n",
       "      <td>0.932985</td>\n",
       "      <td>0.904359</td>\n",
       "      <td>0.898625</td>\n",
       "      <td>0.926256</td>\n",
       "      <td>0.885955</td>\n",
       "      <td>0.924474</td>\n",
       "      <td>0.943245</td>\n",
       "      <td>0.887473</td>\n",
       "      <td>0.916984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AES</th>\n",
       "      <td>0.867142</td>\n",
       "      <td>0.905947</td>\n",
       "      <td>0.922994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.876463</td>\n",
       "      <td>0.908254</td>\n",
       "      <td>0.901906</td>\n",
       "      <td>0.908670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.908768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.915712</td>\n",
       "      <td>0.908622</td>\n",
       "      <td>0.913063</td>\n",
       "      <td>0.878228</td>\n",
       "      <td>0.888201</td>\n",
       "      <td>0.870428</td>\n",
       "      <td>0.888656</td>\n",
       "      <td>0.910719</td>\n",
       "      <td>0.895787</td>\n",
       "      <td>0.898210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMG</th>\n",
       "      <td>0.867563</td>\n",
       "      <td>0.895632</td>\n",
       "      <td>0.908136</td>\n",
       "      <td>0.876463</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871050</td>\n",
       "      <td>0.869783</td>\n",
       "      <td>0.893722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.898257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808114</td>\n",
       "      <td>0.872916</td>\n",
       "      <td>0.898773</td>\n",
       "      <td>0.865362</td>\n",
       "      <td>0.867588</td>\n",
       "      <td>0.840331</td>\n",
       "      <td>0.882624</td>\n",
       "      <td>0.896644</td>\n",
       "      <td>0.814938</td>\n",
       "      <td>0.864113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SBUX</th>\n",
       "      <td>0.873493</td>\n",
       "      <td>0.904917</td>\n",
       "      <td>0.885955</td>\n",
       "      <td>0.870428</td>\n",
       "      <td>0.840331</td>\n",
       "      <td>0.860348</td>\n",
       "      <td>0.852562</td>\n",
       "      <td>0.870773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.862720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844537</td>\n",
       "      <td>0.883364</td>\n",
       "      <td>0.880400</td>\n",
       "      <td>0.872356</td>\n",
       "      <td>0.887220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.879929</td>\n",
       "      <td>0.901304</td>\n",
       "      <td>0.860447</td>\n",
       "      <td>0.893360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNPS</th>\n",
       "      <td>0.950022</td>\n",
       "      <td>0.926982</td>\n",
       "      <td>0.924474</td>\n",
       "      <td>0.888656</td>\n",
       "      <td>0.882624</td>\n",
       "      <td>0.893065</td>\n",
       "      <td>0.879934</td>\n",
       "      <td>0.945852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.906523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.861360</td>\n",
       "      <td>0.922417</td>\n",
       "      <td>0.900675</td>\n",
       "      <td>0.897768</td>\n",
       "      <td>0.938598</td>\n",
       "      <td>0.879929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929717</td>\n",
       "      <td>0.876526</td>\n",
       "      <td>0.899325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSN</th>\n",
       "      <td>0.920298</td>\n",
       "      <td>0.942927</td>\n",
       "      <td>0.943245</td>\n",
       "      <td>0.910719</td>\n",
       "      <td>0.896644</td>\n",
       "      <td>0.898519</td>\n",
       "      <td>0.888238</td>\n",
       "      <td>0.918187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.920277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889721</td>\n",
       "      <td>0.937255</td>\n",
       "      <td>0.911569</td>\n",
       "      <td>0.925717</td>\n",
       "      <td>0.937084</td>\n",
       "      <td>0.901304</td>\n",
       "      <td>0.929717</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906842</td>\n",
       "      <td>0.908548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TDG</th>\n",
       "      <td>0.852041</td>\n",
       "      <td>0.898032</td>\n",
       "      <td>0.887473</td>\n",
       "      <td>0.895787</td>\n",
       "      <td>0.814938</td>\n",
       "      <td>0.879256</td>\n",
       "      <td>0.851923</td>\n",
       "      <td>0.871382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.850916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.938989</td>\n",
       "      <td>0.888554</td>\n",
       "      <td>0.923241</td>\n",
       "      <td>0.872271</td>\n",
       "      <td>0.881057</td>\n",
       "      <td>0.860447</td>\n",
       "      <td>0.876526</td>\n",
       "      <td>0.906842</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.890136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIAB</th>\n",
       "      <td>0.884839</td>\n",
       "      <td>0.922768</td>\n",
       "      <td>0.916984</td>\n",
       "      <td>0.898210</td>\n",
       "      <td>0.864113</td>\n",
       "      <td>0.889369</td>\n",
       "      <td>0.888760</td>\n",
       "      <td>0.910098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.887351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882486</td>\n",
       "      <td>0.915056</td>\n",
       "      <td>0.908057</td>\n",
       "      <td>0.898107</td>\n",
       "      <td>0.911607</td>\n",
       "      <td>0.893360</td>\n",
       "      <td>0.899325</td>\n",
       "      <td>0.908548</td>\n",
       "      <td>0.890136</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>323 rows × 323 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ADBE       AAP       AMD       AES       AMG       AFL       AIV  \\\n",
       "ADBE  1.000000  0.919373  0.918374  0.867142  0.867563  0.880981  0.877659   \n",
       "AAP   0.919373  1.000000  0.946086  0.905947  0.895632  0.916336  0.912843   \n",
       "AMD   0.918374  0.946086  1.000000  0.922994  0.908136  0.907567  0.906314   \n",
       "AES   0.867142  0.905947  0.922994  1.000000  0.876463  0.908254  0.901906   \n",
       "AMG   0.867563  0.895632  0.908136  0.876463  1.000000  0.871050  0.869783   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "SBUX  0.873493  0.904917  0.885955  0.870428  0.840331  0.860348  0.852562   \n",
       "SNPS  0.950022  0.926982  0.924474  0.888656  0.882624  0.893065  0.879934   \n",
       "TSN   0.920298  0.942927  0.943245  0.910719  0.896644  0.898519  0.888238   \n",
       "TDG   0.852041  0.898032  0.887473  0.895787  0.814938  0.879256  0.851923   \n",
       "VIAB  0.884839  0.922768  0.916984  0.898210  0.864113  0.889369  0.888760   \n",
       "\n",
       "          AKAM   SO       ALK  ...       JCI        MU       RJF       ROK  \\\n",
       "ADBE  0.938738  0.0  0.893183  ...  0.832302  0.905662  0.875531  0.887068   \n",
       "AAP   0.943285  0.0  0.911751  ...  0.871063  0.943673  0.913981  0.923592   \n",
       "AMD   0.929189  0.0  0.927133  ...  0.882126  0.932985  0.904359  0.898625   \n",
       "AES   0.908670  0.0  0.908768  ...  0.915712  0.908622  0.913063  0.878228   \n",
       "AMG   0.893722  0.0  0.898257  ...  0.808114  0.872916  0.898773  0.865362   \n",
       "...        ...  ...       ...  ...       ...       ...       ...       ...   \n",
       "SBUX  0.870773  0.0  0.862720  ...  0.844537  0.883364  0.880400  0.872356   \n",
       "SNPS  0.945852  0.0  0.906523  ...  0.861360  0.922417  0.900675  0.897768   \n",
       "TSN   0.918187  0.0  0.920277  ...  0.889721  0.937255  0.911569  0.925717   \n",
       "TDG   0.871382  0.0  0.850916  ...  0.938989  0.888554  0.923241  0.872271   \n",
       "VIAB  0.910098  0.0  0.887351  ...  0.882486  0.915056  0.908057  0.898107   \n",
       "\n",
       "          SWKS      SBUX      SNPS       TSN       TDG      VIAB  \n",
       "ADBE  0.936977  0.873493  0.950022  0.920298  0.852041  0.884839  \n",
       "AAP   0.921975  0.904917  0.926982  0.942927  0.898032  0.922768  \n",
       "AMD   0.926256  0.885955  0.924474  0.943245  0.887473  0.916984  \n",
       "AES   0.888201  0.870428  0.888656  0.910719  0.895787  0.898210  \n",
       "AMG   0.867588  0.840331  0.882624  0.896644  0.814938  0.864113  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "SBUX  0.887220  1.000000  0.879929  0.901304  0.860447  0.893360  \n",
       "SNPS  0.938598  0.879929  1.000000  0.929717  0.876526  0.899325  \n",
       "TSN   0.937084  0.901304  0.929717  1.000000  0.906842  0.908548  \n",
       "TDG   0.881057  0.860447  0.876526  0.906842  1.000000  0.890136  \n",
       "VIAB  0.911607  0.893360  0.899325  0.908548  0.890136  1.000000  \n",
       "\n",
       "[323 rows x 323 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_sims = cosine_similarity(word_vecs)\n",
    "word_sims_df = pd.DataFrame(word_sims, index=data_tickers, columns=data_tickers)\n",
    "word_sims_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2a: Why `cosine_similarity` and not another measure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER GOES HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cosine similarity` is bounded by $[-1, 1]$, which is nice feature for machine learning. In this way, we would not need to scale our embeddings when dealing with machine learning problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Wrangle the price and word data\n",
    "### Our goal here is to have a dataframe which is indexed on PAIRS of tickers and has columns\n",
    " - ### `returns_correlation`: the correlation of returns for those two tickers from Jan 1 2016 to Jan 1 2017\n",
    " - ### `word_similarity`: the cosine similarity of the word vectors for the two companies' MD&A sections\n",
    " \n",
    "## Tips\n",
    " - ### NB: use pct_change to calculate returns in pandas\n",
    " - ### NB: use the pandas builtin corr function to calculate correlations (we don't need anything fancy)\n",
    " - ### NB: the index of the dataframe should have two columns (the tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>returns_correlation</th>\n",
       "      <th>word_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ACN</th>\n",
       "      <th>ACN</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADBE</th>\n",
       "      <td>0.555422</td>\n",
       "      <td>0.916491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMD</th>\n",
       "      <td>0.215997</td>\n",
       "      <td>0.889912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAP</th>\n",
       "      <td>0.231908</td>\n",
       "      <td>0.901718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AES</th>\n",
       "      <td>0.351658</td>\n",
       "      <td>0.871632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          returns_correlation  word_similarity\n",
       "ACN ACN              1.000000         1.000000\n",
       "    ADBE             0.555422         0.916491\n",
       "    AMD              0.215997         0.889912\n",
       "    AAP              0.231908         0.901718\n",
       "    AES              0.351658         0.871632"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one way you might do this is\n",
    "returns = prices.pct_change()\n",
    "returns = returns.loc['2016-01-01':'2017-01-01']\n",
    "corr_mat = returns.corr()\n",
    "rets_cor = corr_mat.stack().to_frame(name='returns_correlation') # calculate returns correlations\n",
    "word_cor = word_sims_df.stack().to_frame(name='word_similarity') #  calcuate the word similarities in the right shape\n",
    "\n",
    "all_data = rets_cor.join(word_cor)\n",
    "all_data = all_data.dropna()\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3a: \n",
    " - ### What is the contemperaneous correlation of these data?\n",
    " - ### Make a scatter plot of the returns correlation and word similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>returns_correlation</th>\n",
       "      <th>word_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>returns_correlation</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.05523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_similarity</th>\n",
       "      <td>0.05523</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     returns_correlation  word_similarity\n",
       "returns_correlation              1.00000          0.05523\n",
       "word_similarity                  0.05523          1.00000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This should be about 12%. That's not bad, but we can do better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8071e00c50>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_data.plot.scatter(x='returns_correlation', y='word_similarity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Try to predict the future returns correlations\n",
    "### Use OLS (`LinearRegression`) to predict `returns_correlation` from `word_similarity`. \n",
    "### What is the (contemperaneous) out of sample performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = np.array(all_data)\n",
    "feature_cols = data_df[:, 1:]\n",
    "target_col = data_df[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0036502467982036935"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add code here\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "reg = linear_model.LinearRegression() # add code here\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_cols, target_col, test_size=0.25, random_state=42)\n",
    "\n",
    "reg.fit(X_train, y_train)\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02815429])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.Series(reg.coef_, index=feature_cols)\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is not amazing. We can do better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $ \\\\ $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Repeat, but be careful\n",
    "### Here we will see if we can clean the data better\n",
    "\n",
    "### Things to try\n",
    " - ### Look at the histograms of word similarities to see if we can \"ignore\" some ill-behaved data\n",
    " - ### Try limiting how greedy the `TFIDFVectorizer` is: `min_df`, `max_df`, `max_features`, etc.\n",
    " \n",
    "### We will examine our data and look for things that look out of place\n",
    " - ### We will ultimately want our data to look normally distributed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_mda(mda):\n",
    "    paras = [p.lower() for p in mda.split('\\n') if len(p) > 40]\n",
    "    cleaned =  ' '.join(paras)\n",
    "    words = cleaned.split()\n",
    "    words = [word for word in words if len(word) > 2]\n",
    "    if len(words) > 10:\n",
    "        return ' '.join(words)\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADBE</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AMD</th>\n",
       "      <th>AES</th>\n",
       "      <th>AMG</th>\n",
       "      <th>AFL</th>\n",
       "      <th>AIV</th>\n",
       "      <th>AKAM</th>\n",
       "      <th>SO</th>\n",
       "      <th>ALK</th>\n",
       "      <th>...</th>\n",
       "      <th>JCI</th>\n",
       "      <th>MU</th>\n",
       "      <th>RJF</th>\n",
       "      <th>ROK</th>\n",
       "      <th>SWKS</th>\n",
       "      <th>SBUX</th>\n",
       "      <th>SNPS</th>\n",
       "      <th>TSN</th>\n",
       "      <th>TDG</th>\n",
       "      <th>VIAB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADBE</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.778558</td>\n",
       "      <td>0.774899</td>\n",
       "      <td>0.733078</td>\n",
       "      <td>0.716311</td>\n",
       "      <td>0.729026</td>\n",
       "      <td>0.531221</td>\n",
       "      <td>0.846542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.709761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707491</td>\n",
       "      <td>0.761365</td>\n",
       "      <td>0.770023</td>\n",
       "      <td>0.775591</td>\n",
       "      <td>0.838928</td>\n",
       "      <td>0.691573</td>\n",
       "      <td>0.854355</td>\n",
       "      <td>0.781628</td>\n",
       "      <td>0.751405</td>\n",
       "      <td>0.746832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAP</th>\n",
       "      <td>0.778558</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.813690</td>\n",
       "      <td>0.789807</td>\n",
       "      <td>0.754933</td>\n",
       "      <td>0.784507</td>\n",
       "      <td>0.568569</td>\n",
       "      <td>0.858525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.760760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753291</td>\n",
       "      <td>0.803720</td>\n",
       "      <td>0.808612</td>\n",
       "      <td>0.835261</td>\n",
       "      <td>0.795753</td>\n",
       "      <td>0.793316</td>\n",
       "      <td>0.803614</td>\n",
       "      <td>0.796018</td>\n",
       "      <td>0.803191</td>\n",
       "      <td>0.784600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMD</th>\n",
       "      <td>0.774899</td>\n",
       "      <td>0.813690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808407</td>\n",
       "      <td>0.778368</td>\n",
       "      <td>0.773822</td>\n",
       "      <td>0.555433</td>\n",
       "      <td>0.836496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.738259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808158</td>\n",
       "      <td>0.820952</td>\n",
       "      <td>0.805966</td>\n",
       "      <td>0.782649</td>\n",
       "      <td>0.821668</td>\n",
       "      <td>0.712950</td>\n",
       "      <td>0.822254</td>\n",
       "      <td>0.818619</td>\n",
       "      <td>0.811516</td>\n",
       "      <td>0.779165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AES</th>\n",
       "      <td>0.733078</td>\n",
       "      <td>0.789807</td>\n",
       "      <td>0.808407</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.728791</td>\n",
       "      <td>0.811388</td>\n",
       "      <td>0.560585</td>\n",
       "      <td>0.834174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847035</td>\n",
       "      <td>0.804228</td>\n",
       "      <td>0.827569</td>\n",
       "      <td>0.795757</td>\n",
       "      <td>0.781394</td>\n",
       "      <td>0.710607</td>\n",
       "      <td>0.787304</td>\n",
       "      <td>0.778269</td>\n",
       "      <td>0.836574</td>\n",
       "      <td>0.780424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMG</th>\n",
       "      <td>0.716311</td>\n",
       "      <td>0.754933</td>\n",
       "      <td>0.778368</td>\n",
       "      <td>0.728791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.715637</td>\n",
       "      <td>0.532612</td>\n",
       "      <td>0.803293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.692333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.690209</td>\n",
       "      <td>0.737643</td>\n",
       "      <td>0.784179</td>\n",
       "      <td>0.739985</td>\n",
       "      <td>0.742765</td>\n",
       "      <td>0.655550</td>\n",
       "      <td>0.761007</td>\n",
       "      <td>0.746108</td>\n",
       "      <td>0.711462</td>\n",
       "      <td>0.723726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SBUX</th>\n",
       "      <td>0.691573</td>\n",
       "      <td>0.793316</td>\n",
       "      <td>0.712950</td>\n",
       "      <td>0.710607</td>\n",
       "      <td>0.655550</td>\n",
       "      <td>0.691381</td>\n",
       "      <td>0.497866</td>\n",
       "      <td>0.721705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.649364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.709006</td>\n",
       "      <td>0.695158</td>\n",
       "      <td>0.732028</td>\n",
       "      <td>0.710487</td>\n",
       "      <td>0.721926</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.713095</td>\n",
       "      <td>0.728960</td>\n",
       "      <td>0.732974</td>\n",
       "      <td>0.700939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNPS</th>\n",
       "      <td>0.854355</td>\n",
       "      <td>0.803614</td>\n",
       "      <td>0.822254</td>\n",
       "      <td>0.787304</td>\n",
       "      <td>0.761007</td>\n",
       "      <td>0.768204</td>\n",
       "      <td>0.543023</td>\n",
       "      <td>0.880849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.745447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777111</td>\n",
       "      <td>0.800838</td>\n",
       "      <td>0.815892</td>\n",
       "      <td>0.795628</td>\n",
       "      <td>0.845985</td>\n",
       "      <td>0.713095</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.807497</td>\n",
       "      <td>0.806666</td>\n",
       "      <td>0.777724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSN</th>\n",
       "      <td>0.781628</td>\n",
       "      <td>0.796018</td>\n",
       "      <td>0.818619</td>\n",
       "      <td>0.778269</td>\n",
       "      <td>0.746108</td>\n",
       "      <td>0.747136</td>\n",
       "      <td>0.534825</td>\n",
       "      <td>0.806890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.722657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.794384</td>\n",
       "      <td>0.793677</td>\n",
       "      <td>0.804490</td>\n",
       "      <td>0.779029</td>\n",
       "      <td>0.837411</td>\n",
       "      <td>0.728960</td>\n",
       "      <td>0.807497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.822440</td>\n",
       "      <td>0.753907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TDG</th>\n",
       "      <td>0.751405</td>\n",
       "      <td>0.803191</td>\n",
       "      <td>0.811516</td>\n",
       "      <td>0.836574</td>\n",
       "      <td>0.711462</td>\n",
       "      <td>0.816654</td>\n",
       "      <td>0.535491</td>\n",
       "      <td>0.823169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.739916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887557</td>\n",
       "      <td>0.795769</td>\n",
       "      <td>0.876082</td>\n",
       "      <td>0.782101</td>\n",
       "      <td>0.793394</td>\n",
       "      <td>0.732974</td>\n",
       "      <td>0.806666</td>\n",
       "      <td>0.822440</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.755362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIAB</th>\n",
       "      <td>0.746832</td>\n",
       "      <td>0.784600</td>\n",
       "      <td>0.779165</td>\n",
       "      <td>0.780424</td>\n",
       "      <td>0.723726</td>\n",
       "      <td>0.754813</td>\n",
       "      <td>0.540632</td>\n",
       "      <td>0.824094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.719132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.748436</td>\n",
       "      <td>0.771267</td>\n",
       "      <td>0.778179</td>\n",
       "      <td>0.788118</td>\n",
       "      <td>0.771674</td>\n",
       "      <td>0.700939</td>\n",
       "      <td>0.777724</td>\n",
       "      <td>0.753907</td>\n",
       "      <td>0.755362</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 323 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ADBE       AAP       AMD       AES       AMG       AFL       AIV  \\\n",
       "ADBE  1.000000  0.778558  0.774899  0.733078  0.716311  0.729026  0.531221   \n",
       "AAP   0.778558  1.000000  0.813690  0.789807  0.754933  0.784507  0.568569   \n",
       "AMD   0.774899  0.813690  1.000000  0.808407  0.778368  0.773822  0.555433   \n",
       "AES   0.733078  0.789807  0.808407  1.000000  0.728791  0.811388  0.560585   \n",
       "AMG   0.716311  0.754933  0.778368  0.728791  1.000000  0.715637  0.532612   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "SBUX  0.691573  0.793316  0.712950  0.710607  0.655550  0.691381  0.497866   \n",
       "SNPS  0.854355  0.803614  0.822254  0.787304  0.761007  0.768204  0.543023   \n",
       "TSN   0.781628  0.796018  0.818619  0.778269  0.746108  0.747136  0.534825   \n",
       "TDG   0.751405  0.803191  0.811516  0.836574  0.711462  0.816654  0.535491   \n",
       "VIAB  0.746832  0.784600  0.779165  0.780424  0.723726  0.754813  0.540632   \n",
       "\n",
       "          AKAM   SO       ALK  ...       JCI        MU       RJF       ROK  \\\n",
       "ADBE  0.846542  0.0  0.709761  ...  0.707491  0.761365  0.770023  0.775591   \n",
       "AAP   0.858525  0.0  0.760760  ...  0.753291  0.803720  0.808612  0.835261   \n",
       "AMD   0.836496  0.0  0.738259  ...  0.808158  0.820952  0.805966  0.782649   \n",
       "AES   0.834174  0.0  0.750890  ...  0.847035  0.804228  0.827569  0.795757   \n",
       "AMG   0.803293  0.0  0.692333  ...  0.690209  0.737643  0.784179  0.739985   \n",
       "...        ...  ...       ...  ...       ...       ...       ...       ...   \n",
       "SBUX  0.721705  0.0  0.649364  ...  0.709006  0.695158  0.732028  0.710487   \n",
       "SNPS  0.880849  0.0  0.745447  ...  0.777111  0.800838  0.815892  0.795628   \n",
       "TSN   0.806890  0.0  0.722657  ...  0.794384  0.793677  0.804490  0.779029   \n",
       "TDG   0.823169  0.0  0.739916  ...  0.887557  0.795769  0.876082  0.782101   \n",
       "VIAB  0.824094  0.0  0.719132  ...  0.748436  0.771267  0.778179  0.788118   \n",
       "\n",
       "          SWKS      SBUX      SNPS       TSN       TDG      VIAB  \n",
       "ADBE  0.838928  0.691573  0.854355  0.781628  0.751405  0.746832  \n",
       "AAP   0.795753  0.793316  0.803614  0.796018  0.803191  0.784600  \n",
       "AMD   0.821668  0.712950  0.822254  0.818619  0.811516  0.779165  \n",
       "AES   0.781394  0.710607  0.787304  0.778269  0.836574  0.780424  \n",
       "AMG   0.742765  0.655550  0.761007  0.746108  0.711462  0.723726  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "SBUX  0.721926  1.000000  0.713095  0.728960  0.732974  0.700939  \n",
       "SNPS  0.845985  0.713095  1.000000  0.807497  0.806666  0.777724  \n",
       "TSN   0.837411  0.728960  0.807497  1.000000  0.822440  0.753907  \n",
       "TDG   0.793394  0.732974  0.806666  0.822440  1.000000  0.755362  \n",
       "VIAB  0.771674  0.700939  0.777724  0.753907  0.755362  1.000000  \n",
       "\n",
       "[300 rows x 323 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = TfidfVectorizer(min_df = 3, max_df = 1.0, max_features = None)\n",
    "word_vecs = vec.fit_transform((clean_mda(item['mda']) for item in data))\n",
    "\n",
    "vocab = {token: n for n, token in enumerate(pd.Series(vec.vocabulary_).sort_values().index)}\n",
    "inv_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "word_sims = cosine_similarity(word_vecs)\n",
    "# Lots of word similarities are all zeros- so we'll ignore\n",
    "# add code here to remove rows of word_sims where all the elements are zero\n",
    "tickers = np.array([item['ticker'] for item in data])\n",
    "new_tickers = tickers[word_sims.sum(axis=1)!=0]\n",
    "new_word_sims = word_sims[word_sims.sum(axis=1)!=0]\n",
    "new_word_sims_df = pd.DataFrame(new_word_sims, index=new_tickers, columns=tickers)\n",
    "new_word_sims_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>word_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ADBE</th>\n",
       "      <th>ADBE</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAP</th>\n",
       "      <td>0.778558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMD</th>\n",
       "      <td>0.774899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AES</th>\n",
       "      <td>0.733078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMG</th>\n",
       "      <td>0.716311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">VIAB</th>\n",
       "      <th>SBUX</th>\n",
       "      <td>0.700939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNPS</th>\n",
       "      <td>0.777724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSN</th>\n",
       "      <td>0.753907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TDG</th>\n",
       "      <td>0.755362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIAB</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96900 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word_similarity\n",
       "ADBE ADBE         1.000000\n",
       "     AAP          0.778558\n",
       "     AMD          0.774899\n",
       "     AES          0.733078\n",
       "     AMG          0.716311\n",
       "...                    ...\n",
       "VIAB SBUX         0.700939\n",
       "     SNPS         0.777724\n",
       "     TSN          0.753907\n",
       "     TDG          0.755362\n",
       "     VIAB         1.000000\n",
       "\n",
       "[96900 rows x 1 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_word_cor = new_word_sims_df.stack().to_frame(name='word_similarity')\n",
    "new_word_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>returns_correlation</th>\n",
       "      <th>word_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ACN</th>\n",
       "      <th>ACN</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADBE</th>\n",
       "      <td>0.555422</td>\n",
       "      <td>0.797598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMD</th>\n",
       "      <td>0.215997</td>\n",
       "      <td>0.775307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAP</th>\n",
       "      <td>0.231908</td>\n",
       "      <td>0.778956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AES</th>\n",
       "      <td>0.351658</td>\n",
       "      <td>0.784401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          returns_correlation  word_similarity\n",
       "ACN ACN              1.000000         1.000000\n",
       "    ADBE             0.555422         0.797598\n",
       "    AMD              0.215997         0.775307\n",
       "    AAP              0.231908         0.778956\n",
       "    AES              0.351658         0.784401"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the returns correlation and the cosine similarities as above\n",
    "all_data = rets_cor.join(new_word_cor)\n",
    "all_data = all_data.dropna()\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Word Similarity')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# inspect your data- make some histograms\n",
    "plt.figure(figsize=(12,7))\n",
    "all_data.returns_correlation.hist(bins=40)\n",
    "plt.title('Returns Correlation')\n",
    "plt.figure(figsize=(12,7))\n",
    "all_data.word_similarity.hist(bins=40)\n",
    "plt.title('Word Similarity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning our data\n",
    "### It seems lots of things are identically 0 (no word overlap) or identically 1 (the MD&A section for one company perfectly overlaps itself). We will exclude those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>returns_correlation</th>\n",
       "      <th>word_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <td>0.555422</td>\n",
       "      <td>0.797598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMD</th>\n",
       "      <td>0.215997</td>\n",
       "      <td>0.775307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAP</th>\n",
       "      <td>0.231908</td>\n",
       "      <td>0.778956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AES</th>\n",
       "      <td>0.351658</td>\n",
       "      <td>0.784401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMG</th>\n",
       "      <td>0.510561</td>\n",
       "      <td>0.709525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ZTS</th>\n",
       "      <th>XRX</th>\n",
       "      <td>0.382344</td>\n",
       "      <td>0.825251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLNX</th>\n",
       "      <td>0.344773</td>\n",
       "      <td>0.803660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XYL</th>\n",
       "      <td>0.385495</td>\n",
       "      <td>0.813930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YUM</th>\n",
       "      <td>0.344108</td>\n",
       "      <td>0.717907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZION</th>\n",
       "      <td>0.327581</td>\n",
       "      <td>0.771679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86762 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          returns_correlation  word_similarity\n",
       "ACN ADBE             0.555422         0.797598\n",
       "    AMD              0.215997         0.775307\n",
       "    AAP              0.231908         0.778956\n",
       "    AES              0.351658         0.784401\n",
       "    AMG              0.510561         0.709525\n",
       "...                       ...              ...\n",
       "ZTS XRX              0.382344         0.825251\n",
       "    XLNX             0.344773         0.803660\n",
       "    XYL              0.385495         0.813930\n",
       "    YUM              0.344108         0.717907\n",
       "    ZION             0.327581         0.771679\n",
       "\n",
       "[86762 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "all_data = all_data[(all_data['word_similarity']>0)&(all_data['word_similarity']<1)]\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Word Similarity')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# examine histograms again\n",
    "plt.figure(figsize=(12,7))\n",
    "all_data.returns_correlation.hist(bins=40)\n",
    "plt.title('Returns Correlation')\n",
    "plt.figure(figsize=(12,7))\n",
    "all_data.word_similarity.hist(bins=40)\n",
    "plt.title('Word Similarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>returns_correlation</th>\n",
       "      <th>word_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>returns_correlation</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_similarity</th>\n",
       "      <td>0.140083</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     returns_correlation  word_similarity\n",
       "returns_correlation             1.000000         0.140083\n",
       "word_similarity                 0.140083         1.000000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lastly, there is a bit of a \"hump\" at low `word_similarity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>returns_correlation</th>\n",
       "      <th>word_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>returns_correlation</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_similarity</th>\n",
       "      <td>0.214137</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     returns_correlation  word_similarity\n",
       "returns_correlation             1.000000         0.214137\n",
       "word_similarity                 0.214137         1.000000"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add code here\n",
    "all_data = all_data[(all_data['word_similarity']>0.47)]\n",
    "all_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The contemperaneous correlation is twice as large!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Now, repeat the exercise of predicting future returns correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = np.array(all_data)\n",
    "feature_cols = data_df[:, 1:]\n",
    "target_col = data_df[:, 0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_cols, target_col, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04635788880171021"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reg.fit(X_train, y_train)\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41670885])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.Series(reg.coef_, index=feature_cols)\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is about 5 times better than before!\n",
    "## $ \\\\ $ \n",
    "## Part 7: What will happen if we include last year's returns correlation as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>last_returns_correlation</th>\n",
       "      <th>returns_correlation</th>\n",
       "      <th>word_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <td>0.490708</td>\n",
       "      <td>0.555422</td>\n",
       "      <td>0.797598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMD</th>\n",
       "      <td>0.192102</td>\n",
       "      <td>0.215997</td>\n",
       "      <td>0.775307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAP</th>\n",
       "      <td>0.192131</td>\n",
       "      <td>0.231908</td>\n",
       "      <td>0.778956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AES</th>\n",
       "      <td>0.329957</td>\n",
       "      <td>0.351658</td>\n",
       "      <td>0.784401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMG</th>\n",
       "      <td>0.509118</td>\n",
       "      <td>0.510561</td>\n",
       "      <td>0.709525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ZTS</th>\n",
       "      <th>XRX</th>\n",
       "      <td>0.278654</td>\n",
       "      <td>0.382344</td>\n",
       "      <td>0.825251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLNX</th>\n",
       "      <td>0.294776</td>\n",
       "      <td>0.344773</td>\n",
       "      <td>0.803660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XYL</th>\n",
       "      <td>0.341346</td>\n",
       "      <td>0.385495</td>\n",
       "      <td>0.813930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YUM</th>\n",
       "      <td>0.275481</td>\n",
       "      <td>0.344108</td>\n",
       "      <td>0.717907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZION</th>\n",
       "      <td>0.273752</td>\n",
       "      <td>0.327581</td>\n",
       "      <td>0.771679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80298 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          last_returns_correlation  returns_correlation  word_similarity\n",
       "ACN ADBE                  0.490708             0.555422         0.797598\n",
       "    AMD                   0.192102             0.215997         0.775307\n",
       "    AAP                   0.192131             0.231908         0.778956\n",
       "    AES                   0.329957             0.351658         0.784401\n",
       "    AMG                   0.509118             0.510561         0.709525\n",
       "...                            ...                  ...              ...\n",
       "ZTS XRX                   0.278654             0.382344         0.825251\n",
       "    XLNX                  0.294776             0.344773         0.803660\n",
       "    XYL                   0.341346             0.385495         0.813930\n",
       "    YUM                   0.275481             0.344108         0.717907\n",
       "    ZION                  0.273752             0.327581         0.771679\n",
       "\n",
       "[80298 rows x 3 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns = prices.pct_change()\n",
    "last_returns = returns.loc['2015-01-01':'2016-01-01']\n",
    "last_corr_mat = returns.corr()\n",
    "\n",
    "last_year_corr = last_corr_mat.stack().to_frame(name='last_returns_correlation')\n",
    "data_df = last_year_corr.join(all_data)\n",
    "data_df = data_df.dropna()\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8106990020212006"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = np.array(data_df)\n",
    "feature_cols = data_df[:, [0,2]]\n",
    "target_col = data_df[:, 1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_cols, target_col, test_size=0.33, random_state=42)\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.12423119, 0.15565082])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.Series(reg.coef_, index=feature_cols)\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indeed, we do much better, but the word features still help!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
